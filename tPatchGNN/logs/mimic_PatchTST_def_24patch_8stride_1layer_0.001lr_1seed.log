/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_baselines.py
2024-07-19 11:33:05
run_baselines.py --history 24 --model PatchTST --dataset mimic
Namespace(state='def', n=100000000, epoch=100, patience=10, history=24, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='mimic', quantization=0.0, model='PatchTST', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=8, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='0', seq_len=280, top_k=5, num_kernels=64, npatch=1, device=device(type='cuda', index=0), PID=1816613, pred_window=24, ndim=96, patch_layer=1, task_name='long_term_forecast', label_len=48, pred_len=96, patch_len=16, d_model=64, dropout=0.1, output_attention=None, n_heads=1, d_ff=64, activation='gelu', e_layers=2, factor=3, enc_in=321)
- Epoch 000, ExpID 52171
Train - Loss (one batch): 0.05954
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06688, 0.06688, 0.25861, 0.20610, 838.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07137, 0.07137, 0.26716, 0.20938, 771.99%
Time spent: 31.14s
- Epoch 001, ExpID 52171
Train - Loss (one batch): 0.05762
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06062, 0.06062, 0.24622, 0.18580, 631.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.06530, 0.06530, 0.25554, 0.18956, 582.03%
Time spent: 30.60s
- Epoch 002, ExpID 52171
Train - Loss (one batch): 0.06440
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06010, 0.06010, 0.24515, 0.18267, 547.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.06488, 0.06488, 0.25472, 0.18675, 494.62%
Time spent: 30.57s
- Epoch 003, ExpID 52171
Train - Loss (one batch): 0.05775
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06957, 0.06957, 0.26376, 0.18403, 362.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.06488, 0.06488, 0.25472, 0.18675, 494.62%
Time spent: 26.80s
- Epoch 004, ExpID 52171
Train - Loss (one batch): 0.05314
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06262, 0.06262, 0.25024, 0.18541, 601.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.06488, 0.06488, 0.25472, 0.18675, 494.62%
Time spent: 26.67s
- Epoch 005, ExpID 52171
Train - Loss (one batch): 0.05074
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06909, 0.06909, 0.26286, 0.17873, 320.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.06488, 0.06488, 0.25472, 0.18675, 494.62%
Time spent: 26.92s
- Epoch 006, ExpID 52171
Train - Loss (one batch): 0.05796
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06469, 0.06469, 0.25434, 0.18321, 481.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.06488, 0.06488, 0.25472, 0.18675, 494.62%
Time spent: 26.87s
- Epoch 007, ExpID 52171
Train - Loss (one batch): 0.05367
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05980, 0.05980, 0.24455, 0.18036, 534.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.06529, 0.06529, 0.25552, 0.18491, 496.44%
Time spent: 30.53s
- Epoch 008, ExpID 52171
Train - Loss (one batch): 0.04742
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06717, 0.06717, 0.25918, 0.18728, 526.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.06529, 0.06529, 0.25552, 0.18491, 496.44%
Time spent: 26.74s
- Epoch 009, ExpID 52171
Train - Loss (one batch): 0.07581
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06524, 0.06524, 0.25542, 0.18019, 402.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.06529, 0.06529, 0.25552, 0.18491, 496.44%
Time spent: 26.68s
- Epoch 010, ExpID 52171
Train - Loss (one batch): 0.05829
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06042, 0.06042, 0.24580, 0.18157, 554.03%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.06529, 0.06529, 0.25552, 0.18491, 496.44%
Time spent: 26.52s
- Epoch 011, ExpID 52171
Train - Loss (one batch): 0.05613
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06645, 0.06645, 0.25778, 0.18472, 476.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.06529, 0.06529, 0.25552, 0.18491, 496.44%
Time spent: 26.70s
- Epoch 012, ExpID 52171
Train - Loss (one batch): 0.05960
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06584, 0.06584, 0.25659, 0.18452, 492.74%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.06529, 0.06529, 0.25552, 0.18491, 496.44%
Time spent: 26.56s
- Epoch 013, ExpID 52171
Train - Loss (one batch): 0.07100
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05892, 0.05892, 0.24274, 0.18000, 509.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 30.32s
- Epoch 014, ExpID 52171
Train - Loss (one batch): 0.04505
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06642, 0.06642, 0.25773, 0.18638, 523.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 26.65s
- Epoch 015, ExpID 52171
Train - Loss (one batch): 0.05841
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06028, 0.06028, 0.24552, 0.17407, 401.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 26.76s
- Epoch 016, ExpID 52171
Train - Loss (one batch): 0.06130
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06419, 0.06419, 0.25336, 0.17837, 388.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 26.79s
- Epoch 017, ExpID 52171
Train - Loss (one batch): 0.08024
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07292, 0.07292, 0.27004, 0.19330, 468.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 26.70s
- Epoch 018, ExpID 52171
Train - Loss (one batch): 0.05434
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06461, 0.06461, 0.25418, 0.18176, 409.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 26.79s
- Epoch 019, ExpID 52171
Train - Loss (one batch): 0.06502
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06810, 0.06810, 0.26097, 0.18573, 530.02%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 26.90s
- Epoch 020, ExpID 52171
Train - Loss (one batch): 0.05099
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06689, 0.06689, 0.25864, 0.18482, 444.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 26.80s
- Epoch 021, ExpID 52171
Train - Loss (one batch): 0.05639
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06365, 0.06365, 0.25228, 0.18240, 523.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 26.86s
- Epoch 022, ExpID 52171
Train - Loss (one batch): 0.06235
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06473, 0.06473, 0.25443, 0.18516, 508.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 26.83s
- Epoch 023, ExpID 52171
Train - Loss (one batch): 0.06901
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06358, 0.06358, 0.25216, 0.18092, 483.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 26.70s
- Epoch 024, ExpID 52171
Train - Loss (one batch): 0.05806
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06254, 0.06254, 0.25009, 0.18147, 459.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 26.79s
- Epoch 025, ExpID 52171
Train - Loss (one batch): 0.05409
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05691, 0.05691, 0.23855, 0.17278, 433.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 30.60s
- Epoch 026, ExpID 52171
Train - Loss (one batch): 0.05728
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07110, 0.07110, 0.26665, 0.19044, 457.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.70s
- Epoch 027, ExpID 52171
Train - Loss (one batch): 0.05246
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06433, 0.06433, 0.25364, 0.18002, 461.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.84s
- Epoch 028, ExpID 52171
Train - Loss (one batch): 0.06580
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06631, 0.06631, 0.25751, 0.18268, 438.30%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.76s
- Epoch 029, ExpID 52171
Train - Loss (one batch): 0.05533
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06566, 0.06566, 0.25624, 0.18470, 464.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.57s
- Epoch 030, ExpID 52171
Train - Loss (one batch): 0.05791
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06586, 0.06586, 0.25663, 0.18353, 429.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.74s
- Epoch 031, ExpID 52171
Train - Loss (one batch): 0.05938
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06176, 0.06176, 0.24852, 0.17981, 450.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.84s
- Epoch 032, ExpID 52171
Train - Loss (one batch): 0.06691
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06602, 0.06602, 0.25694, 0.18440, 446.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.65s
- Epoch 033, ExpID 52171
Train - Loss (one batch): 0.05785
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06313, 0.06313, 0.25127, 0.18154, 477.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.61s
- Epoch 034, ExpID 52171
Train - Loss (one batch): 0.06269
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07152, 0.07152, 0.26743, 0.19238, 455.62%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.58s
- Epoch 035, ExpID 52171
Train - Loss (one batch): 0.04843
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07760, 0.07760, 0.27857, 0.19712, 408.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.80s
- Epoch 036, ExpID 52171
Train - Loss (one batch): 0.05906
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07289, 0.07289, 0.26997, 0.19130, 449.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.74s
- Epoch 037, ExpID 52171
Train - Loss (one batch): 0.05096
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07064, 0.07064, 0.26578, 0.18666, 430.43%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.75s
- Epoch 038, ExpID 52171
Train - Loss (one batch): 0.04780
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06553, 0.06553, 0.25599, 0.18448, 496.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.75s
- Epoch 039, ExpID 52171
Train - Loss (one batch): 0.05301
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06646, 0.06646, 0.25781, 0.18307, 429.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.90s
- Epoch 040, ExpID 52171
Train - Loss (one batch): 0.05280
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07166, 0.07166, 0.26769, 0.18706, 381.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.85s
- Epoch 041, ExpID 52171
Train - Loss (one batch): 0.05824
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07449, 0.07449, 0.27292, 0.19305, 436.09%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.83s
- Epoch 042, ExpID 52171
Train - Loss (one batch): 0.05728
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07619, 0.07619, 0.27602, 0.19474, 421.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.57s
- Epoch 043, ExpID 52171
Train - Loss (one batch): 0.05905
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06646, 0.06646, 0.25779, 0.18428, 433.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.50s
- Epoch 044, ExpID 52171
Train - Loss (one batch): 0.06824
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06684, 0.06684, 0.25853, 0.18527, 477.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.61s
- Epoch 045, ExpID 52171
Train - Loss (one batch): 0.05941
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07407, 0.07407, 0.27215, 0.19475, 445.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.66s
- Epoch 046, ExpID 52171
Train - Loss (one batch): 0.05059
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07008, 0.07008, 0.26472, 0.18999, 518.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.72s
- Epoch 047, ExpID 52171
Train - Loss (one batch): 0.05329
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06723, 0.06723, 0.25929, 0.18173, 430.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.63s
- Epoch 048, ExpID 52171
Train - Loss (one batch): 0.05501
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07446, 0.07446, 0.27288, 0.19367, 459.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.52s
- Epoch 049, ExpID 52171
Train - Loss (one batch): 0.05354
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06719, 0.06719, 0.25920, 0.18589, 494.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.77s
- Epoch 050, ExpID 52171
Train - Loss (one batch): 0.05783
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06369, 0.06369, 0.25237, 0.17867, 421.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.65s
- Epoch 051, ExpID 52171
Train - Loss (one batch): 0.04322
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07535, 0.07535, 0.27451, 0.19229, 368.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.68s
- Epoch 052, ExpID 52171
Train - Loss (one batch): 0.06436
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06581, 0.06581, 0.25653, 0.17985, 381.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.75s
- Epoch 053, ExpID 52171
Train - Loss (one batch): 0.05101
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07948, 0.07948, 0.28192, 0.19954, 438.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.59s
- Epoch 054, ExpID 52171
Train - Loss (one batch): 0.06559
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06612, 0.06612, 0.25714, 0.18516, 458.09%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.62s
- Epoch 055, ExpID 52171
Train - Loss (one batch): 0.05119
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07901, 0.07901, 0.28108, 0.19825, 402.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.50s
- Epoch 056, ExpID 52171
Train - Loss (one batch): 0.05599
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06736, 0.06736, 0.25954, 0.18479, 432.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.76s
- Epoch 057, ExpID 52171
Train - Loss (one batch): 0.05126
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06349, 0.06349, 0.25197, 0.18050, 510.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.67s
- Epoch 058, ExpID 52171
Train - Loss (one batch): 0.06088
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07000, 0.07000, 0.26458, 0.18849, 443.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.83s
- Epoch 059, ExpID 52171
Train - Loss (one batch): 0.05532
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06570, 0.06570, 0.25631, 0.18163, 445.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.67s
- Epoch 060, ExpID 52171
Train - Loss (one batch): 0.04378
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07023, 0.07023, 0.26501, 0.18715, 440.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.70s
- Epoch 061, ExpID 52171
Train - Loss (one batch): 0.06052
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07327, 0.07327, 0.27069, 0.19180, 427.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.77s
- Epoch 062, ExpID 52171
Train - Loss (one batch): 0.05813
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07509, 0.07509, 0.27403, 0.19464, 506.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.86s
- Epoch 063, ExpID 52171
Train - Loss (one batch): 0.05643
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07525, 0.07525, 0.27431, 0.19356, 430.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.88s
- Epoch 064, ExpID 52171
Train - Loss (one batch): 0.04769
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06681, 0.06681, 0.25847, 0.18354, 473.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.83s
- Epoch 065, ExpID 52171
Train - Loss (one batch): 0.05969
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06817, 0.06817, 0.26109, 0.18637, 451.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.83s
- Epoch 066, ExpID 52171
Train - Loss (one batch): 0.06095
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07098, 0.07098, 0.26642, 0.18917, 425.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.88s
- Epoch 067, ExpID 52171
Train - Loss (one batch): 0.06390
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06909, 0.06909, 0.26284, 0.18631, 454.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.73s
- Epoch 068, ExpID 52171
Train - Loss (one batch): 0.07276
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07137, 0.07137, 0.26715, 0.19007, 441.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.91s
- Epoch 069, ExpID 52171
Train - Loss (one batch): 0.06222
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07728, 0.07728, 0.27800, 0.19645, 439.43%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.74s
- Epoch 070, ExpID 52171
Train - Loss (one batch): 0.05183
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06118, 0.06118, 0.24735, 0.17818, 451.99%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.68s
- Epoch 071, ExpID 52171
Train - Loss (one batch): 0.05735
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07187, 0.07187, 0.26809, 0.19212, 506.18%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.52s
- Epoch 072, ExpID 52171
Train - Loss (one batch): 0.04974
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06616, 0.06616, 0.25721, 0.18292, 436.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.78s
- Epoch 073, ExpID 52171
Train - Loss (one batch): 0.05988
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06558, 0.06558, 0.25609, 0.18503, 492.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.82s
- Epoch 074, ExpID 52171
Train - Loss (one batch): 0.05534
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06568, 0.06568, 0.25627, 0.18462, 476.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.84s
- Epoch 075, ExpID 52171
Train - Loss (one batch): 0.05370
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07772, 0.07772, 0.27878, 0.19664, 420.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.87s
- Epoch 076, ExpID 52171
Train - Loss (one batch): 0.05334
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06443, 0.06443, 0.25383, 0.18022, 431.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.87s
- Epoch 077, ExpID 52171
Train - Loss (one batch): 0.04616
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06807, 0.06807, 0.26090, 0.18524, 480.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.76s
- Epoch 078, ExpID 52171
Train - Loss (one batch): 0.05548
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07414, 0.07414, 0.27228, 0.19174, 405.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.79s
- Epoch 079, ExpID 52171
Train - Loss (one batch): 0.06853
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07043, 0.07043, 0.26539, 0.18847, 462.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.92s
- Epoch 080, ExpID 52171
Train - Loss (one batch): 0.05832
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05935, 0.05935, 0.24362, 0.17514, 525.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.86s
- Epoch 081, ExpID 52171
Train - Loss (one batch): 0.05791
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06352, 0.06352, 0.25203, 0.17971, 450.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.82s
- Epoch 082, ExpID 52171
Train - Loss (one batch): 0.04314
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07049, 0.07049, 0.26550, 0.18758, 433.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.90s
- Epoch 083, ExpID 52171
Train - Loss (one batch): 0.06227
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05741, 0.05741, 0.23960, 0.17434, 523.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.83s
- Epoch 084, ExpID 52171
Train - Loss (one batch): 0.06032
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07075, 0.07075, 0.26599, 0.18787, 434.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.79s
- Epoch 085, ExpID 52171
Train - Loss (one batch): 0.05246
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07263, 0.07263, 0.26949, 0.19166, 434.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.77s
- Epoch 086, ExpID 52171
Train - Loss (one batch): 0.05567
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06743, 0.06743, 0.25966, 0.18328, 457.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.82s
- Epoch 087, ExpID 52171
Train - Loss (one batch): 0.04889
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06582, 0.06582, 0.25656, 0.17972, 399.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.86s
- Epoch 088, ExpID 52171
Train - Loss (one batch): 0.06828
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06576, 0.06576, 0.25644, 0.18364, 488.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.77s
- Epoch 089, ExpID 52171
Train - Loss (one batch): 0.05127
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07920, 0.07920, 0.28142, 0.19844, 436.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 27.05s
- Epoch 090, ExpID 52171
Train - Loss (one batch): 0.05450
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07006, 0.07006, 0.26469, 0.18795, 449.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.82s
- Epoch 091, ExpID 52171
Train - Loss (one batch): 0.05408
Val - Loss, MSE, RMSE, MAE, MAPE: 0.08422, 0.08422, 0.29020, 0.20661, 452.99%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.69s
- Epoch 092, ExpID 52171
Train - Loss (one batch): 0.04821
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06495, 0.06495, 0.25485, 0.18042, 432.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.60s
- Epoch 093, ExpID 52171
Train - Loss (one batch): 0.06708
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06531, 0.06531, 0.25556, 0.18132, 441.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.80s
- Epoch 094, ExpID 52171
Train - Loss (one batch): 0.04805
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06998, 0.06998, 0.26454, 0.18414, 371.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.59s
- Epoch 095, ExpID 52171
Train - Loss (one batch): 0.05035
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07547, 0.07547, 0.27471, 0.19360, 437.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.77s
- Epoch 096, ExpID 52171
Train - Loss (one batch): 0.06174
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06517, 0.06517, 0.25528, 0.18300, 466.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.84s
- Epoch 097, ExpID 52171
Train - Loss (one batch): 0.04107
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07900, 0.07900, 0.28107, 0.19539, 375.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.75s
- Epoch 098, ExpID 52171
Train - Loss (one batch): 0.05678
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06741, 0.06741, 0.25964, 0.18336, 433.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.60s
- Epoch 099, ExpID 52171
Train - Loss (one batch): 0.05363
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06935, 0.06935, 0.26335, 0.18586, 416.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.73s
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_baselines.py
2024-07-19 12:20:53
run_baselines.py --history 36 --model PatchTST --dataset mimic
Namespace(state='def', n=100000000, epoch=100, patience=10, history=36, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='mimic', quantization=0.0, model='PatchTST', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=8, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='0', seq_len=464, top_k=5, num_kernels=64, npatch=2, device=device(type='cuda', index=0), PID=1843178, pred_window=12, ndim=96, patch_layer=2, task_name='long_term_forecast', label_len=48, pred_len=96, patch_len=16, d_model=64, dropout=0.1, output_attention=None, n_heads=1, d_ff=64, activation='gelu', e_layers=2, factor=3, enc_in=321)
- Epoch 000, ExpID 25838
Train - Loss (one batch): 0.04583
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06463, 0.06463, 0.25422, 0.19428, 720.02%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.06889, 0.06889, 0.26247, 0.20107, 670.37%
Time spent: 32.68s
- Epoch 001, ExpID 25838
Train - Loss (one batch): 0.05349
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06038, 0.06038, 0.24572, 0.17541, 507.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.06438, 0.06438, 0.25373, 0.18191, 457.64%
Time spent: 32.05s
- Epoch 002, ExpID 25838
Train - Loss (one batch): 0.05286
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06281, 0.06281, 0.25062, 0.18651, 515.62%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.06438, 0.06438, 0.25373, 0.18191, 457.64%
Time spent: 28.31s
- Epoch 003, ExpID 25838
Train - Loss (one batch): 0.04386
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05734, 0.05734, 0.23946, 0.17968, 568.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.06026, 0.06026, 0.24548, 0.18570, 525.59%
Time spent: 32.02s
- Epoch 004, ExpID 25838
Train - Loss (one batch): 0.03979
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06668, 0.06668, 0.25822, 0.18108, 465.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.06026, 0.06026, 0.24548, 0.18570, 525.59%
Time spent: 28.07s
- Epoch 005, ExpID 25838
Train - Loss (one batch): 0.03642
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06705, 0.06705, 0.25893, 0.17516, 317.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.06026, 0.06026, 0.24548, 0.18570, 525.59%
Time spent: 28.34s
- Epoch 006, ExpID 25838
Train - Loss (one batch): 0.03539
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05495, 0.05495, 0.23442, 0.16728, 429.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.05789, 0.05789, 0.24061, 0.17368, 394.56%
Time spent: 32.06s
- Epoch 007, ExpID 25838
Train - Loss (one batch): 0.04721
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05952, 0.05952, 0.24398, 0.17041, 384.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.05789, 0.05789, 0.24061, 0.17368, 394.56%
Time spent: 28.38s
- Epoch 008, ExpID 25838
Train - Loss (one batch): 0.03811
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05893, 0.05893, 0.24275, 0.16531, 313.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.05789, 0.05789, 0.24061, 0.17368, 394.56%
Time spent: 28.34s
- Epoch 009, ExpID 25838
Train - Loss (one batch): 0.08757
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06555, 0.06555, 0.25603, 0.17259, 299.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.05789, 0.05789, 0.24061, 0.17368, 394.56%
Time spent: 28.27s
- Epoch 010, ExpID 25838
Train - Loss (one batch): 0.04883
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05779, 0.05779, 0.24040, 0.16838, 355.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.05789, 0.05789, 0.24061, 0.17368, 394.56%
Time spent: 28.12s
- Epoch 011, ExpID 25838
Train - Loss (one batch): 0.04105
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05517, 0.05517, 0.23488, 0.16428, 370.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.05789, 0.05789, 0.24061, 0.17368, 394.56%
Time spent: 28.09s
- Epoch 012, ExpID 25838
Train - Loss (one batch): 0.03596
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06830, 0.06830, 0.26134, 0.17281, 270.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.05789, 0.05789, 0.24061, 0.17368, 394.56%
Time spent: 28.06s
- Epoch 013, ExpID 25838
Train - Loss (one batch): 0.04362
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05508, 0.05508, 0.23470, 0.16849, 373.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.05789, 0.05789, 0.24061, 0.17368, 394.56%
Time spent: 28.10s
- Epoch 014, ExpID 25838
Train - Loss (one batch): 0.05004
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05723, 0.05723, 0.23923, 0.16451, 328.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.05789, 0.05789, 0.24061, 0.17368, 394.56%
Time spent: 28.13s
- Epoch 015, ExpID 25838
Train - Loss (one batch): 0.04499
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06121, 0.06121, 0.24741, 0.16910, 329.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.05789, 0.05789, 0.24061, 0.17368, 394.56%
Time spent: 28.15s
- Epoch 016, ExpID 25838
Train - Loss (one batch): 0.03899
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05675, 0.05675, 0.23822, 0.16357, 327.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.05789, 0.05789, 0.24061, 0.17368, 394.56%
Time spent: 28.12s
- Epoch 017, ExpID 25838
Train - Loss (one batch): 0.04038
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05483, 0.05483, 0.23417, 0.16089, 319.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 17, 0.05857, 0.05857, 0.24201, 0.16723, 304.48%
Time spent: 31.87s
- Epoch 018, ExpID 25838
Train - Loss (one batch): 0.04133
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05520, 0.05520, 0.23495, 0.16112, 364.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 17, 0.05857, 0.05857, 0.24201, 0.16723, 304.48%
Time spent: 28.20s
- Epoch 019, ExpID 25838
Train - Loss (one batch): 0.03843
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06376, 0.06376, 0.25252, 0.16721, 261.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 17, 0.05857, 0.05857, 0.24201, 0.16723, 304.48%
Time spent: 28.25s
- Epoch 020, ExpID 25838
Train - Loss (one batch): 0.03710
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05231, 0.05231, 0.22872, 0.16002, 364.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 31.92s
- Epoch 021, ExpID 25838
Train - Loss (one batch): 0.06633
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05924, 0.05924, 0.24338, 0.17058, 303.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.31s
- Epoch 022, ExpID 25838
Train - Loss (one batch): 0.04214
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05276, 0.05276, 0.22970, 0.16002, 382.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.22s
- Epoch 023, ExpID 25838
Train - Loss (one batch): 0.04179
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06466, 0.06466, 0.25428, 0.16763, 248.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.23s
- Epoch 024, ExpID 25838
Train - Loss (one batch): 0.04649
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05536, 0.05536, 0.23530, 0.15989, 308.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.17s
- Epoch 025, ExpID 25838
Train - Loss (one batch): 0.03770
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07622, 0.07622, 0.27608, 0.18898, 312.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.25s
- Epoch 026, ExpID 25838
Train - Loss (one batch): 0.04607
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07759, 0.07759, 0.27855, 0.19210, 326.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.18s
- Epoch 027, ExpID 25838
Train - Loss (one batch): 0.03886
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06329, 0.06329, 0.25157, 0.17486, 372.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.33s
- Epoch 028, ExpID 25838
Train - Loss (one batch): 0.05675
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06664, 0.06664, 0.25815, 0.17619, 322.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.30s
- Epoch 029, ExpID 25838
Train - Loss (one batch): 0.03346
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05425, 0.05425, 0.23292, 0.16143, 336.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.11s
- Epoch 030, ExpID 25838
Train - Loss (one batch): 0.03917
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06617, 0.06617, 0.25724, 0.17546, 324.09%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.37s
- Epoch 031, ExpID 25838
Train - Loss (one batch): 0.04760
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05826, 0.05826, 0.24136, 0.16770, 350.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.38s
- Epoch 032, ExpID 25838
Train - Loss (one batch): 0.04955
Val - Loss, MSE, RMSE, MAE, MAPE: 0.08345, 0.08345, 0.28888, 0.19188, 225.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.28s
- Epoch 033, ExpID 25838
Train - Loss (one batch): 0.05275
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06224, 0.06224, 0.24948, 0.17249, 364.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.22s
- Epoch 034, ExpID 25838
Train - Loss (one batch): 0.04741
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06535, 0.06535, 0.25564, 0.17562, 434.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.06s
- Epoch 035, ExpID 25838
Train - Loss (one batch): 0.04297
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06061, 0.06061, 0.24620, 0.16764, 356.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.05s
- Epoch 036, ExpID 25838
Train - Loss (one batch): 0.04326
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05625, 0.05625, 0.23718, 0.16449, 335.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.14s
- Epoch 037, ExpID 25838
Train - Loss (one batch): 0.04903
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07497, 0.07497, 0.27380, 0.18368, 279.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.25s
- Epoch 038, ExpID 25838
Train - Loss (one batch): 0.03111
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05429, 0.05429, 0.23301, 0.16118, 348.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.20s
- Epoch 039, ExpID 25838
Train - Loss (one batch): 0.03816
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07653, 0.07653, 0.27664, 0.18730, 285.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.19s
- Epoch 040, ExpID 25838
Train - Loss (one batch): 0.04641
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06450, 0.06450, 0.25397, 0.17379, 366.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.27s
- Epoch 041, ExpID 25838
Train - Loss (one batch): 0.03817
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07136, 0.07136, 0.26713, 0.18654, 354.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.09s
- Epoch 042, ExpID 25838
Train - Loss (one batch): 0.03504
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05664, 0.05664, 0.23798, 0.15881, 286.83%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.28s
- Epoch 043, ExpID 25838
Train - Loss (one batch): 0.05529
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05472, 0.05472, 0.23391, 0.16693, 397.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.23s
- Epoch 044, ExpID 25838
Train - Loss (one batch): 0.05486
Val - Loss, MSE, RMSE, MAE, MAPE: 0.09687, 0.09687, 0.31124, 0.20697, 208.57%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.30s
- Epoch 045, ExpID 25838
Train - Loss (one batch): 0.04716
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05913, 0.05913, 0.24317, 0.16780, 369.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.40s
- Epoch 046, ExpID 25838
Train - Loss (one batch): 0.03938
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06410, 0.06410, 0.25319, 0.17642, 363.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.35s
- Epoch 047, ExpID 25838
Train - Loss (one batch): 0.03441
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07471, 0.07471, 0.27333, 0.18558, 287.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.24s
- Epoch 048, ExpID 25838
Train - Loss (one batch): 0.03910
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06191, 0.06191, 0.24881, 0.17293, 364.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.32s
- Epoch 049, ExpID 25838
Train - Loss (one batch): 0.05609
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06059, 0.06059, 0.24615, 0.17128, 398.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.42s
- Epoch 050, ExpID 25838
Train - Loss (one batch): 0.03404
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06118, 0.06118, 0.24734, 0.16768, 325.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.33s
- Epoch 051, ExpID 25838
Train - Loss (one batch): 0.03978
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05365, 0.05365, 0.23163, 0.16183, 351.09%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.33s
- Epoch 052, ExpID 25838
Train - Loss (one batch): 0.05087
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05410, 0.05410, 0.23260, 0.16643, 357.30%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.21s
- Epoch 053, ExpID 25838
Train - Loss (one batch): 0.04624
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06828, 0.06828, 0.26131, 0.17883, 355.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.37s
- Epoch 054, ExpID 25838
Train - Loss (one batch): 0.05541
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05282, 0.05282, 0.22982, 0.15631, 318.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.13s
- Epoch 055, ExpID 25838
Train - Loss (one batch): 0.03797
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05950, 0.05950, 0.24393, 0.16728, 345.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.11s
- Epoch 056, ExpID 25838
Train - Loss (one batch): 0.04443
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06563, 0.06563, 0.25619, 0.17651, 348.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.29s
- Epoch 057, ExpID 25838
Train - Loss (one batch): 0.03032
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05912, 0.05912, 0.24315, 0.16697, 335.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.00s
- Epoch 058, ExpID 25838
Train - Loss (one batch): 0.06174
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07034, 0.07034, 0.26522, 0.18291, 352.30%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.33s
- Epoch 059, ExpID 25838
Train - Loss (one batch): 0.03969
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05971, 0.05971, 0.24436, 0.16711, 361.62%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.33s
- Epoch 060, ExpID 25838
Train - Loss (one batch): 0.03860
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05908, 0.05908, 0.24307, 0.16267, 290.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.27s
- Epoch 061, ExpID 25838
Train - Loss (one batch): 0.04577
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07092, 0.07092, 0.26632, 0.18432, 342.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.00s
- Epoch 062, ExpID 25838
Train - Loss (one batch): 0.03983
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06080, 0.06080, 0.24658, 0.16881, 316.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.26s
- Epoch 063, ExpID 25838
Train - Loss (one batch): 0.04384
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06027, 0.06027, 0.24550, 0.16745, 341.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.25s
- Epoch 064, ExpID 25838
Train - Loss (one batch): 0.02409
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07043, 0.07043, 0.26539, 0.18398, 339.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.28s
- Epoch 065, ExpID 25838
Train - Loss (one batch): 0.03117
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06136, 0.06136, 0.24771, 0.17073, 396.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.24s
- Epoch 066, ExpID 25838
Train - Loss (one batch): 0.05223
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06732, 0.06732, 0.25947, 0.18009, 363.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.17s
- Epoch 067, ExpID 25838
Train - Loss (one batch): 0.03437
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07409, 0.07409, 0.27219, 0.19093, 382.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.34s
- Epoch 068, ExpID 25838
Train - Loss (one batch): 0.05715
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05346, 0.05346, 0.23122, 0.16168, 351.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.37s
- Epoch 069, ExpID 25838
Train - Loss (one batch): 0.04757
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07991, 0.07991, 0.28268, 0.19567, 333.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.34s
- Epoch 070, ExpID 25838
Train - Loss (one batch): 0.03462
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05642, 0.05642, 0.23753, 0.16405, 347.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.32s
- Epoch 071, ExpID 25838
Train - Loss (one batch): 0.03909
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05560, 0.05560, 0.23580, 0.16439, 349.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.28s
- Epoch 072, ExpID 25838
Train - Loss (one batch): 0.03938
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05366, 0.05366, 0.23165, 0.15826, 348.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.25s
- Epoch 073, ExpID 25838
Train - Loss (one batch): 0.03717
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05592, 0.05592, 0.23648, 0.16259, 348.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.18s
- Epoch 074, ExpID 25838
Train - Loss (one batch): 0.04148
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05565, 0.05565, 0.23590, 0.16110, 339.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.12s
- Epoch 075, ExpID 25838
Train - Loss (one batch): 0.04669
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05430, 0.05430, 0.23303, 0.16129, 313.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.14s
- Epoch 076, ExpID 25838
Train - Loss (one batch): 0.04118
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06990, 0.06990, 0.26438, 0.18472, 395.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.07s
- Epoch 077, ExpID 25838
Train - Loss (one batch): 0.03648
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05592, 0.05592, 0.23648, 0.15960, 299.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.10s
- Epoch 078, ExpID 25838
Train - Loss (one batch): 0.03076
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06258, 0.06258, 0.25016, 0.16939, 354.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.04s
- Epoch 079, ExpID 25838
Train - Loss (one batch): 0.05536
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06072, 0.06072, 0.24642, 0.17071, 362.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.12s
- Epoch 080, ExpID 25838
Train - Loss (one batch): 0.04248
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07459, 0.07459, 0.27310, 0.18985, 355.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.10s
- Epoch 081, ExpID 25838
Train - Loss (one batch): 0.03464
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05510, 0.05510, 0.23474, 0.16014, 354.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.04s
- Epoch 082, ExpID 25838
Train - Loss (one batch): 0.03248
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07403, 0.07403, 0.27208, 0.18782, 334.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.27s
- Epoch 083, ExpID 25838
Train - Loss (one batch): 0.04653
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05637, 0.05637, 0.23742, 0.16457, 391.09%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.29s
- Epoch 084, ExpID 25838
Train - Loss (one batch): 0.04411
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07824, 0.07824, 0.27972, 0.19252, 323.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.20s
- Epoch 085, ExpID 25838
Train - Loss (one batch): 0.04154
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06508, 0.06508, 0.25511, 0.17497, 344.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.11s
- Epoch 086, ExpID 25838
Train - Loss (one batch): 0.04273
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06637, 0.06637, 0.25761, 0.17607, 323.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.13s
- Epoch 087, ExpID 25838
Train - Loss (one batch): 0.04419
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06267, 0.06267, 0.25034, 0.16893, 298.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.10s
- Epoch 088, ExpID 25838
Train - Loss (one batch): 0.04827
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06297, 0.06297, 0.25095, 0.17207, 333.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.30s
- Epoch 089, ExpID 25838
Train - Loss (one batch): 0.04016
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06325, 0.06325, 0.25150, 0.17047, 326.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.29s
- Epoch 090, ExpID 25838
Train - Loss (one batch): 0.03467
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06481, 0.06481, 0.25459, 0.17539, 342.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.24s
- Epoch 091, ExpID 25838
Train - Loss (one batch): 0.03080
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06668, 0.06668, 0.25822, 0.18041, 400.02%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.26s
- Epoch 092, ExpID 25838
Train - Loss (one batch): 0.02970
Val - Loss, MSE, RMSE, MAE, MAPE: 0.08015, 0.08015, 0.28311, 0.19652, 362.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.25s
- Epoch 093, ExpID 25838
Train - Loss (one batch): 0.04440
Val - Loss, MSE, RMSE, MAE, MAPE: 0.08810, 0.08810, 0.29682, 0.20193, 293.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.32s
- Epoch 094, ExpID 25838
Train - Loss (one batch): 0.02627
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06535, 0.06535, 0.25564, 0.17503, 310.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.26s
- Epoch 095, ExpID 25838
Train - Loss (one batch): 0.03654
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05535, 0.05535, 0.23527, 0.16273, 323.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.33s
- Epoch 096, ExpID 25838
Train - Loss (one batch): 0.04893
Val - Loss, MSE, RMSE, MAE, MAPE: 0.08040, 0.08040, 0.28355, 0.19580, 345.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.13s
- Epoch 097, ExpID 25838
Train - Loss (one batch): 0.03048
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07312, 0.07312, 0.27042, 0.18181, 277.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.32s
- Epoch 098, ExpID 25838
Train - Loss (one batch): 0.02903
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05766, 0.05766, 0.24013, 0.16708, 339.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.34s
- Epoch 099, ExpID 25838
Train - Loss (one batch): 0.04311
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06881, 0.06881, 0.26232, 0.17950, 331.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.11s
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_baselines.py
2024-07-19 13:11:05
run_baselines.py --history 12 --model PatchTST --dataset mimic
Namespace(state='def', n=100000000, epoch=100, patience=10, history=12, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='mimic', quantization=0.0, model='PatchTST', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=8, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='0', seq_len=133, top_k=5, num_kernels=64, npatch=1, device=device(type='cuda', index=0), PID=1871401, pred_window=36, ndim=96, patch_layer=1, task_name='long_term_forecast', label_len=48, pred_len=96, patch_len=16, d_model=64, dropout=0.1, output_attention=None, n_heads=1, d_ff=64, activation='gelu', e_layers=2, factor=3, enc_in=321)
- Epoch 000, ExpID 24674
Train - Loss (one batch): 0.06403
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07127, 0.07127, 0.26696, 0.21910, 917.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07516, 0.07516, 0.27415, 0.22046, 868.55%
Time spent: 28.62s
- Epoch 001, ExpID 24674
Train - Loss (one batch): 0.06124
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07127, 0.07127, 0.26696, 0.20925, 785.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.07534, 0.07534, 0.27448, 0.21012, 732.27%
Time spent: 27.89s
- Epoch 002, ExpID 24674
Train - Loss (one batch): 0.07856
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07117, 0.07117, 0.26679, 0.21165, 822.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.07504, 0.07504, 0.27394, 0.21242, 756.98%
Time spent: 27.95s
- Epoch 003, ExpID 24674
Train - Loss (one batch): 0.06782
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07138, 0.07138, 0.26717, 0.21042, 789.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.07504, 0.07504, 0.27394, 0.21242, 756.98%
Time spent: 24.33s
- Epoch 004, ExpID 24674
Train - Loss (one batch): 0.06495
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06918, 0.06918, 0.26303, 0.20815, 789.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.07292, 0.07292, 0.27003, 0.20920, 735.74%
Time spent: 27.82s
- Epoch 005, ExpID 24674
Train - Loss (one batch): 0.07469
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07043, 0.07043, 0.26539, 0.21224, 842.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.07292, 0.07292, 0.27003, 0.20920, 735.74%
Time spent: 24.48s
- Epoch 006, ExpID 24674
Train - Loss (one batch): 0.07310
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07137, 0.07137, 0.26716, 0.20872, 755.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.07292, 0.07292, 0.27003, 0.20920, 735.74%
Time spent: 24.29s
- Epoch 007, ExpID 24674
Train - Loss (one batch): 0.07251
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07033, 0.07033, 0.26520, 0.21153, 801.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.07292, 0.07292, 0.27003, 0.20920, 735.74%
Time spent: 24.23s
- Epoch 008, ExpID 24674
Train - Loss (one batch): 0.06114
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07057, 0.07057, 0.26565, 0.20935, 803.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.07292, 0.07292, 0.27003, 0.20920, 735.74%
Time spent: 24.39s
- Epoch 009, ExpID 24674
Train - Loss (one batch): 0.08128
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07088, 0.07088, 0.26623, 0.21194, 814.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.07292, 0.07292, 0.27003, 0.20920, 735.74%
Time spent: 24.21s
- Epoch 010, ExpID 24674
Train - Loss (one batch): 0.06465
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06840, 0.06840, 0.26153, 0.20602, 769.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.07209, 0.07209, 0.26850, 0.20734, 716.38%
Time spent: 27.63s
- Epoch 011, ExpID 24674
Train - Loss (one batch): 0.07103
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06985, 0.06985, 0.26428, 0.20533, 728.18%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.07209, 0.07209, 0.26850, 0.20734, 716.38%
Time spent: 24.08s
- Epoch 012, ExpID 24674
Train - Loss (one batch): 0.07293
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07029, 0.07029, 0.26513, 0.20689, 760.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.07209, 0.07209, 0.26850, 0.20734, 716.38%
Time spent: 24.54s
- Epoch 013, ExpID 24674
Train - Loss (one batch): 0.06017
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07168, 0.07168, 0.26773, 0.20660, 717.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.07209, 0.07209, 0.26850, 0.20734, 716.38%
Time spent: 24.50s
- Epoch 014, ExpID 24674
Train - Loss (one batch): 0.05931
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06980, 0.06980, 0.26420, 0.20681, 739.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.07209, 0.07209, 0.26850, 0.20734, 716.38%
Time spent: 24.51s
- Epoch 015, ExpID 24674
Train - Loss (one batch): 0.06760
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.20594, 726.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.07209, 0.07209, 0.26850, 0.20734, 716.38%
Time spent: 24.52s
- Epoch 016, ExpID 24674
Train - Loss (one batch): 0.06957
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07038, 0.07038, 0.26528, 0.20501, 729.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.07209, 0.07209, 0.26850, 0.20734, 716.38%
Time spent: 24.28s
- Epoch 017, ExpID 24674
Train - Loss (one batch): 0.07581
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06810, 0.06810, 0.26096, 0.20337, 735.85%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 17, 0.07173, 0.07173, 0.26783, 0.20447, 690.45%
Time spent: 27.84s
- Epoch 018, ExpID 24674
Train - Loss (one batch): 0.07893
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06802, 0.06802, 0.26080, 0.20615, 788.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 27.70s
- Epoch 019, ExpID 24674
Train - Loss (one batch): 0.07558
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07050, 0.07050, 0.26552, 0.20396, 719.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.07s
- Epoch 020, ExpID 24674
Train - Loss (one batch): 0.05817
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07038, 0.07038, 0.26529, 0.20787, 757.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.21s
- Epoch 021, ExpID 24674
Train - Loss (one batch): 0.07266
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06863, 0.06863, 0.26197, 0.20513, 748.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.21s
- Epoch 022, ExpID 24674
Train - Loss (one batch): 0.07462
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06824, 0.06824, 0.26123, 0.20225, 699.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.20s
- Epoch 023, ExpID 24674
Train - Loss (one batch): 0.07251
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06926, 0.06926, 0.26317, 0.20515, 725.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.44s
- Epoch 024, ExpID 24674
Train - Loss (one batch): 0.06945
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07149, 0.07149, 0.26738, 0.20594, 723.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.36s
- Epoch 025, ExpID 24674
Train - Loss (one batch): 0.06774
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07005, 0.07005, 0.26466, 0.19696, 603.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.34s
- Epoch 026, ExpID 24674
Train - Loss (one batch): 0.06959
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06857, 0.06857, 0.26185, 0.20793, 787.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.38s
- Epoch 027, ExpID 24674
Train - Loss (one batch): 0.06341
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06965, 0.06965, 0.26392, 0.20716, 785.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.34s
- Epoch 028, ExpID 24674
Train - Loss (one batch): 0.08460
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07083, 0.07083, 0.26614, 0.20794, 759.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.35s
- Epoch 029, ExpID 24674
Train - Loss (one batch): 0.06290
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07033, 0.07033, 0.26520, 0.20413, 698.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.27s
- Epoch 030, ExpID 24674
Train - Loss (one batch): 0.06827
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26432, 0.21005, 799.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.35s
- Epoch 031, ExpID 24674
Train - Loss (one batch): 0.06168
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06956, 0.06956, 0.26374, 0.20725, 745.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.56s
- Epoch 032, ExpID 24674
Train - Loss (one batch): 0.06995
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07017, 0.07017, 0.26490, 0.20730, 734.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.56s
- Epoch 033, ExpID 24674
Train - Loss (one batch): 0.06659
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07065, 0.07065, 0.26580, 0.20529, 708.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.33s
- Epoch 034, ExpID 24674
Train - Loss (one batch): 0.07732
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06787, 0.06787, 0.26052, 0.20571, 741.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 34, 0.07166, 0.07166, 0.26769, 0.20691, 694.51%
Time spent: 27.97s
- Epoch 035, ExpID 24674
Train - Loss (one batch): 0.05941
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06825, 0.06825, 0.26124, 0.20501, 756.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 34, 0.07166, 0.07166, 0.26769, 0.20691, 694.51%
Time spent: 24.54s
- Epoch 036, ExpID 24674
Train - Loss (one batch): 0.07099
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07087, 0.07087, 0.26622, 0.20875, 737.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 34, 0.07166, 0.07166, 0.26769, 0.20691, 694.51%
Time spent: 24.56s
- Epoch 037, ExpID 24674
Train - Loss (one batch): 0.07112
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06939, 0.06939, 0.26343, 0.20697, 746.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 34, 0.07166, 0.07166, 0.26769, 0.20691, 694.51%
Time spent: 24.41s
- Epoch 038, ExpID 24674
Train - Loss (one batch): 0.07100
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06874, 0.06874, 0.26219, 0.20487, 736.43%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 34, 0.07166, 0.07166, 0.26769, 0.20691, 694.51%
Time spent: 24.35s
- Epoch 039, ExpID 24674
Train - Loss (one batch): 0.07257
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06898, 0.06898, 0.26264, 0.20380, 720.18%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 34, 0.07166, 0.07166, 0.26769, 0.20691, 694.51%
Time spent: 24.49s
- Epoch 040, ExpID 24674
Train - Loss (one batch): 0.05836
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06725, 0.06725, 0.25932, 0.20260, 723.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 27.75s
- Epoch 041, ExpID 24674
Train - Loss (one batch): 0.06394
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07238, 0.07238, 0.26903, 0.20886, 724.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 24.22s
- Epoch 042, ExpID 24674
Train - Loss (one batch): 0.06688
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07255, 0.07255, 0.26936, 0.21054, 785.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 24.11s
- Epoch 043, ExpID 24674
Train - Loss (one batch): 0.07456
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06905, 0.06905, 0.26278, 0.20491, 733.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 24.30s
- Epoch 044, ExpID 24674
Train - Loss (one batch): 0.06585
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06846, 0.06846, 0.26165, 0.20617, 751.03%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 24.50s
- Epoch 045, ExpID 24674
Train - Loss (one batch): 0.05977
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07019, 0.07019, 0.26493, 0.20723, 741.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 25.50s
- Epoch 046, ExpID 24674
Train - Loss (one batch): 0.07441
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07339, 0.07339, 0.27091, 0.20759, 736.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 29.44s
- Epoch 047, ExpID 24674
Train - Loss (one batch): 0.06854
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06887, 0.06887, 0.26242, 0.20302, 706.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 29.57s
- Epoch 048, ExpID 24674
Train - Loss (one batch): 0.06466
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06745, 0.06745, 0.25972, 0.20535, 748.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 29.91s
- Epoch 049, ExpID 24674
Train - Loss (one batch): 0.06955
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07163, 0.07163, 0.26764, 0.20593, 720.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 29.58s
- Epoch 050, ExpID 24674
Train - Loss (one batch): 0.05811
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26435, 0.20565, 729.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 29.69s
- Epoch 051, ExpID 24674
Train - Loss (one batch): 0.07688
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07102, 0.07102, 0.26650, 0.20789, 742.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 29.86s
- Epoch 052, ExpID 24674
Train - Loss (one batch): 0.06665
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07003, 0.07003, 0.26463, 0.20500, 714.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 29.80s
- Epoch 053, ExpID 24674
Train - Loss (one batch): 0.07901
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06930, 0.06930, 0.26324, 0.20719, 756.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 29.70s
- Epoch 054, ExpID 24674
Train - Loss (one batch): 0.06262
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07167, 0.07167, 0.26771, 0.20642, 719.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 29.41s
- Epoch 055, ExpID 24674
Train - Loss (one batch): 0.06977
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06824, 0.06824, 0.26123, 0.20405, 736.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 29.57s
- Epoch 056, ExpID 24674
Train - Loss (one batch): 0.05977
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06721, 0.06721, 0.25925, 0.20210, 730.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 56, 0.07096, 0.07096, 0.26639, 0.20337, 672.92%
Time spent: 54.86s
- Epoch 057, ExpID 24674
Train - Loss (one batch): 0.06199
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06832, 0.06832, 0.26138, 0.20398, 737.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 56, 0.07096, 0.07096, 0.26639, 0.20337, 672.92%
Time spent: 47.39s
- Epoch 058, ExpID 24674
Train - Loss (one batch): 0.06189
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07161, 0.07161, 0.26761, 0.20880, 742.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 56, 0.07096, 0.07096, 0.26639, 0.20337, 672.92%
Time spent: 48.19s
- Epoch 059, ExpID 24674
Train - Loss (one batch): 0.06608
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06712, 0.06712, 0.25907, 0.20363, 734.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 59, 0.07105, 0.07105, 0.26655, 0.20532, 689.97%
Time spent: 57.46s
- Epoch 060, ExpID 24674
Train - Loss (one batch): 0.05894
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25875, 0.20192, 718.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 56.30s
- Epoch 061, ExpID 24674
Train - Loss (one batch): 0.06864
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25887, 0.20190, 724.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 47.90s
- Epoch 062, ExpID 24674
Train - Loss (one batch): 0.05908
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06911, 0.06911, 0.26290, 0.20640, 754.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 48.11s
- Epoch 063, ExpID 24674
Train - Loss (one batch): 0.07260
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07102, 0.07102, 0.26650, 0.20721, 728.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 48.86s
- Epoch 064, ExpID 24674
Train - Loss (one batch): 0.06631
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07097, 0.07097, 0.26640, 0.20806, 735.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 49.02s
- Epoch 065, ExpID 24674
Train - Loss (one batch): 0.07475
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07082, 0.07082, 0.26611, 0.20821, 754.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 49.11s
- Epoch 066, ExpID 24674
Train - Loss (one batch): 0.07716
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06900, 0.06900, 0.26267, 0.20727, 759.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 49.46s
- Epoch 067, ExpID 24674
Train - Loss (one batch): 0.06560
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07096, 0.07096, 0.26638, 0.20762, 730.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 48.24s
- Epoch 068, ExpID 24674
Train - Loss (one batch): 0.07008
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07043, 0.07043, 0.26539, 0.20820, 752.02%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 47.94s
- Epoch 069, ExpID 24674
Train - Loss (one batch): 0.06197
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07034, 0.07034, 0.26522, 0.20641, 723.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 48.47s
- Epoch 070, ExpID 24674
Train - Loss (one batch): 0.06212
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06809, 0.06809, 0.26095, 0.20332, 724.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 49.13s
- Epoch 071, ExpID 24674
Train - Loss (one batch): 0.06788
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06947, 0.06947, 0.26357, 0.20700, 758.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 49.33s
- Epoch 072, ExpID 24674
Train - Loss (one batch): 0.06359
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06882, 0.06882, 0.26233, 0.20643, 747.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 49.24s
- Epoch 073, ExpID 24674
Train - Loss (one batch): 0.06170
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06966, 0.06966, 0.26393, 0.20596, 743.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 49.73s
- Epoch 074, ExpID 24674
Train - Loss (one batch): 0.07616
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06912, 0.06912, 0.26291, 0.20539, 733.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 48.16s
- Epoch 075, ExpID 24674
Train - Loss (one batch): 0.06065
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06978, 0.06978, 0.26416, 0.20530, 725.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 48.08s
- Epoch 076, ExpID 24674
Train - Loss (one batch): 0.07390
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07246, 0.07246, 0.26918, 0.20656, 705.62%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 48.42s
- Epoch 077, ExpID 24674
Train - Loss (one batch): 0.07317
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07027, 0.07027, 0.26508, 0.20675, 740.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 49.07s
- Epoch 078, ExpID 24674
Train - Loss (one batch): 0.06805
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26049, 0.20408, 750.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 51.26s
- Epoch 079, ExpID 24674
Train - Loss (one batch): 0.06780
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06999, 0.06999, 0.26456, 0.20513, 706.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 49.94s
- Epoch 080, ExpID 24674
Train - Loss (one batch): 0.06364
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06875, 0.06875, 0.26221, 0.20351, 712.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 49.47s
- Epoch 081, ExpID 24674
Train - Loss (one batch): 0.07108
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06943, 0.06943, 0.26350, 0.20615, 763.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 48.22s
- Epoch 082, ExpID 24674
Train - Loss (one batch): 0.07260
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06870, 0.06870, 0.26210, 0.20379, 717.48%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 42.62s
- Epoch 083, ExpID 24674
Train - Loss (one batch): 0.07205
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07165, 0.07165, 0.26767, 0.20743, 726.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 29.39s
- Epoch 084, ExpID 24674
Train - Loss (one batch): 0.06168
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07004, 0.07004, 0.26466, 0.20482, 714.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 29.81s
- Epoch 085, ExpID 24674
Train - Loss (one batch): 0.06253
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07020, 0.07020, 0.26496, 0.20400, 704.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 29.68s
- Epoch 086, ExpID 24674
Train - Loss (one batch): 0.07543
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06729, 0.06729, 0.25941, 0.20510, 777.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 29.85s
- Epoch 087, ExpID 24674
Train - Loss (one batch): 0.06395
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06942, 0.06942, 0.26349, 0.20463, 735.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 29.94s
- Epoch 088, ExpID 24674
Train - Loss (one batch): 0.06442
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06895, 0.06895, 0.26259, 0.20346, 716.85%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 29.93s
- Epoch 089, ExpID 24674
Train - Loss (one batch): 0.06670
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07094, 0.07094, 0.26634, 0.20590, 700.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 29.99s
- Epoch 090, ExpID 24674
Train - Loss (one batch): 0.05878
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06717, 0.06717, 0.25917, 0.20357, 743.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 29.68s
- Epoch 091, ExpID 24674
Train - Loss (one batch): 0.08138
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06606, 0.06606, 0.25702, 0.20122, 726.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 91, 0.06995, 0.06995, 0.26449, 0.20270, 666.94%
Time spent: 34.17s
- Epoch 092, ExpID 24674
Train - Loss (one batch): 0.06650
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07069, 0.07069, 0.26588, 0.20639, 733.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 91, 0.06995, 0.06995, 0.26449, 0.20270, 666.94%
Time spent: 29.76s
- Epoch 093, ExpID 24674
Train - Loss (one batch): 0.06686
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07269, 0.07269, 0.26962, 0.20851, 721.83%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 91, 0.06995, 0.06995, 0.26449, 0.20270, 666.94%
Time spent: 41.96s
- Epoch 094, ExpID 24674
Train - Loss (one batch): 0.06146
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06867, 0.06867, 0.26205, 0.20274, 716.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 91, 0.06995, 0.06995, 0.26449, 0.20270, 666.94%
Time spent: 42.29s
- Epoch 095, ExpID 24674
Train - Loss (one batch): 0.05020
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06991, 0.06991, 0.26440, 0.20680, 725.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 91, 0.06995, 0.06995, 0.26449, 0.20270, 666.94%
Time spent: 42.27s
- Epoch 096, ExpID 24674
Train - Loss (one batch): 0.06554
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06736, 0.06736, 0.25954, 0.20313, 733.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 91, 0.06995, 0.06995, 0.26449, 0.20270, 666.94%
Time spent: 42.72s
- Epoch 097, ExpID 24674
Train - Loss (one batch): 0.05954
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07079, 0.07079, 0.26606, 0.20632, 721.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 91, 0.06995, 0.06995, 0.26449, 0.20270, 666.94%
Time spent: 43.20s
- Epoch 098, ExpID 24674
Train - Loss (one batch): 0.06317
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06776, 0.06776, 0.26031, 0.20220, 716.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 91, 0.06995, 0.06995, 0.26449, 0.20270, 666.94%
Time spent: 42.92s
- Epoch 099, ExpID 24674
Train - Loss (one batch): 0.06908
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06888, 0.06888, 0.26244, 0.20435, 726.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 91, 0.06995, 0.06995, 0.26449, 0.20270, 666.94%
Time spent: 43.16s
