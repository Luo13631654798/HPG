/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_baselines.py
2024-07-19 10:19:41
run_baselines.py
Namespace(state='def', n=100000000, epoch=100, patience=10, history=3000, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='physionet', quantization=0.0, model='iTransformer', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=24, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='0', seq_len=96, top_k=5, num_kernels=64, npatch=125, device=device(type='cuda', index=0), PID=1768426, pred_window=-2952, ndim=41, patch_layer=8, task_name='long_term_forecast', pred_len=720, output_attention=None, d_model=512, embed='timeF', freq='h', dropout=0.1, factor=3, d_ff=512, e_layers=4, n_heads=1, activation='gelu')
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_baselines.py
2024-07-19 10:22:02
run_baselines.py
Namespace(state='def', n=100000000, epoch=100, patience=10, history=24, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='physionet', quantization=0.0, model='iTransformer', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=24, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='0', seq_len=128, top_k=5, num_kernels=64, npatch=1, device=device(type='cuda', index=0), PID=1770079, pred_window=24, ndim=41, patch_layer=1, task_name='long_term_forecast', pred_len=720, output_attention=None, d_model=512, embed='timeF', freq='h', dropout=0.1, factor=3, d_ff=512, e_layers=4, n_heads=1, activation='gelu')
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_iTransformer.py
2024-07-19 13:35:15
run_iTransformer.py --history 24 --model iTransformer --dataset physionet --gpu 1
Namespace(state='def', n=100000000, epoch=50, patience=10, history=24, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='physionet', quantization=0.0, model='iTransformer', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=24, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='1', seq_len=128, top_k=5, num_kernels=64, npatch=1, device=device(type='cuda', index=0), PID=1884609, pred_window=24, ndim=41, patch_layer=1, task_name='long_term_forecast', pred_len=720, output_attention=None, d_model=512, embed='timeF', freq='h', dropout=0.1, factor=3, d_ff=512, e_layers=4, n_heads=1, activation='gelu')
- Epoch 000, ExpID 21738
Train - Loss (one batch): 0.05889
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05891, 0.05891, 0.24272, 0.17080, 776.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05753, 0.05753, 0.23985, 0.16830, 802.99%
Time spent: 33.21s
- Epoch 001, ExpID 21738
Train - Loss (one batch): 0.04930
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05469, 0.05469, 0.23385, 0.17467, 1034.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 29.28s
- Epoch 002, ExpID 21738
Train - Loss (one batch): 0.06449
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06567, 0.06567, 0.25625, 0.19720, 1604.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 27.21s
- Epoch 003, ExpID 21738
Train - Loss (one batch): 0.06750
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06549, 0.06549, 0.25591, 0.19254, 1645.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 26.17s
- Epoch 004, ExpID 21738
Train - Loss (one batch): 0.06648
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06594, 0.06594, 0.25678, 0.20056, 1789.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 27.14s
- Epoch 005, ExpID 21738
Train - Loss (one batch): 0.06880
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06571, 0.06571, 0.25633, 0.19374, 1623.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 26.02s
- Epoch 006, ExpID 21738
Train - Loss (one batch): 0.07031
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06534, 0.06534, 0.25561, 0.19483, 1746.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 25.80s
- Epoch 007, ExpID 21738
Train - Loss (one batch): 0.06909
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06758, 0.06758, 0.25996, 0.19695, 1747.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 25.07s
- Epoch 008, ExpID 21738
Train - Loss (one batch): 0.06600
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06654, 0.06654, 0.25796, 0.19718, 1744.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 27.49s
- Epoch 009, ExpID 21738
Train - Loss (one batch): 0.06595
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06677, 0.06677, 0.25839, 0.19821, 1845.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 24.57s
- Epoch 010, ExpID 21738
Train - Loss (one batch): 0.06434
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06630, 0.06630, 0.25748, 0.19714, 1781.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 27.33s
- Epoch 011, ExpID 21738
Train - Loss (one batch): 0.06706
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06810, 0.06810, 0.26095, 0.20130, 1997.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 25.95s
- Epoch 012, ExpID 21738
Train - Loss (one batch): 0.06955
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06795, 0.06795, 0.26067, 0.20153, 2017.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 27.27s
- Epoch 013, ExpID 21738
Train - Loss (one batch): 0.06856
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06791, 0.06791, 0.26060, 0.20198, 2043.48%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 26.08s
- Epoch 014, ExpID 21738
Train - Loss (one batch): 0.06750
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06796, 0.06796, 0.26069, 0.20304, 2093.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 25.91s
- Epoch 015, ExpID 21738
Train - Loss (one batch): 0.06659
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06664, 0.06664, 0.25815, 0.19788, 1826.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 26.64s
- Epoch 016, ExpID 21738
Train - Loss (one batch): 0.06832
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26062, 0.20253, 2069.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 25.27s
- Epoch 017, ExpID 21738
Train - Loss (one batch): 0.06533
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06783, 0.06783, 0.26044, 0.20292, 2083.57%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 26.80s
- Epoch 018, ExpID 21738
Train - Loss (one batch): 0.06572
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06783, 0.06783, 0.26045, 0.19877, 1832.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 25.06s
- Epoch 019, ExpID 21738
Train - Loss (one batch): 0.06614
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06802, 0.06802, 0.26080, 0.20209, 2045.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 27.22s
- Epoch 020, ExpID 21738
Train - Loss (one batch): 0.06642
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26061, 0.20310, 2104.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 25.89s
- Epoch 021, ExpID 21738
Train - Loss (one batch): 0.06484
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26061, 0.20233, 2060.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 27.49s
- Epoch 022, ExpID 21738
Train - Loss (one batch): 0.06988
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06804, 0.06804, 0.26084, 0.20189, 2025.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 25.70s
- Epoch 023, ExpID 21738
Train - Loss (one batch): 0.07003
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06822, 0.06822, 0.26120, 0.20060, 1947.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 27.67s
- Epoch 024, ExpID 21738
Train - Loss (one batch): 0.07234
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06796, 0.06796, 0.26070, 0.20317, 2098.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 25.84s
- Epoch 025, ExpID 21738
Train - Loss (one batch): 0.06567
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06803, 0.06803, 0.26083, 0.20364, 2115.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 26.51s
- Epoch 026, ExpID 21738
Train - Loss (one batch): 0.06979
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06796, 0.06796, 0.26068, 0.20277, 2080.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 25.97s
- Epoch 027, ExpID 21738
Train - Loss (one batch): 0.06808
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26062, 0.20183, 2036.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 25.75s
- Epoch 028, ExpID 21738
Train - Loss (one batch): 0.06918
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06794, 0.06794, 0.26066, 0.20273, 2077.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 26.36s
- Epoch 029, ExpID 21738
Train - Loss (one batch): 0.06411
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06819, 0.06819, 0.26113, 0.19969, 1903.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 25.52s
- Epoch 030, ExpID 21738
Train - Loss (one batch): 0.07028
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06793, 0.06793, 0.26064, 0.20165, 2026.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 27.42s
- Epoch 031, ExpID 21738
Train - Loss (one batch): 0.06664
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06819, 0.06819, 0.26113, 0.20511, 2181.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 24.88s
- Epoch 032, ExpID 21738
Train - Loss (one batch): 0.06833
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06793, 0.06793, 0.26063, 0.20165, 2025.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 27.41s
- Epoch 033, ExpID 21738
Train - Loss (one batch): 0.06997
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06797, 0.06797, 0.26072, 0.20103, 1990.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 26.12s
- Epoch 034, ExpID 21738
Train - Loss (one batch): 0.06703
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06796, 0.06796, 0.26069, 0.20137, 2009.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 27.23s
- Epoch 035, ExpID 21738
Train - Loss (one batch): 0.06579
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06799, 0.06799, 0.26075, 0.20223, 2047.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 25.70s
- Epoch 036, ExpID 21738
Train - Loss (one batch): 0.06728
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06791, 0.06791, 0.26059, 0.20074, 1978.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 27.47s
- Epoch 037, ExpID 21738
Train - Loss (one batch): 0.07054
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26061, 0.20232, 2060.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 25.83s
- Epoch 038, ExpID 21738
Train - Loss (one batch): 0.06898
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06794, 0.06794, 0.26065, 0.20142, 2014.03%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 26.71s
- Epoch 039, ExpID 21738
Train - Loss (one batch): 0.06881
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06793, 0.06793, 0.26063, 0.20169, 2028.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 26.48s
- Epoch 040, ExpID 21738
Train - Loss (one batch): 0.06739
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06805, 0.06805, 0.26086, 0.20044, 1957.35%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 25.55s
- Epoch 041, ExpID 21738
Train - Loss (one batch): 0.07152
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06793, 0.06793, 0.26064, 0.20135, 2011.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 27.75s
- Epoch 042, ExpID 21738
Train - Loss (one batch): 0.06904
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26062, 0.20122, 2005.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 25.99s
- Epoch 043, ExpID 21738
Train - Loss (one batch): 0.06836
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06800, 0.06800, 0.26077, 0.20067, 1972.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 28.13s
- Epoch 044, ExpID 21738
Train - Loss (one batch): 0.06728
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06789, 0.06789, 0.26056, 0.20178, 2035.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 25.13s
- Epoch 045, ExpID 21738
Train - Loss (one batch): 0.06799
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06795, 0.06795, 0.26066, 0.20245, 2065.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 27.42s
- Epoch 046, ExpID 21738
Train - Loss (one batch): 0.07278
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06790, 0.06790, 0.26057, 0.20106, 1999.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 26.11s
- Epoch 047, ExpID 21738
Train - Loss (one batch): 0.06941
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06797, 0.06797, 0.26071, 0.20074, 1977.35%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 27.32s
- Epoch 048, ExpID 21738
Train - Loss (one batch): 0.06872
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26048, 0.20154, 2026.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 25.69s
- Epoch 049, ExpID 21738
Train - Loss (one batch): 0.07162
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06797, 0.06797, 0.26071, 0.20086, 1984.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 27.28s
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_iTransformer.py
2024-07-19 14:02:31
run_iTransformer.py --history 36 --model iTransformer --dataset physionet --gpu 1
Namespace(state='def', n=100000000, epoch=50, patience=10, history=36, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='physionet', quantization=0.0, model='iTransformer', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=24, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='1', seq_len=175, top_k=5, num_kernels=64, npatch=2, device=device(type='cuda', index=0), PID=1900663, pred_window=12, ndim=41, patch_layer=2, task_name='long_term_forecast', pred_len=720, output_attention=None, d_model=512, embed='timeF', freq='h', dropout=0.1, factor=3, d_ff=512, e_layers=4, n_heads=1, activation='gelu')
- Epoch 000, ExpID 74440
Train - Loss (one batch): 0.06178
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05632, 0.05632, 0.23733, 0.17677, 1194.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 28.96s
- Epoch 001, ExpID 74440
Train - Loss (one batch): 0.06608
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06615, 0.06615, 0.25720, 0.19722, 1968.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 22.08s
- Epoch 002, ExpID 74440
Train - Loss (one batch): 0.07109
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06439, 0.06439, 0.25376, 0.19452, 1836.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 23.74s
- Epoch 003, ExpID 74440
Train - Loss (one batch): 0.06078
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06404, 0.06404, 0.25307, 0.19750, 1897.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 21.40s
- Epoch 004, ExpID 74440
Train - Loss (one batch): 0.06460
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06567, 0.06567, 0.25627, 0.20304, 2087.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 23.49s
- Epoch 005, ExpID 74440
Train - Loss (one batch): 0.06280
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06474, 0.06474, 0.25444, 0.19383, 1694.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 21.89s
- Epoch 006, ExpID 74440
Train - Loss (one batch): 0.06958
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06514, 0.06514, 0.25523, 0.20051, 2028.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 23.20s
- Epoch 007, ExpID 74440
Train - Loss (one batch): 0.06723
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06495, 0.06495, 0.25486, 0.19568, 1832.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 22.40s
- Epoch 008, ExpID 74440
Train - Loss (one batch): 0.06212
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06510, 0.06510, 0.25515, 0.19420, 1798.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 22.48s
- Epoch 009, ExpID 74440
Train - Loss (one batch): 0.06473
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06521, 0.06521, 0.25536, 0.19827, 1966.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 22.75s
- Epoch 010, ExpID 74440
Train - Loss (one batch): 0.07069
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06622, 0.06622, 0.25733, 0.20315, 2083.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 21.88s
- Epoch 011, ExpID 74440
Train - Loss (one batch): 0.06676
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06543, 0.06543, 0.25579, 0.19894, 2006.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 23.54s
- Epoch 012, ExpID 74440
Train - Loss (one batch): 0.07220
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06533, 0.06533, 0.25561, 0.19828, 1955.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 21.31s
- Epoch 013, ExpID 74440
Train - Loss (one batch): 0.06813
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06528, 0.06528, 0.25549, 0.19533, 1843.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 10.54s
- Epoch 014, ExpID 74440
Train - Loss (one batch): 0.06235
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06525, 0.06525, 0.25545, 0.19651, 1844.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.31s
- Epoch 015, ExpID 74440
Train - Loss (one batch): 0.06898
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06747, 0.06747, 0.25974, 0.20453, 2321.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.25s
- Epoch 016, ExpID 74440
Train - Loss (one batch): 0.06699
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06750, 0.06750, 0.25980, 0.20468, 2326.10%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.37s
- Epoch 017, ExpID 74440
Train - Loss (one batch): 0.06884
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06718, 0.06718, 0.25918, 0.20286, 2255.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.32s
- Epoch 018, ExpID 74440
Train - Loss (one batch): 0.07004
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06702, 0.06702, 0.25889, 0.20157, 2200.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.35s
- Epoch 019, ExpID 74440
Train - Loss (one batch): 0.07290
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06714, 0.06714, 0.25911, 0.20259, 2244.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.42s
- Epoch 020, ExpID 74440
Train - Loss (one batch): 0.07155
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06709, 0.06709, 0.25901, 0.20216, 2226.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.37s
- Epoch 021, ExpID 74440
Train - Loss (one batch): 0.07877
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06700, 0.06700, 0.25884, 0.19892, 2064.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.42s
- Epoch 022, ExpID 74440
Train - Loss (one batch): 0.06762
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06711, 0.06711, 0.25905, 0.19819, 2017.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.47s
- Epoch 023, ExpID 74440
Train - Loss (one batch): 0.07419
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06718, 0.06718, 0.25919, 0.20285, 2255.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.99s
- Epoch 024, ExpID 74440
Train - Loss (one batch): 0.06505
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25874, 0.19979, 2114.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 12.14s
- Epoch 025, ExpID 74440
Train - Loss (one batch): 0.06837
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26051, 0.20629, 2384.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.77s
- Epoch 026, ExpID 74440
Train - Loss (one batch): 0.06748
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06728, 0.06728, 0.25939, 0.20353, 2282.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.59s
- Epoch 027, ExpID 74440
Train - Loss (one batch): 0.06469
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06704, 0.06704, 0.25891, 0.20172, 2207.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.52s
- Epoch 028, ExpID 74440
Train - Loss (one batch): 0.07215
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06721, 0.06721, 0.25926, 0.20312, 2266.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.93s
- Epoch 029, ExpID 74440
Train - Loss (one batch): 0.06355
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06697, 0.06697, 0.25879, 0.19933, 2087.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.65s
- Epoch 030, ExpID 74440
Train - Loss (one batch): 0.06764
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25887, 0.19879, 2056.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.28s
- Epoch 031, ExpID 74440
Train - Loss (one batch): 0.06574
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25877, 0.20074, 2162.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.50s
- Epoch 032, ExpID 74440
Train - Loss (one batch): 0.06870
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25877, 0.19946, 2095.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.26s
- Epoch 033, ExpID 74440
Train - Loss (one batch): 0.07272
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25887, 0.19879, 2056.35%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.19s
- Epoch 034, ExpID 74440
Train - Loss (one batch): 0.06998
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06702, 0.06702, 0.25889, 0.20157, 2200.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.18s
- Epoch 035, ExpID 74440
Train - Loss (one batch): 0.06546
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25875, 0.19961, 2103.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.16s
- Epoch 036, ExpID 74440
Train - Loss (one batch): 0.06977
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25875, 0.20036, 2143.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.16s
- Epoch 037, ExpID 74440
Train - Loss (one batch): 0.07140
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06758, 0.06758, 0.25997, 0.20507, 2340.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.23s
- Epoch 038, ExpID 74440
Train - Loss (one batch): 0.06590
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06703, 0.06703, 0.25890, 0.20163, 2202.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.14s
- Epoch 039, ExpID 74440
Train - Loss (one batch): 0.07359
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06698, 0.06698, 0.25881, 0.19911, 2075.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.18s
- Epoch 040, ExpID 74440
Train - Loss (one batch): 0.06896
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06698, 0.06698, 0.25881, 0.20108, 2178.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.62s
- Epoch 041, ExpID 74440
Train - Loss (one batch): 0.06883
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25876, 0.20065, 2157.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.59s
- Epoch 042, ExpID 74440
Train - Loss (one batch): 0.06573
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06694, 0.06694, 0.25873, 0.19986, 2118.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.62s
- Epoch 043, ExpID 74440
Train - Loss (one batch): 0.06978
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06711, 0.06711, 0.25905, 0.20238, 2235.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.43s
- Epoch 044, ExpID 74440
Train - Loss (one batch): 0.07117
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25874, 0.20017, 2133.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.57s
- Epoch 045, ExpID 74440
Train - Loss (one batch): 0.06499
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25874, 0.20022, 2136.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.44s
- Epoch 046, ExpID 74440
Train - Loss (one batch): 0.07159
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06699, 0.06699, 0.25883, 0.20138, 2196.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.46s
- Epoch 047, ExpID 74440
Train - Loss (one batch): 0.06931
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25874, 0.20017, 2133.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.66s
- Epoch 048, ExpID 74440
Train - Loss (one batch): 0.07037
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25885, 0.20139, 2192.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.59s
- Epoch 049, ExpID 74440
Train - Loss (one batch): 0.06570
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06698, 0.06698, 0.25880, 0.20101, 2175.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.76s
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_iTransformer.py
2024-07-19 14:16:03
run_iTransformer.py --history 12 --model iTransformer --dataset physionet --gpu 1
Namespace(state='def', n=100000000, epoch=50, patience=10, history=12, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='physionet', quantization=0.0, model='iTransformer', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=24, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='1', seq_len=83, top_k=5, num_kernels=64, npatch=1, device=device(type='cuda', index=0), PID=1910472, pred_window=36, ndim=41, patch_layer=1, task_name='long_term_forecast', pred_len=720, output_attention=None, d_model=512, embed='timeF', freq='h', dropout=0.1, factor=3, d_ff=512, e_layers=4, n_heads=1, activation='gelu')
- Epoch 000, ExpID 43210
Train - Loss (one batch): 0.05369
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05880, 0.05880, 0.24249, 0.17889, 1149.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 23.08s
- Epoch 001, ExpID 43210
Train - Loss (one batch): 0.06510
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06257, 0.06257, 0.25014, 0.19167, 1451.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.66s
- Epoch 002, ExpID 43210
Train - Loss (one batch): 0.06894
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06673, 0.06673, 0.25832, 0.20174, 1979.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.64s
- Epoch 003, ExpID 43210
Train - Loss (one batch): 0.06858
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06620, 0.06620, 0.25730, 0.19676, 1836.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.59s
- Epoch 004, ExpID 43210
Train - Loss (one batch): 0.06491
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06634, 0.06634, 0.25756, 0.19671, 1812.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.72s
- Epoch 005, ExpID 43210
Train - Loss (one batch): 0.06192
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06611, 0.06611, 0.25712, 0.20081, 1979.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.79s
- Epoch 006, ExpID 43210
Train - Loss (one batch): 0.06888
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06689, 0.06689, 0.25863, 0.20563, 2046.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.73s
- Epoch 007, ExpID 43210
Train - Loss (one batch): 0.06477
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06674, 0.06674, 0.25833, 0.20485, 2025.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.75s
- Epoch 008, ExpID 43210
Train - Loss (one batch): 0.06086
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06598, 0.06598, 0.25686, 0.19837, 1820.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.85s
- Epoch 009, ExpID 43210
Train - Loss (one batch): 0.06606
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06613, 0.06613, 0.25716, 0.19912, 1896.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.54s
- Epoch 010, ExpID 43210
Train - Loss (one batch): 0.06846
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06602, 0.06602, 0.25695, 0.19788, 1843.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.70s
- Epoch 011, ExpID 43210
Train - Loss (one batch): 0.06633
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06765, 0.06765, 0.26010, 0.20083, 2070.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.59s
- Epoch 012, ExpID 43210
Train - Loss (one batch): 0.06593
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06623, 0.06623, 0.25736, 0.19980, 1918.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.65s
- Epoch 013, ExpID 43210
Train - Loss (one batch): 0.06520
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06620, 0.06620, 0.25729, 0.19669, 1774.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.54s
- Epoch 014, ExpID 43210
Train - Loss (one batch): 0.06535
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06631, 0.06631, 0.25751, 0.20054, 1909.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.53s
- Epoch 015, ExpID 43210
Train - Loss (one batch): 0.06998
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06623, 0.06623, 0.25734, 0.19721, 1759.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.56s
- Epoch 016, ExpID 43210
Train - Loss (one batch): 0.06611
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06620, 0.06620, 0.25730, 0.19887, 1901.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.71s
- Epoch 017, ExpID 43210
Train - Loss (one batch): 0.06587
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06746, 0.06746, 0.25973, 0.20542, 2212.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.65s
- Epoch 018, ExpID 43210
Train - Loss (one batch): 0.06538
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06647, 0.06647, 0.25782, 0.19707, 1757.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.67s
- Epoch 019, ExpID 43210
Train - Loss (one batch): 0.07158
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06778, 0.06778, 0.26034, 0.20095, 2073.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.66s
- Epoch 020, ExpID 43210
Train - Loss (one batch): 0.06475
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06649, 0.06649, 0.25785, 0.19680, 1750.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.61s
- Epoch 021, ExpID 43210
Train - Loss (one batch): 0.06933
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06660, 0.06660, 0.25807, 0.19607, 1735.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.55s
- Epoch 022, ExpID 43210
Train - Loss (one batch): 0.06701
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06650, 0.06650, 0.25787, 0.19739, 1836.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.77s
- Epoch 023, ExpID 43210
Train - Loss (one batch): 0.06851
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06665, 0.06665, 0.25817, 0.19679, 1805.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.66s
- Epoch 024, ExpID 43210
Train - Loss (one batch): 0.06257
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06654, 0.06654, 0.25796, 0.19659, 1754.03%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.57s
- Epoch 025, ExpID 43210
Train - Loss (one batch): 0.06649
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06773, 0.06773, 0.26025, 0.20159, 2111.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.67s
- Epoch 026, ExpID 43210
Train - Loss (one batch): 0.06714
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06772, 0.06772, 0.26024, 0.20182, 2124.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.80s
- Epoch 027, ExpID 43210
Train - Loss (one batch): 0.07061
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06777, 0.06777, 0.26033, 0.20192, 2125.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.66s
- Epoch 028, ExpID 43210
Train - Loss (one batch): 0.06665
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06771, 0.06771, 0.26021, 0.20179, 2123.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.65s
- Epoch 029, ExpID 43210
Train - Loss (one batch): 0.06924
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06770, 0.06770, 0.26019, 0.20217, 2143.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 19.74s
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_iTransformer.py
2024-07-19 14:32:37
run_iTransformer.py --history 24 --model iTransformer --dataset physionet
Namespace(state='def', n=100000000, epoch=100, patience=10, history=24, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='physionet', quantization=0.0, model='iTransformer', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=24, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='0', seq_len=128, top_k=5, num_kernels=64, npatch=1, device=device(type='cuda', index=0), PID=1920382, pred_window=24, ndim=41, patch_layer=1, task_name='long_term_forecast', pred_len=720, output_attention=None, d_model=512, embed='timeF', freq='h', dropout=0.1, factor=3, d_ff=512, e_layers=4, n_heads=1, activation='gelu')
- Epoch 000, ExpID 9942
Train - Loss (one batch): 0.05889
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05891, 0.05891, 0.24272, 0.17080, 776.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05753, 0.05753, 0.23985, 0.16830, 802.99%
Time spent: 18.05s
- Epoch 001, ExpID 9942
Train - Loss (one batch): 0.04930
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05469, 0.05469, 0.23385, 0.17467, 1034.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 17.40s
- Epoch 002, ExpID 9942
Train - Loss (one batch): 0.06449
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06567, 0.06567, 0.25625, 0.19720, 1604.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.18s
- Epoch 003, ExpID 9942
Train - Loss (one batch): 0.06750
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06549, 0.06549, 0.25591, 0.19254, 1645.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.31s
- Epoch 004, ExpID 9942
Train - Loss (one batch): 0.06648
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06594, 0.06594, 0.25678, 0.20056, 1789.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.39s
- Epoch 005, ExpID 9942
Train - Loss (one batch): 0.06880
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06571, 0.06571, 0.25633, 0.19374, 1623.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.67s
- Epoch 006, ExpID 9942
Train - Loss (one batch): 0.07031
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06534, 0.06534, 0.25561, 0.19483, 1746.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.65s
- Epoch 007, ExpID 9942
Train - Loss (one batch): 0.06909
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06758, 0.06758, 0.25996, 0.19695, 1747.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.72s
- Epoch 008, ExpID 9942
Train - Loss (one batch): 0.06600
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06654, 0.06654, 0.25796, 0.19718, 1744.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.75s
- Epoch 009, ExpID 9942
Train - Loss (one batch): 0.06595
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06677, 0.06677, 0.25839, 0.19821, 1845.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.43s
- Epoch 010, ExpID 9942
Train - Loss (one batch): 0.06434
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06630, 0.06630, 0.25748, 0.19714, 1781.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.54s
- Epoch 011, ExpID 9942
Train - Loss (one batch): 0.06706
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06810, 0.06810, 0.26095, 0.20130, 1997.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.41s
- Epoch 012, ExpID 9942
Train - Loss (one batch): 0.06955
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06795, 0.06795, 0.26067, 0.20153, 2017.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.33s
- Epoch 013, ExpID 9942
Train - Loss (one batch): 0.06856
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06791, 0.06791, 0.26060, 0.20198, 2043.48%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.40s
- Epoch 014, ExpID 9942
Train - Loss (one batch): 0.06750
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06796, 0.06796, 0.26069, 0.20304, 2093.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.51s
- Epoch 015, ExpID 9942
Train - Loss (one batch): 0.06659
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06664, 0.06664, 0.25815, 0.19788, 1826.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.42s
- Epoch 016, ExpID 9942
Train - Loss (one batch): 0.06832
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26062, 0.20253, 2069.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.63s
- Epoch 017, ExpID 9942
Train - Loss (one batch): 0.06533
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06783, 0.06783, 0.26044, 0.20292, 2083.57%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.57s
- Epoch 018, ExpID 9942
Train - Loss (one batch): 0.06572
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06783, 0.06783, 0.26045, 0.19877, 1832.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.71s
- Epoch 019, ExpID 9942
Train - Loss (one batch): 0.06614
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06802, 0.06802, 0.26080, 0.20209, 2045.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.50s
- Epoch 020, ExpID 9942
Train - Loss (one batch): 0.06642
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26061, 0.20310, 2104.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.49s
- Epoch 021, ExpID 9942
Train - Loss (one batch): 0.06484
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26061, 0.20233, 2060.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.48s
- Epoch 022, ExpID 9942
Train - Loss (one batch): 0.06988
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06804, 0.06804, 0.26084, 0.20189, 2025.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.65s
- Epoch 023, ExpID 9942
Train - Loss (one batch): 0.07003
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06822, 0.06822, 0.26120, 0.20060, 1947.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.79s
- Epoch 024, ExpID 9942
Train - Loss (one batch): 0.07234
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06796, 0.06796, 0.26070, 0.20317, 2098.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.61s
- Epoch 025, ExpID 9942
Train - Loss (one batch): 0.06567
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06803, 0.06803, 0.26083, 0.20364, 2115.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.44s
- Epoch 026, ExpID 9942
Train - Loss (one batch): 0.06979
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06796, 0.06796, 0.26068, 0.20277, 2080.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.59s
- Epoch 027, ExpID 9942
Train - Loss (one batch): 0.06808
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26062, 0.20183, 2036.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.59s
- Epoch 028, ExpID 9942
Train - Loss (one batch): 0.06918
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06794, 0.06794, 0.26066, 0.20273, 2077.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.36s
- Epoch 029, ExpID 9942
Train - Loss (one batch): 0.06411
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06819, 0.06819, 0.26113, 0.19969, 1903.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.34s
- Epoch 030, ExpID 9942
Train - Loss (one batch): 0.07028
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06793, 0.06793, 0.26064, 0.20165, 2026.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.68s
- Epoch 031, ExpID 9942
Train - Loss (one batch): 0.06664
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06819, 0.06819, 0.26113, 0.20511, 2181.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.52s
- Epoch 032, ExpID 9942
Train - Loss (one batch): 0.06833
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06793, 0.06793, 0.26063, 0.20165, 2025.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.58s
- Epoch 033, ExpID 9942
Train - Loss (one batch): 0.06997
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06797, 0.06797, 0.26072, 0.20103, 1990.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.30s
- Epoch 034, ExpID 9942
Train - Loss (one batch): 0.06703
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06796, 0.06796, 0.26069, 0.20137, 2009.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.70s
- Epoch 035, ExpID 9942
Train - Loss (one batch): 0.06579
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06799, 0.06799, 0.26075, 0.20223, 2047.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.35s
- Epoch 036, ExpID 9942
Train - Loss (one batch): 0.06728
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06791, 0.06791, 0.26059, 0.20074, 1978.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.29s
- Epoch 037, ExpID 9942
Train - Loss (one batch): 0.07054
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26061, 0.20232, 2060.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.25s
- Epoch 038, ExpID 9942
Train - Loss (one batch): 0.06898
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06794, 0.06794, 0.26065, 0.20142, 2014.03%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.27s
- Epoch 039, ExpID 9942
Train - Loss (one batch): 0.06881
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06793, 0.06793, 0.26063, 0.20169, 2028.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.27s
- Epoch 040, ExpID 9942
Train - Loss (one batch): 0.06739
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06805, 0.06805, 0.26086, 0.20044, 1957.35%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.18s
- Epoch 041, ExpID 9942
Train - Loss (one batch): 0.07152
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06793, 0.06793, 0.26064, 0.20135, 2011.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.67s
- Epoch 042, ExpID 9942
Train - Loss (one batch): 0.06904
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26062, 0.20122, 2005.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.69s
- Epoch 043, ExpID 9942
Train - Loss (one batch): 0.06836
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06800, 0.06800, 0.26077, 0.20067, 1972.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.76s
- Epoch 044, ExpID 9942
Train - Loss (one batch): 0.06728
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06789, 0.06789, 0.26056, 0.20178, 2035.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.73s
- Epoch 045, ExpID 9942
Train - Loss (one batch): 0.06799
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06795, 0.06795, 0.26066, 0.20245, 2065.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.73s
- Epoch 046, ExpID 9942
Train - Loss (one batch): 0.07278
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06790, 0.06790, 0.26057, 0.20106, 1999.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.71s
- Epoch 047, ExpID 9942
Train - Loss (one batch): 0.06941
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06797, 0.06797, 0.26071, 0.20074, 1977.35%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.74s
- Epoch 048, ExpID 9942
Train - Loss (one batch): 0.06872
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26048, 0.20154, 2026.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.46s
- Epoch 049, ExpID 9942
Train - Loss (one batch): 0.07162
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06797, 0.06797, 0.26071, 0.20086, 1984.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.48s
- Epoch 050, ExpID 9942
Train - Loss (one batch): 0.06723
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06789, 0.06789, 0.26055, 0.20210, 2052.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.47s
- Epoch 051, ExpID 9942
Train - Loss (one batch): 0.06246
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26048, 0.20239, 2068.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.45s
- Epoch 052, ExpID 9942
Train - Loss (one batch): 0.06781
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06789, 0.06789, 0.26055, 0.20127, 2010.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.38s
- Epoch 053, ExpID 9942
Train - Loss (one batch): 0.06977
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26050, 0.20255, 2076.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.48s
- Epoch 054, ExpID 9942
Train - Loss (one batch): 0.07042
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26047, 0.20200, 2049.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.52s
- Epoch 055, ExpID 9942
Train - Loss (one batch): 0.07145
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26051, 0.20190, 2042.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.39s
- Epoch 056, ExpID 9942
Train - Loss (one batch): 0.06885
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06788, 0.06788, 0.26053, 0.20105, 1999.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.41s
- Epoch 057, ExpID 9942
Train - Loss (one batch): 0.06937
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06788, 0.06788, 0.26054, 0.20127, 2010.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.62s
- Epoch 058, ExpID 9942
Train - Loss (one batch): 0.06671
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26045, 0.20173, 2036.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.27s
- Epoch 059, ExpID 9942
Train - Loss (one batch): 0.06706
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26051, 0.20222, 2058.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.33s
- Epoch 060, ExpID 9942
Train - Loss (one batch): 0.06590
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06783, 0.06783, 0.26045, 0.20179, 2039.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.33s
- Epoch 061, ExpID 9942
Train - Loss (one batch): 0.06578
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26046, 0.20159, 2029.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.52s
- Epoch 062, ExpID 9942
Train - Loss (one batch): 0.07015
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26049, 0.20173, 2036.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.61s
- Epoch 063, ExpID 9942
Train - Loss (one batch): 0.06771
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26047, 0.20212, 2055.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.51s
- Epoch 064, ExpID 9942
Train - Loss (one batch): 0.06799
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06800, 0.06800, 0.26076, 0.20271, 2073.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.44s
- Epoch 065, ExpID 9942
Train - Loss (one batch): 0.06816
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26047, 0.20147, 2022.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 14.05s
- Epoch 066, ExpID 9942
Train - Loss (one batch): 0.06536
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26048, 0.20155, 2026.57%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.93s
- Epoch 067, ExpID 9942
Train - Loss (one batch): 0.06638
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26046, 0.20142, 2020.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.80s
- Epoch 068, ExpID 9942
Train - Loss (one batch): 0.06294
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26050, 0.20277, 2086.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.89s
- Epoch 069, ExpID 9942
Train - Loss (one batch): 0.07180
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26047, 0.20188, 2043.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.86s
- Epoch 070, ExpID 9942
Train - Loss (one batch): 0.06976
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26050, 0.20120, 2008.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.83s
- Epoch 071, ExpID 9942
Train - Loss (one batch): 0.06890
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06789, 0.06789, 0.26057, 0.20234, 2062.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.94s
- Epoch 072, ExpID 9942
Train - Loss (one batch): 0.06735
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26061, 0.20069, 1979.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.84s
- Epoch 073, ExpID 9942
Train - Loss (one batch): 0.06779
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26049, 0.20140, 2018.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.84s
- Epoch 074, ExpID 9942
Train - Loss (one batch): 0.06496
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06790, 0.06790, 0.26058, 0.20227, 2058.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.83s
- Epoch 075, ExpID 9942
Train - Loss (one batch): 0.06878
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26048, 0.20257, 2077.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.90s
- Epoch 076, ExpID 9942
Train - Loss (one batch): 0.06727
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06787, 0.06787, 0.26052, 0.20124, 2010.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.88s
- Epoch 077, ExpID 9942
Train - Loss (one batch): 0.06616
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26050, 0.20171, 2034.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.94s
- Epoch 078, ExpID 9942
Train - Loss (one batch): 0.06530
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26046, 0.20182, 2041.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.58s
- Epoch 079, ExpID 9942
Train - Loss (one batch): 0.06752
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06788, 0.06788, 0.26054, 0.20099, 1997.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.64s
- Epoch 080, ExpID 9942
Train - Loss (one batch): 0.07066
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26048, 0.20135, 2017.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.87s
- Epoch 081, ExpID 9942
Train - Loss (one batch): 0.07103
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06791, 0.06791, 0.26059, 0.20096, 1993.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.70s
- Epoch 082, ExpID 9942
Train - Loss (one batch): 0.07280
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06787, 0.06787, 0.26053, 0.20142, 2019.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.58s
- Epoch 083, ExpID 9942
Train - Loss (one batch): 0.07142
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26048, 0.20158, 2029.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.63s
- Epoch 084, ExpID 9942
Train - Loss (one batch): 0.06822
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06790, 0.06790, 0.26057, 0.20113, 2002.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.51s
- Epoch 085, ExpID 9942
Train - Loss (one batch): 0.06854
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06789, 0.06789, 0.26056, 0.20141, 2017.02%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.53s
- Epoch 086, ExpID 9942
Train - Loss (one batch): 0.07342
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06790, 0.06790, 0.26057, 0.20180, 2036.43%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.75s
- Epoch 087, ExpID 9942
Train - Loss (one batch): 0.07154
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06787, 0.06787, 0.26052, 0.20169, 2032.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.55s
- Epoch 088, ExpID 9942
Train - Loss (one batch): 0.06998
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26049, 0.20123, 2010.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.55s
- Epoch 089, ExpID 9942
Train - Loss (one batch): 0.06881
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06788, 0.06788, 0.26054, 0.20113, 2003.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.69s
- Epoch 090, ExpID 9942
Train - Loss (one batch): 0.06461
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26047, 0.20149, 2023.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.59s
- Epoch 091, ExpID 9942
Train - Loss (one batch): 0.06838
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26051, 0.20249, 2072.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.65s
- Epoch 092, ExpID 9942
Train - Loss (one batch): 0.07208
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06787, 0.06787, 0.26052, 0.20121, 2008.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.62s
- Epoch 093, ExpID 9942
Train - Loss (one batch): 0.07158
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26049, 0.20141, 2018.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.59s
- Epoch 094, ExpID 9942
Train - Loss (one batch): 0.06536
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26046, 0.20221, 2059.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.65s
- Epoch 095, ExpID 9942
Train - Loss (one batch): 0.06749
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26062, 0.20172, 2030.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.77s
- Epoch 096, ExpID 9942
Train - Loss (one batch): 0.06596
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06788, 0.06788, 0.26053, 0.20178, 2036.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.76s
- Epoch 097, ExpID 9942
Train - Loss (one batch): 0.06677
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26062, 0.20094, 1992.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.15s
- Epoch 098, ExpID 9942
Train - Loss (one batch): 0.06978
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06789, 0.06789, 0.26057, 0.20122, 2008.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.76s
- Epoch 099, ExpID 9942
Train - Loss (one batch): 0.07442
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06789, 0.06789, 0.26056, 0.20135, 2014.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.78s
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_iTransformer.py
2024-07-19 14:57:48
run_iTransformer.py --history 36 --model iTransformer --dataset physionet
Namespace(state='def', n=100000000, epoch=100, patience=10, history=36, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='physionet', quantization=0.0, model='iTransformer', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=24, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='0', seq_len=175, top_k=5, num_kernels=64, npatch=2, device=device(type='cuda', index=0), PID=1935998, pred_window=12, ndim=41, patch_layer=2, task_name='long_term_forecast', pred_len=720, output_attention=None, d_model=512, embed='timeF', freq='h', dropout=0.1, factor=3, d_ff=512, e_layers=4, n_heads=1, activation='gelu')
- Epoch 000, ExpID 59333
Train - Loss (one batch): 0.06178
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05632, 0.05632, 0.23733, 0.17677, 1194.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 12.07s
- Epoch 001, ExpID 59333
Train - Loss (one batch): 0.06608
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06615, 0.06615, 0.25720, 0.19722, 1968.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.66s
- Epoch 002, ExpID 59333
Train - Loss (one batch): 0.07109
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06439, 0.06439, 0.25376, 0.19452, 1836.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.55s
- Epoch 003, ExpID 59333
Train - Loss (one batch): 0.06078
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06404, 0.06404, 0.25307, 0.19750, 1897.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.44s
- Epoch 004, ExpID 59333
Train - Loss (one batch): 0.06460
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06567, 0.06567, 0.25627, 0.20304, 2087.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.60s
- Epoch 005, ExpID 59333
Train - Loss (one batch): 0.06280
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06474, 0.06474, 0.25444, 0.19383, 1694.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.50s
- Epoch 006, ExpID 59333
Train - Loss (one batch): 0.06958
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06514, 0.06514, 0.25523, 0.20051, 2028.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.57s
- Epoch 007, ExpID 59333
Train - Loss (one batch): 0.06723
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06495, 0.06495, 0.25486, 0.19568, 1832.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.89s
- Epoch 008, ExpID 59333
Train - Loss (one batch): 0.06212
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06510, 0.06510, 0.25515, 0.19420, 1798.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.94s
- Epoch 009, ExpID 59333
Train - Loss (one batch): 0.06473
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06521, 0.06521, 0.25536, 0.19827, 1966.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.90s
- Epoch 010, ExpID 59333
Train - Loss (one batch): 0.07069
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06622, 0.06622, 0.25733, 0.20315, 2083.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 10.25s
- Epoch 011, ExpID 59333
Train - Loss (one batch): 0.06676
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06543, 0.06543, 0.25579, 0.19894, 2006.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.81s
- Epoch 012, ExpID 59333
Train - Loss (one batch): 0.07220
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06533, 0.06533, 0.25561, 0.19828, 1955.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.39s
- Epoch 013, ExpID 59333
Train - Loss (one batch): 0.06813
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06528, 0.06528, 0.25549, 0.19533, 1843.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.96s
- Epoch 014, ExpID 59333
Train - Loss (one batch): 0.06235
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06525, 0.06525, 0.25545, 0.19651, 1844.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.91s
- Epoch 015, ExpID 59333
Train - Loss (one batch): 0.06898
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06747, 0.06747, 0.25974, 0.20453, 2321.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 10.00s
- Epoch 016, ExpID 59333
Train - Loss (one batch): 0.06699
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06750, 0.06750, 0.25980, 0.20468, 2326.10%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 10.03s
- Epoch 017, ExpID 59333
Train - Loss (one batch): 0.06884
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06718, 0.06718, 0.25918, 0.20286, 2255.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.75s
- Epoch 018, ExpID 59333
Train - Loss (one batch): 0.07004
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06702, 0.06702, 0.25889, 0.20157, 2200.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.67s
- Epoch 019, ExpID 59333
Train - Loss (one batch): 0.07290
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06714, 0.06714, 0.25911, 0.20259, 2244.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.78s
- Epoch 020, ExpID 59333
Train - Loss (one batch): 0.07155
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06709, 0.06709, 0.25901, 0.20216, 2226.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.90s
- Epoch 021, ExpID 59333
Train - Loss (one batch): 0.07877
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06700, 0.06700, 0.25884, 0.19892, 2064.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.62s
- Epoch 022, ExpID 59333
Train - Loss (one batch): 0.06762
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06711, 0.06711, 0.25905, 0.19819, 2017.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.98s
- Epoch 023, ExpID 59333
Train - Loss (one batch): 0.07419
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06718, 0.06718, 0.25919, 0.20285, 2255.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.88s
- Epoch 024, ExpID 59333
Train - Loss (one batch): 0.06505
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25874, 0.19979, 2114.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.87s
- Epoch 025, ExpID 59333
Train - Loss (one batch): 0.06837
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26051, 0.20629, 2384.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.98s
- Epoch 026, ExpID 59333
Train - Loss (one batch): 0.06748
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06728, 0.06728, 0.25939, 0.20353, 2282.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.92s
- Epoch 027, ExpID 59333
Train - Loss (one batch): 0.06469
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06704, 0.06704, 0.25891, 0.20172, 2207.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.92s
- Epoch 028, ExpID 59333
Train - Loss (one batch): 0.07215
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06721, 0.06721, 0.25926, 0.20312, 2266.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 10.21s
- Epoch 029, ExpID 59333
Train - Loss (one batch): 0.06355
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06697, 0.06697, 0.25879, 0.19933, 2087.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.89s
- Epoch 030, ExpID 59333
Train - Loss (one batch): 0.06764
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25887, 0.19879, 2056.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 10.23s
- Epoch 031, ExpID 59333
Train - Loss (one batch): 0.06574
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25877, 0.20074, 2162.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.76s
- Epoch 032, ExpID 59333
Train - Loss (one batch): 0.06870
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25877, 0.19946, 2095.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 10.01s
- Epoch 033, ExpID 59333
Train - Loss (one batch): 0.07272
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25887, 0.19879, 2056.35%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.72s
- Epoch 034, ExpID 59333
Train - Loss (one batch): 0.06998
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06702, 0.06702, 0.25889, 0.20157, 2200.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.94s
- Epoch 035, ExpID 59333
Train - Loss (one batch): 0.06546
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25875, 0.19961, 2103.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 10.01s
- Epoch 036, ExpID 59333
Train - Loss (one batch): 0.06977
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25875, 0.20036, 2143.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.53s
- Epoch 037, ExpID 59333
Train - Loss (one batch): 0.07140
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06758, 0.06758, 0.25997, 0.20507, 2340.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.43s
- Epoch 038, ExpID 59333
Train - Loss (one batch): 0.06590
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06703, 0.06703, 0.25890, 0.20163, 2202.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.18s
- Epoch 039, ExpID 59333
Train - Loss (one batch): 0.07359
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06698, 0.06698, 0.25881, 0.19911, 2075.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.22s
- Epoch 040, ExpID 59333
Train - Loss (one batch): 0.06896
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06698, 0.06698, 0.25881, 0.20108, 2178.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.21s
- Epoch 041, ExpID 59333
Train - Loss (one batch): 0.06883
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25876, 0.20065, 2157.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.23s
- Epoch 042, ExpID 59333
Train - Loss (one batch): 0.06573
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06694, 0.06694, 0.25873, 0.19986, 2118.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.55s
- Epoch 043, ExpID 59333
Train - Loss (one batch): 0.06978
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06711, 0.06711, 0.25905, 0.20238, 2235.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.65s
- Epoch 044, ExpID 59333
Train - Loss (one batch): 0.07117
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25874, 0.20017, 2133.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.90s
- Epoch 045, ExpID 59333
Train - Loss (one batch): 0.06499
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25874, 0.20022, 2136.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 10.00s
- Epoch 046, ExpID 59333
Train - Loss (one batch): 0.07159
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06699, 0.06699, 0.25883, 0.20138, 2196.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 10.14s
- Epoch 047, ExpID 59333
Train - Loss (one batch): 0.06931
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25874, 0.20017, 2133.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 10.32s
- Epoch 048, ExpID 59333
Train - Loss (one batch): 0.07037
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25885, 0.20139, 2192.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 10.34s
- Epoch 049, ExpID 59333
Train - Loss (one batch): 0.06570
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06698, 0.06698, 0.25880, 0.20101, 2175.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 10.32s
- Epoch 050, ExpID 59333
Train - Loss (one batch): 0.06682
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06697, 0.06697, 0.25879, 0.20093, 2171.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 10.23s
- Epoch 051, ExpID 59333
Train - Loss (one batch): 0.07225
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25875, 0.19955, 2101.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.74s
- Epoch 052, ExpID 59333
Train - Loss (one batch): 0.07278
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25875, 0.19953, 2100.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 10.03s
- Epoch 053, ExpID 59333
Train - Loss (one batch): 0.06971
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25876, 0.20052, 2151.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.53s
- Epoch 054, ExpID 59333
Train - Loss (one batch): 0.06642
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25887, 0.20149, 2196.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.99s
- Epoch 055, ExpID 59333
Train - Loss (one batch): 0.06958
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06698, 0.06698, 0.25881, 0.19904, 2072.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.67s
- Epoch 056, ExpID 59333
Train - Loss (one batch): 0.07274
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06699, 0.06699, 0.25883, 0.20112, 2179.02%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.54s
- Epoch 057, ExpID 59333
Train - Loss (one batch): 0.07353
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06704, 0.06704, 0.25892, 0.19856, 2043.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.88s
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_iTransformer.py
2024-07-19 15:08:35
run_iTransformer.py --history 24 --model iTransformer --dataset physionet
Namespace(state='def', n=100000000, epoch=100, patience=10, history=24, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='physionet', quantization=0.0, model='iTransformer', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=24, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='0', seq_len=128, top_k=5, num_kernels=64, npatch=1, device=device(type='cuda', index=0), PID=1942242, pred_window=24, ndim=41, patch_layer=1, task_name='long_term_forecast', pred_len=720, output_attention=None, d_model=512, embed='timeF', freq='h', dropout=0.1, factor=3, d_ff=512, e_layers=4, n_heads=1, activation='gelu')
- Epoch 000, ExpID 75256
Train - Loss (one batch): 0.05889
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05891, 0.05891, 0.24272, 0.17080, 776.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05753, 0.05753, 0.23985, 0.16830, 802.99%
Time spent: 15.30s
- Epoch 001, ExpID 75256
Train - Loss (one batch): 0.04930
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05469, 0.05469, 0.23385, 0.17467, 1034.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 14.61s
- Epoch 002, ExpID 75256
Train - Loss (one batch): 0.06449
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06567, 0.06567, 0.25625, 0.19720, 1604.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.99s
- Epoch 003, ExpID 75256
Train - Loss (one batch): 0.06750
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06549, 0.06549, 0.25591, 0.19254, 1645.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.96s
- Epoch 004, ExpID 75256
Train - Loss (one batch): 0.06648
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06594, 0.06594, 0.25678, 0.20056, 1789.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.82s
- Epoch 005, ExpID 75256
Train - Loss (one batch): 0.06880
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06571, 0.06571, 0.25633, 0.19374, 1623.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.70s
- Epoch 006, ExpID 75256
Train - Loss (one batch): 0.07031
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06534, 0.06534, 0.25561, 0.19483, 1746.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.75s
- Epoch 007, ExpID 75256
Train - Loss (one batch): 0.06909
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06758, 0.06758, 0.25996, 0.19695, 1747.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.01s
- Epoch 008, ExpID 75256
Train - Loss (one batch): 0.06600
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06654, 0.06654, 0.25796, 0.19718, 1744.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.91s
- Epoch 009, ExpID 75256
Train - Loss (one batch): 0.06595
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06677, 0.06677, 0.25839, 0.19821, 1845.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.92s
- Epoch 010, ExpID 75256
Train - Loss (one batch): 0.06434
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06630, 0.06630, 0.25748, 0.19714, 1781.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.95s
- Epoch 011, ExpID 75256
Train - Loss (one batch): 0.06706
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06810, 0.06810, 0.26095, 0.20130, 1997.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.12s
- Epoch 012, ExpID 75256
Train - Loss (one batch): 0.06955
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06795, 0.06795, 0.26067, 0.20153, 2017.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.88s
- Epoch 013, ExpID 75256
Train - Loss (one batch): 0.06856
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06791, 0.06791, 0.26060, 0.20198, 2043.48%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.87s
- Epoch 014, ExpID 75256
Train - Loss (one batch): 0.06750
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06796, 0.06796, 0.26069, 0.20304, 2093.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.87s
- Epoch 015, ExpID 75256
Train - Loss (one batch): 0.06659
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06664, 0.06664, 0.25815, 0.19788, 1826.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.02s
- Epoch 016, ExpID 75256
Train - Loss (one batch): 0.06832
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26062, 0.20253, 2069.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.26s
- Epoch 017, ExpID 75256
Train - Loss (one batch): 0.06533
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06783, 0.06783, 0.26044, 0.20292, 2083.57%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.22s
- Epoch 018, ExpID 75256
Train - Loss (one batch): 0.06572
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06783, 0.06783, 0.26045, 0.19877, 1832.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.09s
- Epoch 019, ExpID 75256
Train - Loss (one batch): 0.06614
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06802, 0.06802, 0.26080, 0.20209, 2045.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.99s
- Epoch 020, ExpID 75256
Train - Loss (one batch): 0.06642
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26061, 0.20310, 2104.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.01s
- Epoch 021, ExpID 75256
Train - Loss (one batch): 0.06484
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26061, 0.20233, 2060.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.99s
- Epoch 022, ExpID 75256
Train - Loss (one batch): 0.06988
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06804, 0.06804, 0.26084, 0.20189, 2025.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.01s
- Epoch 023, ExpID 75256
Train - Loss (one batch): 0.07003
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06822, 0.06822, 0.26120, 0.20060, 1947.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.05s
- Epoch 024, ExpID 75256
Train - Loss (one batch): 0.07234
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06796, 0.06796, 0.26070, 0.20317, 2098.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.97s
- Epoch 025, ExpID 75256
Train - Loss (one batch): 0.06567
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06803, 0.06803, 0.26083, 0.20364, 2115.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.08s
- Epoch 026, ExpID 75256
Train - Loss (one batch): 0.06979
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06796, 0.06796, 0.26068, 0.20277, 2080.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.80s
- Epoch 027, ExpID 75256
Train - Loss (one batch): 0.06808
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26062, 0.20183, 2036.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.98s
- Epoch 028, ExpID 75256
Train - Loss (one batch): 0.06918
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06794, 0.06794, 0.26066, 0.20273, 2077.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.83s
- Epoch 029, ExpID 75256
Train - Loss (one batch): 0.06411
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06819, 0.06819, 0.26113, 0.19969, 1903.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.81s
- Epoch 030, ExpID 75256
Train - Loss (one batch): 0.07028
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06793, 0.06793, 0.26064, 0.20165, 2026.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.71s
- Epoch 031, ExpID 75256
Train - Loss (one batch): 0.06664
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06819, 0.06819, 0.26113, 0.20511, 2181.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.88s
- Epoch 032, ExpID 75256
Train - Loss (one batch): 0.06833
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06793, 0.06793, 0.26063, 0.20165, 2025.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.91s
- Epoch 033, ExpID 75256
Train - Loss (one batch): 0.06997
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06797, 0.06797, 0.26072, 0.20103, 1990.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.79s
- Epoch 034, ExpID 75256
Train - Loss (one batch): 0.06703
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06796, 0.06796, 0.26069, 0.20137, 2009.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.82s
- Epoch 035, ExpID 75256
Train - Loss (one batch): 0.06579
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06799, 0.06799, 0.26075, 0.20223, 2047.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.80s
- Epoch 036, ExpID 75256
Train - Loss (one batch): 0.06728
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06791, 0.06791, 0.26059, 0.20074, 1978.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.98s
- Epoch 037, ExpID 75256
Train - Loss (one batch): 0.07054
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26061, 0.20232, 2060.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.68s
- Epoch 038, ExpID 75256
Train - Loss (one batch): 0.06898
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06794, 0.06794, 0.26065, 0.20142, 2014.03%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.12s
- Epoch 039, ExpID 75256
Train - Loss (one batch): 0.06881
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06793, 0.06793, 0.26063, 0.20169, 2028.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.07s
- Epoch 040, ExpID 75256
Train - Loss (one batch): 0.06739
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06805, 0.06805, 0.26086, 0.20044, 1957.35%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.97s
- Epoch 041, ExpID 75256
Train - Loss (one batch): 0.07152
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06793, 0.06793, 0.26064, 0.20135, 2011.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.01s
- Epoch 042, ExpID 75256
Train - Loss (one batch): 0.06904
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26062, 0.20122, 2005.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.20s
- Epoch 043, ExpID 75256
Train - Loss (one batch): 0.06836
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06800, 0.06800, 0.26077, 0.20067, 1972.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.71s
- Epoch 044, ExpID 75256
Train - Loss (one batch): 0.06728
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06789, 0.06789, 0.26056, 0.20178, 2035.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.78s
- Epoch 045, ExpID 75256
Train - Loss (one batch): 0.06799
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06795, 0.06795, 0.26066, 0.20245, 2065.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.93s
- Epoch 046, ExpID 75256
Train - Loss (one batch): 0.07278
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06790, 0.06790, 0.26057, 0.20106, 1999.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.03s
- Epoch 047, ExpID 75256
Train - Loss (one batch): 0.06941
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06797, 0.06797, 0.26071, 0.20074, 1977.35%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.78s
- Epoch 048, ExpID 75256
Train - Loss (one batch): 0.06872
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26048, 0.20154, 2026.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.11s
- Epoch 049, ExpID 75256
Train - Loss (one batch): 0.07162
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06797, 0.06797, 0.26071, 0.20086, 1984.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.04s
- Epoch 050, ExpID 75256
Train - Loss (one batch): 0.06723
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06789, 0.06789, 0.26055, 0.20210, 2052.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.13s
- Epoch 051, ExpID 75256
Train - Loss (one batch): 0.06246
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26048, 0.20239, 2068.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.20s
- Epoch 052, ExpID 75256
Train - Loss (one batch): 0.06781
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06789, 0.06789, 0.26055, 0.20127, 2010.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.18s
- Epoch 053, ExpID 75256
Train - Loss (one batch): 0.06977
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26050, 0.20255, 2076.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.23s
- Epoch 054, ExpID 75256
Train - Loss (one batch): 0.07042
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26047, 0.20200, 2049.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.05s
- Epoch 055, ExpID 75256
Train - Loss (one batch): 0.07145
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26051, 0.20190, 2042.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.98s
- Epoch 056, ExpID 75256
Train - Loss (one batch): 0.06885
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06788, 0.06788, 0.26053, 0.20105, 1999.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.03s
- Epoch 057, ExpID 75256
Train - Loss (one batch): 0.06937
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06788, 0.06788, 0.26054, 0.20127, 2010.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.02s
- Epoch 058, ExpID 75256
Train - Loss (one batch): 0.06671
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26045, 0.20173, 2036.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.97s
- Epoch 059, ExpID 75256
Train - Loss (one batch): 0.06706
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26051, 0.20222, 2058.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.03s
- Epoch 060, ExpID 75256
Train - Loss (one batch): 0.06590
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06783, 0.06783, 0.26045, 0.20179, 2039.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.64s
- Epoch 061, ExpID 75256
Train - Loss (one batch): 0.06578
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26046, 0.20159, 2029.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.01s
- Epoch 062, ExpID 75256
Train - Loss (one batch): 0.07015
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26049, 0.20173, 2036.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.05s
- Epoch 063, ExpID 75256
Train - Loss (one batch): 0.06771
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26047, 0.20212, 2055.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.04s
- Epoch 064, ExpID 75256
Train - Loss (one batch): 0.06799
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06800, 0.06800, 0.26076, 0.20271, 2073.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.02s
- Epoch 065, ExpID 75256
Train - Loss (one batch): 0.06816
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26047, 0.20147, 2022.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.95s
- Epoch 066, ExpID 75256
Train - Loss (one batch): 0.06536
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26048, 0.20155, 2026.57%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.92s
- Epoch 067, ExpID 75256
Train - Loss (one batch): 0.06638
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26046, 0.20142, 2020.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.92s
- Epoch 068, ExpID 75256
Train - Loss (one batch): 0.06294
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26050, 0.20277, 2086.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.79s
- Epoch 069, ExpID 75256
Train - Loss (one batch): 0.07180
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26047, 0.20188, 2043.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.72s
- Epoch 070, ExpID 75256
Train - Loss (one batch): 0.06976
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26050, 0.20120, 2008.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.62s
- Epoch 071, ExpID 75256
Train - Loss (one batch): 0.06890
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06789, 0.06789, 0.26057, 0.20234, 2062.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.77s
- Epoch 072, ExpID 75256
Train - Loss (one batch): 0.06735
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26061, 0.20069, 1979.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.59s
- Epoch 073, ExpID 75256
Train - Loss (one batch): 0.06779
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26049, 0.20140, 2018.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.52s
- Epoch 074, ExpID 75256
Train - Loss (one batch): 0.06496
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06790, 0.06790, 0.26058, 0.20227, 2058.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.52s
- Epoch 075, ExpID 75256
Train - Loss (one batch): 0.06878
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26048, 0.20257, 2077.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.60s
- Epoch 076, ExpID 75256
Train - Loss (one batch): 0.06727
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06787, 0.06787, 0.26052, 0.20124, 2010.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.63s
- Epoch 077, ExpID 75256
Train - Loss (one batch): 0.06616
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26050, 0.20171, 2034.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.60s
- Epoch 078, ExpID 75256
Train - Loss (one batch): 0.06530
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26046, 0.20182, 2041.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.77s
- Epoch 079, ExpID 75256
Train - Loss (one batch): 0.06752
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06788, 0.06788, 0.26054, 0.20099, 1997.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.68s
- Epoch 080, ExpID 75256
Train - Loss (one batch): 0.07066
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26048, 0.20135, 2017.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.72s
- Epoch 081, ExpID 75256
Train - Loss (one batch): 0.07103
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06791, 0.06791, 0.26059, 0.20096, 1993.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.94s
- Epoch 082, ExpID 75256
Train - Loss (one batch): 0.07280
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06787, 0.06787, 0.26053, 0.20142, 2019.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.88s
- Epoch 083, ExpID 75256
Train - Loss (one batch): 0.07142
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26048, 0.20158, 2029.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.16s
- Epoch 084, ExpID 75256
Train - Loss (one batch): 0.06822
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06790, 0.06790, 0.26057, 0.20113, 2002.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.25s
- Epoch 085, ExpID 75256
Train - Loss (one batch): 0.06854
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06789, 0.06789, 0.26056, 0.20141, 2017.02%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.82s
- Epoch 086, ExpID 75256
Train - Loss (one batch): 0.07342
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06790, 0.06790, 0.26057, 0.20180, 2036.43%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.74s
- Epoch 087, ExpID 75256
Train - Loss (one batch): 0.07154
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06787, 0.06787, 0.26052, 0.20169, 2032.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.95s
- Epoch 088, ExpID 75256
Train - Loss (one batch): 0.06998
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26049, 0.20123, 2010.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.98s
- Epoch 089, ExpID 75256
Train - Loss (one batch): 0.06881
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06788, 0.06788, 0.26054, 0.20113, 2003.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.00s
- Epoch 090, ExpID 75256
Train - Loss (one batch): 0.06461
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26047, 0.20149, 2023.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.99s
- Epoch 091, ExpID 75256
Train - Loss (one batch): 0.06838
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26051, 0.20249, 2072.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.07s
- Epoch 092, ExpID 75256
Train - Loss (one batch): 0.07208
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06787, 0.06787, 0.26052, 0.20121, 2008.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.03s
- Epoch 093, ExpID 75256
Train - Loss (one batch): 0.07158
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26049, 0.20141, 2018.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.36s
- Epoch 094, ExpID 75256
Train - Loss (one batch): 0.06536
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26046, 0.20221, 2059.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.04s
- Epoch 095, ExpID 75256
Train - Loss (one batch): 0.06749
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26062, 0.20172, 2030.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.14s
- Epoch 096, ExpID 75256
Train - Loss (one batch): 0.06596
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06788, 0.06788, 0.26053, 0.20178, 2036.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.41s
- Epoch 097, ExpID 75256
Train - Loss (one batch): 0.06677
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26062, 0.20094, 1992.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 15.06s
- Epoch 098, ExpID 75256
Train - Loss (one batch): 0.06978
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06789, 0.06789, 0.26057, 0.20122, 2008.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 13.46s
- Epoch 099, ExpID 75256
Train - Loss (one batch): 0.07442
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06789, 0.06789, 0.26056, 0.20135, 2014.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 12.76s
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_iTransformer.py
2024-07-19 15:31:09
run_iTransformer.py --history 36 --model iTransformer --dataset physionet
Namespace(state='def', n=100000000, epoch=100, patience=10, history=36, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='physionet', quantization=0.0, model='iTransformer', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=24, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='0', seq_len=175, top_k=5, num_kernels=64, npatch=2, device=device(type='cuda', index=0), PID=1955723, pred_window=12, ndim=41, patch_layer=2, task_name='long_term_forecast', pred_len=720, output_attention=None, d_model=512, embed='timeF', freq='h', dropout=0.1, factor=3, d_ff=512, e_layers=4, n_heads=1, activation='gelu')
- Epoch 000, ExpID 6130
Train - Loss (one batch): 0.06178
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05632, 0.05632, 0.23733, 0.17677, 1194.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 11.81s
- Epoch 001, ExpID 6130
Train - Loss (one batch): 0.06608
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06615, 0.06615, 0.25720, 0.19722, 1968.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.74s
- Epoch 002, ExpID 6130
Train - Loss (one batch): 0.07109
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06439, 0.06439, 0.25376, 0.19452, 1836.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 10.06s
- Epoch 003, ExpID 6130
Train - Loss (one batch): 0.06078
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06404, 0.06404, 0.25307, 0.19750, 1897.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 10.20s
- Epoch 004, ExpID 6130
Train - Loss (one batch): 0.06460
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06567, 0.06567, 0.25627, 0.20304, 2087.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.38s
- Epoch 005, ExpID 6130
Train - Loss (one batch): 0.06280
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06474, 0.06474, 0.25444, 0.19383, 1694.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.12s
- Epoch 006, ExpID 6130
Train - Loss (one batch): 0.06958
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06514, 0.06514, 0.25523, 0.20051, 2028.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.28s
- Epoch 007, ExpID 6130
Train - Loss (one batch): 0.06723
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06495, 0.06495, 0.25486, 0.19568, 1832.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.71s
- Epoch 008, ExpID 6130
Train - Loss (one batch): 0.06212
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06510, 0.06510, 0.25515, 0.19420, 1798.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.58s
- Epoch 009, ExpID 6130
Train - Loss (one batch): 0.06473
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06521, 0.06521, 0.25536, 0.19827, 1966.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.92s
- Epoch 010, ExpID 6130
Train - Loss (one batch): 0.07069
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06622, 0.06622, 0.25733, 0.20315, 2083.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.51s
- Epoch 011, ExpID 6130
Train - Loss (one batch): 0.06676
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06543, 0.06543, 0.25579, 0.19894, 2006.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.68s
- Epoch 012, ExpID 6130
Train - Loss (one batch): 0.07220
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06533, 0.06533, 0.25561, 0.19828, 1955.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.75s
- Epoch 013, ExpID 6130
Train - Loss (one batch): 0.06813
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06528, 0.06528, 0.25549, 0.19533, 1843.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.81s
- Epoch 014, ExpID 6130
Train - Loss (one batch): 0.06235
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06525, 0.06525, 0.25545, 0.19651, 1844.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.70s
- Epoch 015, ExpID 6130
Train - Loss (one batch): 0.06898
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06747, 0.06747, 0.25974, 0.20453, 2321.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.56s
- Epoch 016, ExpID 6130
Train - Loss (one batch): 0.06699
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06750, 0.06750, 0.25980, 0.20468, 2326.10%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.63s
- Epoch 017, ExpID 6130
Train - Loss (one batch): 0.06884
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06718, 0.06718, 0.25918, 0.20286, 2255.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.54s
- Epoch 018, ExpID 6130
Train - Loss (one batch): 0.07004
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06702, 0.06702, 0.25889, 0.20157, 2200.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.33s
- Epoch 019, ExpID 6130
Train - Loss (one batch): 0.07290
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06714, 0.06714, 0.25911, 0.20259, 2244.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.41s
- Epoch 020, ExpID 6130
Train - Loss (one batch): 0.07155
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06709, 0.06709, 0.25901, 0.20216, 2226.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.49s
- Epoch 021, ExpID 6130
Train - Loss (one batch): 0.07877
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06700, 0.06700, 0.25884, 0.19892, 2064.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.75s
- Epoch 022, ExpID 6130
Train - Loss (one batch): 0.06762
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06711, 0.06711, 0.25905, 0.19819, 2017.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.23s
- Epoch 023, ExpID 6130
Train - Loss (one batch): 0.07419
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06718, 0.06718, 0.25919, 0.20285, 2255.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.25s
- Epoch 024, ExpID 6130
Train - Loss (one batch): 0.06505
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25874, 0.19979, 2114.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.52s
- Epoch 025, ExpID 6130
Train - Loss (one batch): 0.06837
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26051, 0.20629, 2384.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.54s
- Epoch 026, ExpID 6130
Train - Loss (one batch): 0.06748
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06728, 0.06728, 0.25939, 0.20353, 2282.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.87s
- Epoch 027, ExpID 6130
Train - Loss (one batch): 0.06469
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06704, 0.06704, 0.25891, 0.20172, 2207.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.52s
- Epoch 028, ExpID 6130
Train - Loss (one batch): 0.07215
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06721, 0.06721, 0.25926, 0.20312, 2266.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.59s
- Epoch 029, ExpID 6130
Train - Loss (one batch): 0.06355
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06697, 0.06697, 0.25879, 0.19933, 2087.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.41s
- Epoch 030, ExpID 6130
Train - Loss (one batch): 0.06764
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25887, 0.19879, 2056.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.96s
- Epoch 031, ExpID 6130
Train - Loss (one batch): 0.06574
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25877, 0.20074, 2162.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.39s
- Epoch 032, ExpID 6130
Train - Loss (one batch): 0.06870
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25877, 0.19946, 2095.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.56s
- Epoch 033, ExpID 6130
Train - Loss (one batch): 0.07272
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25887, 0.19879, 2056.35%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 10.26s
- Epoch 034, ExpID 6130
Train - Loss (one batch): 0.06998
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06702, 0.06702, 0.25889, 0.20157, 2200.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.84s
- Epoch 035, ExpID 6130
Train - Loss (one batch): 0.06546
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25875, 0.19961, 2103.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.82s
- Epoch 036, ExpID 6130
Train - Loss (one batch): 0.06977
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25875, 0.20036, 2143.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.74s
- Epoch 037, ExpID 6130
Train - Loss (one batch): 0.07140
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06758, 0.06758, 0.25997, 0.20507, 2340.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.73s
- Epoch 038, ExpID 6130
Train - Loss (one batch): 0.06590
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06703, 0.06703, 0.25890, 0.20163, 2202.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.77s
- Epoch 039, ExpID 6130
Train - Loss (one batch): 0.07359
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06698, 0.06698, 0.25881, 0.19911, 2075.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.73s
- Epoch 040, ExpID 6130
Train - Loss (one batch): 0.06896
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06698, 0.06698, 0.25881, 0.20108, 2178.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.66s
- Epoch 041, ExpID 6130
Train - Loss (one batch): 0.06883
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25876, 0.20065, 2157.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.91s
- Epoch 042, ExpID 6130
Train - Loss (one batch): 0.06573
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06694, 0.06694, 0.25873, 0.19986, 2118.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.48s
- Epoch 043, ExpID 6130
Train - Loss (one batch): 0.06978
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06711, 0.06711, 0.25905, 0.20238, 2235.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.95s
- Epoch 044, ExpID 6130
Train - Loss (one batch): 0.07117
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25874, 0.20017, 2133.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.50s
- Epoch 045, ExpID 6130
Train - Loss (one batch): 0.06499
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25874, 0.20022, 2136.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.98s
- Epoch 046, ExpID 6130
Train - Loss (one batch): 0.07159
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06699, 0.06699, 0.25883, 0.20138, 2196.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.72s
- Epoch 047, ExpID 6130
Train - Loss (one batch): 0.06931
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25874, 0.20017, 2133.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.88s
- Epoch 048, ExpID 6130
Train - Loss (one batch): 0.07037
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25885, 0.20139, 2192.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.82s
- Epoch 049, ExpID 6130
Train - Loss (one batch): 0.06570
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06698, 0.06698, 0.25880, 0.20101, 2175.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.81s
- Epoch 050, ExpID 6130
Train - Loss (one batch): 0.06682
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06697, 0.06697, 0.25879, 0.20093, 2171.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.29s
- Epoch 051, ExpID 6130
Train - Loss (one batch): 0.07225
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25875, 0.19955, 2101.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.78s
- Epoch 052, ExpID 6130
Train - Loss (one batch): 0.07278
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25875, 0.19953, 2100.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.95s
- Epoch 053, ExpID 6130
Train - Loss (one batch): 0.06971
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25876, 0.20052, 2151.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.90s
- Epoch 054, ExpID 6130
Train - Loss (one batch): 0.06642
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25887, 0.20149, 2196.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.66s
- Epoch 055, ExpID 6130
Train - Loss (one batch): 0.06958
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06698, 0.06698, 0.25881, 0.19904, 2072.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.42s
- Epoch 056, ExpID 6130
Train - Loss (one batch): 0.07274
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06699, 0.06699, 0.25883, 0.20112, 2179.02%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 10.05s
- Epoch 057, ExpID 6130
Train - Loss (one batch): 0.07353
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06704, 0.06704, 0.25892, 0.19856, 2043.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.52s
- Epoch 058, ExpID 6130
Train - Loss (one batch): 0.06762
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06697, 0.06697, 0.25879, 0.20095, 2172.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.59s
- Epoch 059, ExpID 6130
Train - Loss (one batch): 0.06584
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06712, 0.06712, 0.25908, 0.20252, 2242.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.71s
- Epoch 060, ExpID 6130
Train - Loss (one batch): 0.06903
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06694, 0.06694, 0.25873, 0.19983, 2117.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.85s
- Epoch 061, ExpID 6130
Train - Loss (one batch): 0.06846
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06694, 0.06694, 0.25873, 0.19984, 2118.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.67s
- Epoch 062, ExpID 6130
Train - Loss (one batch): 0.06314
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25876, 0.20080, 2165.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.91s
- Epoch 063, ExpID 6130
Train - Loss (one batch): 0.06631
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25874, 0.20032, 2141.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.87s
- Epoch 064, ExpID 6130
Train - Loss (one batch): 0.06976
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06697, 0.06697, 0.25878, 0.19967, 2108.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 10.14s
- Epoch 065, ExpID 6130
Train - Loss (one batch): 0.07624
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25876, 0.20065, 2157.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.78s
- Epoch 066, ExpID 6130
Train - Loss (one batch): 0.06663
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06702, 0.06702, 0.25887, 0.20153, 2199.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.80s
- Epoch 067, ExpID 6130
Train - Loss (one batch): 0.07229
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25874, 0.20054, 2153.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.79s
- Epoch 068, ExpID 6130
Train - Loss (one batch): 0.06516
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06694, 0.06694, 0.25873, 0.20004, 2128.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.88s
- Epoch 069, ExpID 6130
Train - Loss (one batch): 0.06525
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06703, 0.06703, 0.25889, 0.20153, 2198.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.39s
- Epoch 070, ExpID 6130
Train - Loss (one batch): 0.07212
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06698, 0.06698, 0.25881, 0.20116, 2182.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.45s
- Epoch 071, ExpID 6130
Train - Loss (one batch): 0.06630
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25886, 0.20143, 2194.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.92s
- Epoch 072, ExpID 6130
Train - Loss (one batch): 0.06857
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25874, 0.20050, 2152.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.50s
- Epoch 073, ExpID 6130
Train - Loss (one batch): 0.07441
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25876, 0.19966, 2107.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.50s
- Epoch 074, ExpID 6130
Train - Loss (one batch): 0.06899
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06698, 0.06698, 0.25881, 0.20094, 2170.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.50s
- Epoch 075, ExpID 6130
Train - Loss (one batch): 0.06431
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25876, 0.20039, 2144.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 10.09s
- Epoch 076, ExpID 6130
Train - Loss (one batch): 0.06629
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06694, 0.06694, 0.25872, 0.20031, 2143.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.66s
- Epoch 077, ExpID 6130
Train - Loss (one batch): 0.07220
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06710, 0.06710, 0.25903, 0.20226, 2230.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 10.18s
- Epoch 078, ExpID 6130
Train - Loss (one batch): 0.06394
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06704, 0.06704, 0.25893, 0.20188, 2216.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.75s
- Epoch 079, ExpID 6130
Train - Loss (one batch): 0.07025
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06706, 0.06706, 0.25897, 0.20164, 2201.09%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.69s
- Epoch 080, ExpID 6130
Train - Loss (one batch): 0.07025
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06698, 0.06698, 0.25880, 0.20106, 2179.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.64s
- Epoch 081, ExpID 6130
Train - Loss (one batch): 0.06678
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06722, 0.06722, 0.25926, 0.20304, 2262.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.71s
- Epoch 082, ExpID 6130
Train - Loss (one batch): 0.06500
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06699, 0.06699, 0.25882, 0.19902, 2070.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.55s
- Epoch 083, ExpID 6130
Train - Loss (one batch): 0.06794
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06697, 0.06697, 0.25878, 0.19929, 2087.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.76s
- Epoch 084, ExpID 6130
Train - Loss (one batch): 0.06992
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25876, 0.20079, 2165.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.67s
- Epoch 085, ExpID 6130
Train - Loss (one batch): 0.07332
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06702, 0.06702, 0.25888, 0.20148, 2195.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.81s
- Epoch 086, ExpID 6130
Train - Loss (one batch): 0.06940
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06694, 0.06694, 0.25874, 0.20045, 2149.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.86s
- Epoch 087, ExpID 6130
Train - Loss (one batch): 0.06816
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06710, 0.06710, 0.25903, 0.20229, 2233.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.50s
- Epoch 088, ExpID 6130
Train - Loss (one batch): 0.06790
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06693, 0.06693, 0.25871, 0.19969, 2111.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.98s
- Epoch 089, ExpID 6130
Train - Loss (one batch): 0.06924
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06694, 0.06694, 0.25873, 0.19981, 2116.99%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.67s
- Epoch 090, ExpID 6130
Train - Loss (one batch): 0.07167
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25875, 0.20049, 2150.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.79s
- Epoch 091, ExpID 6130
Train - Loss (one batch): 0.07236
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06694, 0.06694, 0.25873, 0.20000, 2126.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.81s
- Epoch 092, ExpID 6130
Train - Loss (one batch): 0.07355
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25887, 0.20123, 2182.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.62s
- Epoch 093, ExpID 6130
Train - Loss (one batch): 0.06952
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25875, 0.19956, 2102.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.84s
- Epoch 094, ExpID 6130
Train - Loss (one batch): 0.06954
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25885, 0.20144, 2195.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.54s
- Epoch 095, ExpID 6130
Train - Loss (one batch): 0.05417
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25875, 0.20051, 2151.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.28s
- Epoch 096, ExpID 6130
Train - Loss (one batch): 0.07295
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25876, 0.19939, 2093.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.86s
- Epoch 097, ExpID 6130
Train - Loss (one batch): 0.06827
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06694, 0.06694, 0.25874, 0.19967, 2108.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.36s
- Epoch 098, ExpID 6130
Train - Loss (one batch): 0.07155
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06694, 0.06694, 0.25873, 0.19956, 2104.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.21s
- Epoch 099, ExpID 6130
Train - Loss (one batch): 0.06859
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06697, 0.06697, 0.25879, 0.20012, 2128.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 9.19s
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_iTransformer.py
2024-07-19 15:48:06
run_iTransformer.py --history 12 --model iTransformer --dataset physionet
Namespace(state='def', n=100000000, epoch=100, patience=10, history=12, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='physionet', quantization=0.0, model='iTransformer', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=24, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='0', seq_len=83, top_k=5, num_kernels=64, npatch=1, device=device(type='cuda', index=0), PID=1965886, pred_window=36, ndim=41, patch_layer=1, task_name='long_term_forecast', pred_len=720, output_attention=None, d_model=512, embed='timeF', freq='h', dropout=0.1, factor=3, d_ff=512, e_layers=4, n_heads=1, activation='gelu')
- Epoch 000, ExpID 81097
Train - Loss (one batch): 0.05369
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05880, 0.05880, 0.24249, 0.17889, 1149.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 20.01s
- Epoch 001, ExpID 81097
Train - Loss (one batch): 0.06510
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06257, 0.06257, 0.25014, 0.19167, 1451.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.39s
- Epoch 002, ExpID 81097
Train - Loss (one batch): 0.06894
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06673, 0.06673, 0.25832, 0.20174, 1979.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.25s
- Epoch 003, ExpID 81097
Train - Loss (one batch): 0.06858
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06620, 0.06620, 0.25730, 0.19676, 1836.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.17s
- Epoch 004, ExpID 81097
Train - Loss (one batch): 0.06491
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06634, 0.06634, 0.25756, 0.19671, 1812.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.41s
- Epoch 005, ExpID 81097
Train - Loss (one batch): 0.06192
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06611, 0.06611, 0.25712, 0.20081, 1979.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.33s
- Epoch 006, ExpID 81097
Train - Loss (one batch): 0.06888
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06689, 0.06689, 0.25863, 0.20563, 2046.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.40s
- Epoch 007, ExpID 81097
Train - Loss (one batch): 0.06477
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06674, 0.06674, 0.25833, 0.20485, 2025.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.20s
- Epoch 008, ExpID 81097
Train - Loss (one batch): 0.06086
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06598, 0.06598, 0.25686, 0.19837, 1820.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.42s
- Epoch 009, ExpID 81097
Train - Loss (one batch): 0.06606
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06613, 0.06613, 0.25716, 0.19912, 1896.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.62s
- Epoch 010, ExpID 81097
Train - Loss (one batch): 0.06846
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06602, 0.06602, 0.25695, 0.19788, 1843.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 17.26s
- Epoch 011, ExpID 81097
Train - Loss (one batch): 0.06633
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06765, 0.06765, 0.26010, 0.20083, 2070.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.27s
- Epoch 012, ExpID 81097
Train - Loss (one batch): 0.06593
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06623, 0.06623, 0.25736, 0.19980, 1918.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.52s
- Epoch 013, ExpID 81097
Train - Loss (one batch): 0.06520
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06620, 0.06620, 0.25729, 0.19669, 1774.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.18s
- Epoch 014, ExpID 81097
Train - Loss (one batch): 0.06535
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06631, 0.06631, 0.25751, 0.20054, 1909.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.39s
- Epoch 015, ExpID 81097
Train - Loss (one batch): 0.06998
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06623, 0.06623, 0.25734, 0.19721, 1759.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.53s
- Epoch 016, ExpID 81097
Train - Loss (one batch): 0.06611
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06620, 0.06620, 0.25730, 0.19887, 1901.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.65s
- Epoch 017, ExpID 81097
Train - Loss (one batch): 0.06587
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06746, 0.06746, 0.25973, 0.20542, 2212.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.37s
- Epoch 018, ExpID 81097
Train - Loss (one batch): 0.06538
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06647, 0.06647, 0.25782, 0.19707, 1757.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.40s
- Epoch 019, ExpID 81097
Train - Loss (one batch): 0.07158
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06778, 0.06778, 0.26034, 0.20095, 2073.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.44s
- Epoch 020, ExpID 81097
Train - Loss (one batch): 0.06475
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06649, 0.06649, 0.25785, 0.19680, 1750.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.34s
- Epoch 021, ExpID 81097
Train - Loss (one batch): 0.06933
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06660, 0.06660, 0.25807, 0.19607, 1735.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.38s
- Epoch 022, ExpID 81097
Train - Loss (one batch): 0.06701
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06650, 0.06650, 0.25787, 0.19739, 1836.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 17.13s
- Epoch 023, ExpID 81097
Train - Loss (one batch): 0.06851
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06665, 0.06665, 0.25817, 0.19679, 1805.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.44s
- Epoch 024, ExpID 81097
Train - Loss (one batch): 0.06257
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06654, 0.06654, 0.25796, 0.19659, 1754.03%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.38s
- Epoch 025, ExpID 81097
Train - Loss (one batch): 0.06649
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06773, 0.06773, 0.26025, 0.20159, 2111.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.36s
- Epoch 026, ExpID 81097
Train - Loss (one batch): 0.06714
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06772, 0.06772, 0.26024, 0.20182, 2124.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.31s
- Epoch 027, ExpID 81097
Train - Loss (one batch): 0.07061
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06777, 0.06777, 0.26033, 0.20192, 2125.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.16s
- Epoch 028, ExpID 81097
Train - Loss (one batch): 0.06665
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06771, 0.06771, 0.26021, 0.20179, 2123.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.24s
- Epoch 029, ExpID 81097
Train - Loss (one batch): 0.06924
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06770, 0.06770, 0.26019, 0.20217, 2143.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.45s
- Epoch 030, ExpID 81097
Train - Loss (one batch): 0.06603
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06770, 0.06770, 0.26019, 0.20141, 2102.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.74s
- Epoch 031, ExpID 81097
Train - Loss (one batch): 0.06763
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06774, 0.06774, 0.26026, 0.20084, 2072.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.41s
- Epoch 032, ExpID 81097
Train - Loss (one batch): 0.06634
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06770, 0.06770, 0.26020, 0.20168, 2116.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.53s
- Epoch 033, ExpID 81097
Train - Loss (one batch): 0.06930
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06772, 0.06772, 0.26023, 0.20111, 2084.83%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.47s
- Epoch 034, ExpID 81097
Train - Loss (one batch): 0.06684
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06771, 0.06771, 0.26021, 0.20188, 2126.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.36s
- Epoch 035, ExpID 81097
Train - Loss (one batch): 0.06826
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06773, 0.06773, 0.26024, 0.20080, 2069.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.23s
- Epoch 036, ExpID 81097
Train - Loss (one batch): 0.06901
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06776, 0.06776, 0.26031, 0.20187, 2120.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.10s
- Epoch 037, ExpID 81097
Train - Loss (one batch): 0.06870
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06774, 0.06774, 0.26026, 0.20139, 2097.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.42s
- Epoch 038, ExpID 81097
Train - Loss (one batch): 0.06693
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06772, 0.06772, 0.26023, 0.20242, 2155.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.46s
- Epoch 039, ExpID 81097
Train - Loss (one batch): 0.06316
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06780, 0.06780, 0.26038, 0.20058, 2050.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.48s
- Epoch 040, ExpID 81097
Train - Loss (one batch): 0.06729
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06769, 0.06769, 0.26018, 0.20140, 2101.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.25s
- Epoch 041, ExpID 81097
Train - Loss (one batch): 0.06679
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06779, 0.06779, 0.26037, 0.20171, 2112.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.49s
- Epoch 042, ExpID 81097
Train - Loss (one batch): 0.06551
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06775, 0.06775, 0.26029, 0.20079, 2063.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.42s
- Epoch 043, ExpID 81097
Train - Loss (one batch): 0.06258
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06769, 0.06769, 0.26017, 0.20139, 2102.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.28s
- Epoch 044, ExpID 81097
Train - Loss (one batch): 0.06898
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06780, 0.06780, 0.26039, 0.20024, 2031.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.23s
- Epoch 045, ExpID 81097
Train - Loss (one batch): 0.06603
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06774, 0.06774, 0.26027, 0.20070, 2061.30%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.27s
- Epoch 046, ExpID 81097
Train - Loss (one batch): 0.06575
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06775, 0.06775, 0.26029, 0.20158, 2109.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.39s
- Epoch 047, ExpID 81097
Train - Loss (one batch): 0.06912
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06779, 0.06779, 0.26037, 0.20131, 2091.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.39s
- Epoch 048, ExpID 81097
Train - Loss (one batch): 0.06642
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06774, 0.06774, 0.26027, 0.20080, 2067.48%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.20s
- Epoch 049, ExpID 81097
Train - Loss (one batch): 0.07221
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06768, 0.06768, 0.26016, 0.20184, 2126.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.27s
- Epoch 050, ExpID 81097
Train - Loss (one batch): 0.06637
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06770, 0.06770, 0.26019, 0.20206, 2139.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.18s
- Epoch 051, ExpID 81097
Train - Loss (one batch): 0.06893
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06769, 0.06769, 0.26018, 0.20217, 2143.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.12s
- Epoch 052, ExpID 81097
Train - Loss (one batch): 0.06488
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06771, 0.06771, 0.26021, 0.20106, 2085.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.33s
- Epoch 053, ExpID 81097
Train - Loss (one batch): 0.06606
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06770, 0.06770, 0.26019, 0.20105, 2084.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.30s
- Epoch 054, ExpID 81097
Train - Loss (one batch): 0.06859
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06768, 0.06768, 0.26015, 0.20167, 2119.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.53s
- Epoch 055, ExpID 81097
Train - Loss (one batch): 0.06818
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06783, 0.06783, 0.26043, 0.20203, 2120.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.51s
- Epoch 056, ExpID 81097
Train - Loss (one batch): 0.07067
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06772, 0.06772, 0.26022, 0.20159, 2112.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.45s
- Epoch 057, ExpID 81097
Train - Loss (one batch): 0.06402
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06770, 0.06770, 0.26020, 0.20180, 2125.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.70s
- Epoch 058, ExpID 81097
Train - Loss (one batch): 0.06626
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06769, 0.06769, 0.26017, 0.20178, 2122.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.57s
- Epoch 059, ExpID 81097
Train - Loss (one batch): 0.07008
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06772, 0.06772, 0.26023, 0.20134, 2101.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.44s
- Epoch 060, ExpID 81097
Train - Loss (one batch): 0.06842
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06770, 0.06770, 0.26020, 0.20232, 2150.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.36s
- Epoch 061, ExpID 81097
Train - Loss (one batch): 0.06644
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06772, 0.06772, 0.26023, 0.20240, 2152.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.29s
- Epoch 062, ExpID 81097
Train - Loss (one batch): 0.06679
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06772, 0.06772, 0.26022, 0.20126, 2092.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.44s
- Epoch 063, ExpID 81097
Train - Loss (one batch): 0.06409
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06769, 0.06769, 0.26018, 0.20158, 2110.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.38s
- Epoch 064, ExpID 81097
Train - Loss (one batch): 0.06271
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06771, 0.06771, 0.26022, 0.20153, 2108.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.30s
- Epoch 065, ExpID 81097
Train - Loss (one batch): 0.06555
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06769, 0.06769, 0.26018, 0.20128, 2097.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.37s
- Epoch 066, ExpID 81097
Train - Loss (one batch): 0.06616
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06769, 0.06769, 0.26017, 0.20195, 2131.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.41s
- Epoch 067, ExpID 81097
Train - Loss (one batch): 0.06928
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06770, 0.06770, 0.26019, 0.20224, 2145.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.38s
- Epoch 068, ExpID 81097
Train - Loss (one batch): 0.06787
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06769, 0.06769, 0.26017, 0.20150, 2107.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.34s
- Epoch 069, ExpID 81097
Train - Loss (one batch): 0.06501
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06769, 0.06769, 0.26017, 0.20142, 2101.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.27s
- Epoch 070, ExpID 81097
Train - Loss (one batch): 0.07026
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06771, 0.06771, 0.26021, 0.20092, 2076.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.30s
- Epoch 071, ExpID 81097
Train - Loss (one batch): 0.06770
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06770, 0.06770, 0.26019, 0.20186, 2124.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.36s
- Epoch 072, ExpID 81097
Train - Loss (one batch): 0.06699
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06771, 0.06771, 0.26020, 0.20113, 2086.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.30s
- Epoch 073, ExpID 81097
Train - Loss (one batch): 0.06547
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06770, 0.06770, 0.26019, 0.20134, 2096.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.80s
- Epoch 074, ExpID 81097
Train - Loss (one batch): 0.06877
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06768, 0.06768, 0.26016, 0.20162, 2114.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.41s
- Epoch 075, ExpID 81097
Train - Loss (one batch): 0.06551
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06768, 0.06768, 0.26015, 0.20152, 2109.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.37s
- Epoch 076, ExpID 81097
Train - Loss (one batch): 0.06646
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06771, 0.06771, 0.26020, 0.20140, 2101.99%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.48s
- Epoch 077, ExpID 81097
Train - Loss (one batch): 0.06631
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06769, 0.06769, 0.26018, 0.20188, 2127.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.45s
- Epoch 078, ExpID 81097
Train - Loss (one batch): 0.06935
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06769, 0.06769, 0.26016, 0.20169, 2116.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.53s
- Epoch 079, ExpID 81097
Train - Loss (one batch): 0.06993
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06770, 0.06770, 0.26020, 0.20158, 2111.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.44s
- Epoch 080, ExpID 81097
Train - Loss (one batch): 0.06756
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06773, 0.06773, 0.26024, 0.20139, 2094.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.40s
- Epoch 081, ExpID 81097
Train - Loss (one batch): 0.06450
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06769, 0.06769, 0.26016, 0.20204, 2136.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.53s
- Epoch 082, ExpID 81097
Train - Loss (one batch): 0.06878
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06771, 0.06771, 0.26020, 0.20102, 2080.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.39s
- Epoch 083, ExpID 81097
Train - Loss (one batch): 0.06803
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06768, 0.06768, 0.26016, 0.20164, 2114.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.47s
- Epoch 084, ExpID 81097
Train - Loss (one batch): 0.06603
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06773, 0.06773, 0.26025, 0.20131, 2092.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.20s
- Epoch 085, ExpID 81097
Train - Loss (one batch): 0.06756
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06769, 0.06769, 0.26018, 0.20197, 2133.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.18s
- Epoch 086, ExpID 81097
Train - Loss (one batch): 0.06679
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06770, 0.06770, 0.26019, 0.20096, 2078.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.24s
- Epoch 087, ExpID 81097
Train - Loss (one batch): 0.06705
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06768, 0.06768, 0.26016, 0.20162, 2113.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.25s
- Epoch 088, ExpID 81097
Train - Loss (one batch): 0.06672
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06771, 0.06771, 0.26021, 0.20107, 2084.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.35s
- Epoch 089, ExpID 81097
Train - Loss (one batch): 0.06552
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06769, 0.06769, 0.26018, 0.20131, 2096.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.36s
- Epoch 090, ExpID 81097
Train - Loss (one batch): 0.06542
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06770, 0.06770, 0.26020, 0.20177, 2119.09%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.17s
- Epoch 091, ExpID 81097
Train - Loss (one batch): 0.07017
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06768, 0.06768, 0.26016, 0.20171, 2120.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.17s
- Epoch 092, ExpID 81097
Train - Loss (one batch): 0.06967
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06769, 0.06769, 0.26018, 0.20157, 2111.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.30s
- Epoch 093, ExpID 81097
Train - Loss (one batch): 0.06257
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06770, 0.06770, 0.26019, 0.20191, 2128.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 17.21s
- Epoch 094, ExpID 81097
Train - Loss (one batch): 0.06799
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06773, 0.06773, 0.26025, 0.20094, 2074.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.46s
- Epoch 095, ExpID 81097
Train - Loss (one batch): 0.06895
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06771, 0.06771, 0.26022, 0.20187, 2121.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.51s
- Epoch 096, ExpID 81097
Train - Loss (one batch): 0.06647
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06771, 0.06771, 0.26021, 0.20150, 2105.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.36s
- Epoch 097, ExpID 81097
Train - Loss (one batch): 0.06895
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06771, 0.06771, 0.26021, 0.20113, 2085.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.37s
- Epoch 098, ExpID 81097
Train - Loss (one batch): 0.06929
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06776, 0.06776, 0.26031, 0.20071, 2061.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.36s
- Epoch 099, ExpID 81097
Train - Loss (one batch): 0.06478
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06769, 0.06769, 0.26018, 0.20143, 2104.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05840, 0.05840, 0.24167, 0.17840, 1180.27%
Time spent: 16.31s
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_iTransformer.py
2024-07-19 20:38:38
run_iTransformer.py --history 24 --model iTransformer --dataset physionet --gpu 2
Namespace(state='def', n=100000000, epoch=100, patience=10, history=24, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='physionet', quantization=0.0, model='iTransformer', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=24, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='2', seq_len=128, top_k=5, num_kernels=64, npatch=1, device=device(type='cuda', index=0), PID=2141348, pred_window=24, ndim=41, patch_layer=1, task_name='long_term_forecast', pred_len=720, output_attention=None, d_model=512, embed='timeF', freq='h', dropout=0.1, factor=3, d_ff=512, e_layers=4, n_heads=1, activation='gelu')
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_iTransformer.py
2024-07-19 20:47:06
run_iTransformer.py --history 36 --model iTransformer --dataset physionet --gpu 2
Namespace(state='def', n=100000000, epoch=100, patience=10, history=36, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='physionet', quantization=0.0, model='iTransformer', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=24, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='2', seq_len=175, top_k=5, num_kernels=64, npatch=2, device=device(type='cuda', index=0), PID=2146657, pred_window=12, ndim=41, patch_layer=2, task_name='long_term_forecast', pred_len=720, output_attention=None, d_model=512, embed='timeF', freq='h', dropout=0.1, factor=3, d_ff=512, e_layers=4, n_heads=1, activation='gelu')
- Epoch 000, ExpID 11644
Train - Loss (one batch): 0.06178
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05632, 0.05632, 0.23733, 0.17677, 1194.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 39.44s
- Epoch 001, ExpID 11644
Train - Loss (one batch): 0.06608
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06615, 0.06615, 0.25720, 0.19722, 1968.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 27.89s
- Epoch 002, ExpID 11644
Train - Loss (one batch): 0.07109
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06439, 0.06439, 0.25376, 0.19452, 1836.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.04s
- Epoch 003, ExpID 11644
Train - Loss (one batch): 0.06078
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06404, 0.06404, 0.25307, 0.19750, 1897.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.50s
- Epoch 004, ExpID 11644
Train - Loss (one batch): 0.06460
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06567, 0.06567, 0.25627, 0.20304, 2087.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 27.86s
- Epoch 005, ExpID 11644
Train - Loss (one batch): 0.06280
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06474, 0.06474, 0.25444, 0.19383, 1694.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.79s
- Epoch 006, ExpID 11644
Train - Loss (one batch): 0.06958
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06514, 0.06514, 0.25523, 0.20051, 2028.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.85s
- Epoch 007, ExpID 11644
Train - Loss (one batch): 0.06723
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06495, 0.06495, 0.25486, 0.19568, 1832.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 28.87s
- Epoch 008, ExpID 11644
Train - Loss (one batch): 0.06212
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06510, 0.06510, 0.25515, 0.19420, 1798.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.85s
- Epoch 009, ExpID 11644
Train - Loss (one batch): 0.06473
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06521, 0.06521, 0.25536, 0.19827, 1966.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.55s
- Epoch 010, ExpID 11644
Train - Loss (one batch): 0.07069
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06622, 0.06622, 0.25733, 0.20315, 2083.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 29.95s
- Epoch 011, ExpID 11644
Train - Loss (one batch): 0.06676
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06543, 0.06543, 0.25579, 0.19894, 2006.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 29.93s
- Epoch 012, ExpID 11644
Train - Loss (one batch): 0.07220
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06533, 0.06533, 0.25561, 0.19828, 1955.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.66s
- Epoch 013, ExpID 11644
Train - Loss (one batch): 0.06813
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06528, 0.06528, 0.25549, 0.19533, 1843.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.90s
- Epoch 014, ExpID 11644
Train - Loss (one batch): 0.06235
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06525, 0.06525, 0.25545, 0.19651, 1844.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 29.04s
- Epoch 015, ExpID 11644
Train - Loss (one batch): 0.06898
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06747, 0.06747, 0.25974, 0.20453, 2321.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.98s
- Epoch 016, ExpID 11644
Train - Loss (one batch): 0.06699
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06750, 0.06750, 0.25980, 0.20468, 2326.10%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.00s
- Epoch 017, ExpID 11644
Train - Loss (one batch): 0.06884
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06718, 0.06718, 0.25918, 0.20286, 2255.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 27.72s
- Epoch 018, ExpID 11644
Train - Loss (one batch): 0.07004
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06702, 0.06702, 0.25889, 0.20157, 2200.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.29s
- Epoch 019, ExpID 11644
Train - Loss (one batch): 0.07290
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06714, 0.06714, 0.25911, 0.20259, 2244.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.57s
- Epoch 020, ExpID 11644
Train - Loss (one batch): 0.07155
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06709, 0.06709, 0.25901, 0.20216, 2226.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 27.63s
- Epoch 021, ExpID 11644
Train - Loss (one batch): 0.07877
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06700, 0.06700, 0.25884, 0.19892, 2064.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.31s
- Epoch 022, ExpID 11644
Train - Loss (one batch): 0.06762
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06711, 0.06711, 0.25905, 0.19819, 2017.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.03s
- Epoch 023, ExpID 11644
Train - Loss (one batch): 0.07419
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06718, 0.06718, 0.25919, 0.20285, 2255.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 28.17s
- Epoch 024, ExpID 11644
Train - Loss (one batch): 0.06505
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25874, 0.19979, 2114.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.84s
- Epoch 025, ExpID 11644
Train - Loss (one batch): 0.06837
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26051, 0.20629, 2384.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.63s
- Epoch 026, ExpID 11644
Train - Loss (one batch): 0.06748
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06728, 0.06728, 0.25939, 0.20353, 2282.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 28.22s
- Epoch 027, ExpID 11644
Train - Loss (one batch): 0.06469
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06704, 0.06704, 0.25891, 0.20172, 2207.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.58s
- Epoch 028, ExpID 11644
Train - Loss (one batch): 0.07215
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06721, 0.06721, 0.25926, 0.20312, 2266.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.31s
- Epoch 029, ExpID 11644
Train - Loss (one batch): 0.06355
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06697, 0.06697, 0.25879, 0.19933, 2087.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 29.58s
- Epoch 030, ExpID 11644
Train - Loss (one batch): 0.06764
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25887, 0.19879, 2056.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.78s
- Epoch 031, ExpID 11644
Train - Loss (one batch): 0.06574
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25877, 0.20074, 2162.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.94s
- Epoch 032, ExpID 11644
Train - Loss (one batch): 0.06870
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25877, 0.19946, 2095.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 30.13s
- Epoch 033, ExpID 11644
Train - Loss (one batch): 0.07272
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25887, 0.19879, 2056.35%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 30.33s
- Epoch 034, ExpID 11644
Train - Loss (one batch): 0.06998
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06702, 0.06702, 0.25889, 0.20157, 2200.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.03s
- Epoch 035, ExpID 11644
Train - Loss (one batch): 0.06546
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25875, 0.19961, 2103.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.10s
- Epoch 036, ExpID 11644
Train - Loss (one batch): 0.06977
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25875, 0.20036, 2143.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 29.09s
- Epoch 037, ExpID 11644
Train - Loss (one batch): 0.07140
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06758, 0.06758, 0.25997, 0.20507, 2340.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.50s
- Epoch 038, ExpID 11644
Train - Loss (one batch): 0.06590
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06703, 0.06703, 0.25890, 0.20163, 2202.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.57s
- Epoch 039, ExpID 11644
Train - Loss (one batch): 0.07359
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06698, 0.06698, 0.25881, 0.19911, 2075.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 27.76s
- Epoch 040, ExpID 11644
Train - Loss (one batch): 0.06896
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06698, 0.06698, 0.25881, 0.20108, 2178.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.45s
- Epoch 041, ExpID 11644
Train - Loss (one batch): 0.06883
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25876, 0.20065, 2157.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.09s
- Epoch 042, ExpID 11644
Train - Loss (one batch): 0.06573
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06694, 0.06694, 0.25873, 0.19986, 2118.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 27.39s
- Epoch 043, ExpID 11644
Train - Loss (one batch): 0.06978
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06711, 0.06711, 0.25905, 0.20238, 2235.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.83s
- Epoch 044, ExpID 11644
Train - Loss (one batch): 0.07117
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25874, 0.20017, 2133.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.01s
- Epoch 045, ExpID 11644
Train - Loss (one batch): 0.06499
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25874, 0.20022, 2136.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 28.20s
- Epoch 046, ExpID 11644
Train - Loss (one batch): 0.07159
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06699, 0.06699, 0.25883, 0.20138, 2196.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.53s
- Epoch 047, ExpID 11644
Train - Loss (one batch): 0.06931
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25874, 0.20017, 2133.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.86s
- Epoch 048, ExpID 11644
Train - Loss (one batch): 0.07037
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25885, 0.20139, 2192.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 28.49s
- Epoch 049, ExpID 11644
Train - Loss (one batch): 0.06570
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06698, 0.06698, 0.25880, 0.20101, 2175.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.31s
- Epoch 050, ExpID 11644
Train - Loss (one batch): 0.06682
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06697, 0.06697, 0.25879, 0.20093, 2171.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.23s
- Epoch 051, ExpID 11644
Train - Loss (one batch): 0.07225
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25875, 0.19955, 2101.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 30.40s
- Epoch 052, ExpID 11644
Train - Loss (one batch): 0.07278
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25875, 0.19953, 2100.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 30.08s
- Epoch 053, ExpID 11644
Train - Loss (one batch): 0.06971
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25876, 0.20052, 2151.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.68s
- Epoch 054, ExpID 11644
Train - Loss (one batch): 0.06642
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25887, 0.20149, 2196.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.29s
- Epoch 055, ExpID 11644
Train - Loss (one batch): 0.06958
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06698, 0.06698, 0.25881, 0.19904, 2072.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 29.03s
- Epoch 056, ExpID 11644
Train - Loss (one batch): 0.07274
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06699, 0.06699, 0.25883, 0.20112, 2179.02%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.91s
- Epoch 057, ExpID 11644
Train - Loss (one batch): 0.07353
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06704, 0.06704, 0.25892, 0.19856, 2043.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.69s
- Epoch 058, ExpID 11644
Train - Loss (one batch): 0.06762
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06697, 0.06697, 0.25879, 0.20095, 2172.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 27.66s
- Epoch 059, ExpID 11644
Train - Loss (one batch): 0.06584
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06712, 0.06712, 0.25908, 0.20252, 2242.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.17s
- Epoch 060, ExpID 11644
Train - Loss (one batch): 0.06903
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06694, 0.06694, 0.25873, 0.19983, 2117.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.97s
- Epoch 061, ExpID 11644
Train - Loss (one batch): 0.06846
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06694, 0.06694, 0.25873, 0.19984, 2118.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 27.62s
- Epoch 062, ExpID 11644
Train - Loss (one batch): 0.06314
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25876, 0.20080, 2165.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.43s
- Epoch 063, ExpID 11644
Train - Loss (one batch): 0.06631
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25874, 0.20032, 2141.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.81s
- Epoch 064, ExpID 11644
Train - Loss (one batch): 0.06976
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06697, 0.06697, 0.25878, 0.19967, 2108.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 28.16s
- Epoch 065, ExpID 11644
Train - Loss (one batch): 0.07624
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25876, 0.20065, 2157.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.48s
- Epoch 066, ExpID 11644
Train - Loss (one batch): 0.06663
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06702, 0.06702, 0.25887, 0.20153, 2199.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.64s
- Epoch 067, ExpID 11644
Train - Loss (one batch): 0.07229
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25874, 0.20054, 2153.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 28.09s
- Epoch 068, ExpID 11644
Train - Loss (one batch): 0.06516
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06694, 0.06694, 0.25873, 0.20004, 2128.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.11s
- Epoch 069, ExpID 11644
Train - Loss (one batch): 0.06525
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06703, 0.06703, 0.25889, 0.20153, 2198.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.83s
- Epoch 070, ExpID 11644
Train - Loss (one batch): 0.07212
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06698, 0.06698, 0.25881, 0.20116, 2182.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 29.83s
- Epoch 071, ExpID 11644
Train - Loss (one batch): 0.06630
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25886, 0.20143, 2194.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.45s
- Epoch 072, ExpID 11644
Train - Loss (one batch): 0.06857
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25874, 0.20050, 2152.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.37s
- Epoch 073, ExpID 11644
Train - Loss (one batch): 0.07441
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25876, 0.19966, 2107.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 30.41s
- Epoch 074, ExpID 11644
Train - Loss (one batch): 0.06899
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06698, 0.06698, 0.25881, 0.20094, 2170.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 30.35s
- Epoch 075, ExpID 11644
Train - Loss (one batch): 0.06431
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25876, 0.20039, 2144.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.90s
- Epoch 076, ExpID 11644
Train - Loss (one batch): 0.06629
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06694, 0.06694, 0.25872, 0.20031, 2143.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.07s
- Epoch 077, ExpID 11644
Train - Loss (one batch): 0.07220
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06710, 0.06710, 0.25903, 0.20226, 2230.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 29.55s
- Epoch 078, ExpID 11644
Train - Loss (one batch): 0.06394
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06704, 0.06704, 0.25893, 0.20188, 2216.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.69s
- Epoch 079, ExpID 11644
Train - Loss (one batch): 0.07025
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06706, 0.06706, 0.25897, 0.20164, 2201.09%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.95s
- Epoch 080, ExpID 11644
Train - Loss (one batch): 0.07025
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06698, 0.06698, 0.25880, 0.20106, 2179.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 27.73s
- Epoch 081, ExpID 11644
Train - Loss (one batch): 0.06678
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06722, 0.06722, 0.25926, 0.20304, 2262.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.68s
- Epoch 082, ExpID 11644
Train - Loss (one batch): 0.06500
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06699, 0.06699, 0.25882, 0.19902, 2070.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.92s
- Epoch 083, ExpID 11644
Train - Loss (one batch): 0.06794
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06697, 0.06697, 0.25878, 0.19929, 2087.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 27.93s
- Epoch 084, ExpID 11644
Train - Loss (one batch): 0.06992
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25876, 0.20079, 2165.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.11s
- Epoch 085, ExpID 11644
Train - Loss (one batch): 0.07332
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06702, 0.06702, 0.25888, 0.20148, 2195.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.76s
- Epoch 086, ExpID 11644
Train - Loss (one batch): 0.06940
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06694, 0.06694, 0.25874, 0.20045, 2149.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 27.56s
- Epoch 087, ExpID 11644
Train - Loss (one batch): 0.06816
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06710, 0.06710, 0.25903, 0.20229, 2233.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.26s
- Epoch 088, ExpID 11644
Train - Loss (one batch): 0.06790
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06693, 0.06693, 0.25871, 0.19969, 2111.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.31s
- Epoch 089, ExpID 11644
Train - Loss (one batch): 0.06924
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06694, 0.06694, 0.25873, 0.19981, 2116.99%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 27.83s
- Epoch 090, ExpID 11644
Train - Loss (one batch): 0.07167
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25875, 0.20049, 2150.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.08s
- Epoch 091, ExpID 11644
Train - Loss (one batch): 0.07236
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06694, 0.06694, 0.25873, 0.20000, 2126.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.67s
- Epoch 092, ExpID 11644
Train - Loss (one batch): 0.07355
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25887, 0.20123, 2182.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 29.59s
- Epoch 093, ExpID 11644
Train - Loss (one batch): 0.06952
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25875, 0.19956, 2102.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 30.64s
- Epoch 094, ExpID 11644
Train - Loss (one batch): 0.06954
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25885, 0.20144, 2195.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 31.62s
- Epoch 095, ExpID 11644
Train - Loss (one batch): 0.05417
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25875, 0.20051, 2151.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 30.78s
- Epoch 096, ExpID 11644
Train - Loss (one batch): 0.07295
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06696, 0.06696, 0.25876, 0.19939, 2093.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 29.81s
- Epoch 097, ExpID 11644
Train - Loss (one batch): 0.06827
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06694, 0.06694, 0.25874, 0.19967, 2108.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.07s
- Epoch 098, ExpID 11644
Train - Loss (one batch): 0.07155
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06694, 0.06694, 0.25873, 0.19956, 2104.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 32.29s
- Epoch 099, ExpID 11644
Train - Loss (one batch): 0.06859
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06697, 0.06697, 0.25879, 0.20012, 2128.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05572, 0.05572, 0.23605, 0.17490, 1140.19%
Time spent: 28.84s
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_iTransformer.py
2024-07-19 21:46:56
run_iTransformer.py --history 12 --model iTransformer --dataset physionet --gpu 2
Namespace(state='def', n=100000000, epoch=100, patience=10, history=12, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='physionet', quantization=0.0, model='iTransformer', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=24, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='2', seq_len=83, top_k=5, num_kernels=64, npatch=1, device=device(type='cuda', index=0), PID=2180281, pred_window=36, ndim=41, patch_layer=1, task_name='long_term_forecast', pred_len=720, output_attention=None, d_model=512, embed='timeF', freq='h', dropout=0.1, factor=3, d_ff=512, e_layers=4, n_heads=1, activation='gelu')
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_baselines.py
2024-07-22 20:09:04
run_baselines.py --patience 10 --gpu 1 --dataset physionet --history 24 --model iTransformer
Namespace(state='def', n=100000000, epoch=100, patience=10, history=24, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='physionet', quantization=0.0, model='iTransformer', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=24, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='1', seq_len=128, top_k=5, num_kernels=64, npatch=1, device=device(type='cuda', index=0), PID=799981, pred_window=24, ndim=41, patch_layer=1, patch_size_list=[64, 32, 16], num_experts_list=[3, 3, 3], task_name='long_term_forecast', pred_len=720, output_attention=None, d_model=512, embed='timeF', freq='h', dropout=0.1, factor=3, d_ff=512, e_layers=4, n_heads=1, activation='gelu')
- Epoch 000, ExpID 69699
Train - Loss (one batch): 0.05889
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05891, 0.05891, 0.24272, 0.17080, 776.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05753, 0.05753, 0.23985, 0.16830, 802.99%
Time spent: 27.74s
- Epoch 001, ExpID 69699
Train - Loss (one batch): 0.04930
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05469, 0.05469, 0.23385, 0.17467, 1034.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 27.65s
- Epoch 002, ExpID 69699
Train - Loss (one batch): 0.06449
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06567, 0.06567, 0.25625, 0.19720, 1604.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 24.38s
- Epoch 003, ExpID 69699
Train - Loss (one batch): 0.06750
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06549, 0.06549, 0.25591, 0.19254, 1645.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 25.01s
- Epoch 004, ExpID 69699
Train - Loss (one batch): 0.06648
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06594, 0.06594, 0.25678, 0.20056, 1789.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 24.08s
- Epoch 005, ExpID 69699
Train - Loss (one batch): 0.06880
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06571, 0.06571, 0.25633, 0.19374, 1623.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 27.79s
- Epoch 006, ExpID 69699
Train - Loss (one batch): 0.07031
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06534, 0.06534, 0.25561, 0.19483, 1746.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.32s
- Epoch 007, ExpID 69699
Train - Loss (one batch): 0.06909
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06758, 0.06758, 0.25996, 0.19695, 1747.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.03s
- Epoch 008, ExpID 69699
Train - Loss (one batch): 0.06600
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06654, 0.06654, 0.25796, 0.19718, 1744.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 49.04s
- Epoch 009, ExpID 69699
Train - Loss (one batch): 0.06595
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06677, 0.06677, 0.25839, 0.19821, 1845.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 55.31s
- Epoch 010, ExpID 69699
Train - Loss (one batch): 0.06434
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06630, 0.06630, 0.25748, 0.19714, 1781.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 56.85s
- Epoch 011, ExpID 69699
Train - Loss (one batch): 0.06706
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06810, 0.06810, 0.26095, 0.20130, 1997.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 47.80s
- Epoch 012, ExpID 69699
Train - Loss (one batch): 0.06955
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06795, 0.06795, 0.26067, 0.20153, 2017.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 31.07s
- Epoch 013, ExpID 69699
Train - Loss (one batch): 0.06856
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06791, 0.06791, 0.26060, 0.20198, 2043.48%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 29.87s
- Epoch 014, ExpID 69699
Train - Loss (one batch): 0.06750
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06796, 0.06796, 0.26069, 0.20304, 2093.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.46s
- Epoch 015, ExpID 69699
Train - Loss (one batch): 0.06659
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06664, 0.06664, 0.25815, 0.19788, 1826.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.18s
- Epoch 016, ExpID 69699
Train - Loss (one batch): 0.06832
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26062, 0.20253, 2069.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 29.86s
- Epoch 017, ExpID 69699
Train - Loss (one batch): 0.06533
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06783, 0.06783, 0.26044, 0.20292, 2083.57%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 29.62s
- Epoch 018, ExpID 69699
Train - Loss (one batch): 0.06572
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06783, 0.06783, 0.26045, 0.19877, 1832.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 29.97s
- Epoch 019, ExpID 69699
Train - Loss (one batch): 0.06614
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06802, 0.06802, 0.26080, 0.20209, 2045.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.09s
- Epoch 020, ExpID 69699
Train - Loss (one batch): 0.06642
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26061, 0.20310, 2104.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.32s
- Epoch 021, ExpID 69699
Train - Loss (one batch): 0.06484
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26061, 0.20233, 2060.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.53s
- Epoch 022, ExpID 69699
Train - Loss (one batch): 0.06988
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06804, 0.06804, 0.26084, 0.20189, 2025.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 32.00s
- Epoch 023, ExpID 69699
Train - Loss (one batch): 0.07003
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06822, 0.06822, 0.26120, 0.20060, 1947.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 48.65s
- Epoch 024, ExpID 69699
Train - Loss (one batch): 0.07234
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06796, 0.06796, 0.26070, 0.20317, 2098.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 52.44s
- Epoch 025, ExpID 69699
Train - Loss (one batch): 0.06567
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06803, 0.06803, 0.26083, 0.20364, 2115.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 45.77s
- Epoch 026, ExpID 69699
Train - Loss (one batch): 0.06979
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06796, 0.06796, 0.26068, 0.20277, 2080.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.67s
- Epoch 027, ExpID 69699
Train - Loss (one batch): 0.06808
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26062, 0.20183, 2036.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.38s
- Epoch 028, ExpID 69699
Train - Loss (one batch): 0.06918
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06794, 0.06794, 0.26066, 0.20273, 2077.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.56s
- Epoch 029, ExpID 69699
Train - Loss (one batch): 0.06411
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06819, 0.06819, 0.26113, 0.19969, 1903.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.84s
- Epoch 030, ExpID 69699
Train - Loss (one batch): 0.07028
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06793, 0.06793, 0.26064, 0.20165, 2026.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.62s
- Epoch 031, ExpID 69699
Train - Loss (one batch): 0.06664
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06819, 0.06819, 0.26113, 0.20511, 2181.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 50.38s
- Epoch 032, ExpID 69699
Train - Loss (one batch): 0.06833
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06793, 0.06793, 0.26063, 0.20165, 2025.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 56.41s
- Epoch 033, ExpID 69699
Train - Loss (one batch): 0.06997
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06797, 0.06797, 0.26072, 0.20103, 1990.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 55.24s
- Epoch 034, ExpID 69699
Train - Loss (one batch): 0.06703
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06796, 0.06796, 0.26069, 0.20137, 2009.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 47.85s
- Epoch 035, ExpID 69699
Train - Loss (one batch): 0.06579
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06799, 0.06799, 0.26075, 0.20223, 2047.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 29.98s
- Epoch 036, ExpID 69699
Train - Loss (one batch): 0.06728
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06791, 0.06791, 0.26059, 0.20074, 1978.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 29.97s
- Epoch 037, ExpID 69699
Train - Loss (one batch): 0.07054
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26061, 0.20232, 2060.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.05s
- Epoch 038, ExpID 69699
Train - Loss (one batch): 0.06898
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06794, 0.06794, 0.26065, 0.20142, 2014.03%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.03s
- Epoch 039, ExpID 69699
Train - Loss (one batch): 0.06881
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06793, 0.06793, 0.26063, 0.20169, 2028.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.16s
- Epoch 040, ExpID 69699
Train - Loss (one batch): 0.06739
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06805, 0.06805, 0.26086, 0.20044, 1957.35%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 31.05s
- Epoch 041, ExpID 69699
Train - Loss (one batch): 0.07152
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06793, 0.06793, 0.26064, 0.20135, 2011.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 31.33s
- Epoch 042, ExpID 69699
Train - Loss (one batch): 0.06904
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26062, 0.20122, 2005.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 31.52s
- Epoch 043, ExpID 69699
Train - Loss (one batch): 0.06836
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06800, 0.06800, 0.26077, 0.20067, 1972.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.89s
- Epoch 044, ExpID 69699
Train - Loss (one batch): 0.06728
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06789, 0.06789, 0.26056, 0.20178, 2035.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 31.14s
- Epoch 045, ExpID 69699
Train - Loss (one batch): 0.06799
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06795, 0.06795, 0.26066, 0.20245, 2065.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.36s
- Epoch 046, ExpID 69699
Train - Loss (one batch): 0.07278
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06790, 0.06790, 0.26057, 0.20106, 1999.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 50.87s
- Epoch 047, ExpID 69699
Train - Loss (one batch): 0.06941
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06797, 0.06797, 0.26071, 0.20074, 1977.35%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 53.42s
- Epoch 048, ExpID 69699
Train - Loss (one batch): 0.06872
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26048, 0.20154, 2026.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 40.94s
- Epoch 049, ExpID 69699
Train - Loss (one batch): 0.07162
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06797, 0.06797, 0.26071, 0.20086, 1984.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.67s
- Epoch 050, ExpID 69699
Train - Loss (one batch): 0.06723
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06789, 0.06789, 0.26055, 0.20210, 2052.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.89s
- Epoch 051, ExpID 69699
Train - Loss (one batch): 0.06246
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26048, 0.20239, 2068.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 31.49s
- Epoch 052, ExpID 69699
Train - Loss (one batch): 0.06781
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06789, 0.06789, 0.26055, 0.20127, 2010.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.55s
- Epoch 053, ExpID 69699
Train - Loss (one batch): 0.06977
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26050, 0.20255, 2076.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.29s
- Epoch 054, ExpID 69699
Train - Loss (one batch): 0.07042
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26047, 0.20200, 2049.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 53.76s
- Epoch 055, ExpID 69699
Train - Loss (one batch): 0.07145
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26051, 0.20190, 2042.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 57.32s
- Epoch 056, ExpID 69699
Train - Loss (one batch): 0.06885
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06788, 0.06788, 0.26053, 0.20105, 1999.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 55.67s
- Epoch 057, ExpID 69699
Train - Loss (one batch): 0.06937
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06788, 0.06788, 0.26054, 0.20127, 2010.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 43.32s
- Epoch 058, ExpID 69699
Train - Loss (one batch): 0.06671
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26045, 0.20173, 2036.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 31.63s
- Epoch 059, ExpID 69699
Train - Loss (one batch): 0.06706
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26051, 0.20222, 2058.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 31.00s
- Epoch 060, ExpID 69699
Train - Loss (one batch): 0.06590
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06783, 0.06783, 0.26045, 0.20179, 2039.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 31.62s
- Epoch 061, ExpID 69699
Train - Loss (one batch): 0.06578
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26046, 0.20159, 2029.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 31.10s
- Epoch 062, ExpID 69699
Train - Loss (one batch): 0.07015
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26049, 0.20173, 2036.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.87s
- Epoch 063, ExpID 69699
Train - Loss (one batch): 0.06771
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26047, 0.20212, 2055.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 29.71s
- Epoch 064, ExpID 69699
Train - Loss (one batch): 0.06799
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06800, 0.06800, 0.26076, 0.20271, 2073.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.48s
- Epoch 065, ExpID 69699
Train - Loss (one batch): 0.06816
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26047, 0.20147, 2022.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 30.67s
- Epoch 066, ExpID 69699
Train - Loss (one batch): 0.06536
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26048, 0.20155, 2026.57%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 29.77s
- Epoch 067, ExpID 69699
Train - Loss (one batch): 0.06638
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26046, 0.20142, 2020.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 33.19s
- Epoch 068, ExpID 69699
Train - Loss (one batch): 0.06294
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26050, 0.20277, 2086.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 47.24s
- Epoch 069, ExpID 69699
Train - Loss (one batch): 0.07180
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26047, 0.20188, 2043.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 43.78s
- Epoch 070, ExpID 69699
Train - Loss (one batch): 0.06976
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26050, 0.20120, 2008.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 35.30s
- Epoch 071, ExpID 69699
Train - Loss (one batch): 0.06890
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06789, 0.06789, 0.26057, 0.20234, 2062.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 37.29s
- Epoch 072, ExpID 69699
Train - Loss (one batch): 0.06735
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06792, 0.06792, 0.26061, 0.20069, 1979.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 35.85s
- Epoch 073, ExpID 69699
Train - Loss (one batch): 0.06779
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26049, 0.20140, 2018.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 36.76s
- Epoch 074, ExpID 69699
Train - Loss (one batch): 0.06496
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06790, 0.06790, 0.26058, 0.20227, 2058.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 42.83s
- Epoch 075, ExpID 69699
Train - Loss (one batch): 0.06878
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26048, 0.20257, 2077.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 39.46s
- Epoch 076, ExpID 69699
Train - Loss (one batch): 0.06727
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06787, 0.06787, 0.26052, 0.20124, 2010.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 37.70s
- Epoch 077, ExpID 69699
Train - Loss (one batch): 0.06616
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26050, 0.20171, 2034.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 43.07s
- Epoch 078, ExpID 69699
Train - Loss (one batch): 0.06530
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06784, 0.06784, 0.26046, 0.20182, 2041.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 47.38s
- Epoch 079, ExpID 69699
Train - Loss (one batch): 0.06752
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06788, 0.06788, 0.26054, 0.20099, 1997.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 43.14s
- Epoch 080, ExpID 69699
Train - Loss (one batch): 0.07066
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26048, 0.20135, 2017.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 44.71s
- Epoch 081, ExpID 69699
Train - Loss (one batch): 0.07103
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06791, 0.06791, 0.26059, 0.20096, 1993.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 52.93s
- Epoch 082, ExpID 69699
Train - Loss (one batch): 0.07280
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06787, 0.06787, 0.26053, 0.20142, 2019.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 53.85s
- Epoch 083, ExpID 69699
Train - Loss (one batch): 0.07142
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06785, 0.06785, 0.26048, 0.20158, 2029.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 47.18s
- Epoch 084, ExpID 69699
Train - Loss (one batch): 0.06822
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06790, 0.06790, 0.26057, 0.20113, 2002.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 48.75s
- Epoch 085, ExpID 69699
Train - Loss (one batch): 0.06854
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06789, 0.06789, 0.26056, 0.20141, 2017.02%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 53.21s
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_baselines.py
2024-07-22 21:02:56
run_baselines.py --patience 10 --gpu 1 --dataset physionet --history 24 --model iTransformer
Namespace(state='def', n=100000000, epoch=100, patience=10, history=24, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='physionet', quantization=0.0, model='iTransformer', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=24, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='1', seq_len=128, top_k=5, num_kernels=64, npatch=1, device=device(type='cuda', index=0), PID=874292, pred_window=24, ndim=41, patch_layer=1, patch_size_list=[64, 32, 16], num_experts_list=[3, 3, 3], task_name='long_term_forecast', pred_len=720, output_attention=None, d_model=512, embed='timeF', freq='h', dropout=0.1, factor=3, d_ff=512, e_layers=4, n_heads=1, activation='gelu')
- Epoch 086, ExpID 69699
Train - Loss (one batch): 0.07342
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06790, 0.06790, 0.26057, 0.20180, 2036.43%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 53.68s
- Epoch 087, ExpID 69699
Train - Loss (one batch): 0.07154
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06787, 0.06787, 0.26052, 0.20169, 2032.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.05373, 0.05373, 0.23179, 0.17283, 1085.06%
Time spent: 54.16s
