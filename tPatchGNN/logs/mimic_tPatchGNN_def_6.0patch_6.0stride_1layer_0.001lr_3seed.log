/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_models.py
2024-07-22 12:50:28
run_models.py --dataset mimic --state def --history 24 --patience 10 --batch_size 16 --lr 1e-3 --patch_size 6 --stride 6 --nhead 1 --tf_layer 1 --nlayer 1 --hid_dim 8 --outlayer Linear --seed 3 --gpu 1 --alpha 1
Namespace(state='def', n=100000000, epoch=1000, patience=10, history=24, logmode='a', lr=0.001, w_decay=0.0, batch_size=16, viz=False, save='experiments/', load=None, seed=3, dataset='mimic', quantization=0.0, model='tPatchGNN', outlayer='Linear', hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=6.0, stride=6.0, hid_dim=8, te_dim=10, node_dim=10, alpha=1.0, res=1, gpu='1', npatch=4, device=device(type='cuda', index=0), PID=156929, pred_window=24, ndim=96, patch_layer=3, scale_patch_size=0.125)
- Epoch 000, ExpID 20694
Train - Loss (one batch): 0.02201
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03072, 0.03072, 0.17528, 0.11129, 235.30%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.03447, 0.03447, 0.18567, 0.11439, 210.09%
Time spent: 102.71s
- Epoch 001, ExpID 20694
Train - Loss (one batch): 0.02079
Val - Loss, MSE, RMSE, MAE, MAPE: 0.02353, 0.02353, 0.15338, 0.09538, 187.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.02654, 0.02654, 0.16290, 0.09818, 158.68%
Time spent: 102.89s
- Epoch 002, ExpID 20694
Train - Loss (one batch): 0.01487
Val - Loss, MSE, RMSE, MAE, MAPE: 0.02047, 0.02047, 0.14309, 0.08806, 169.57%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.02290, 0.02290, 0.15134, 0.09066, 142.24%
Time spent: 102.54s
- Epoch 003, ExpID 20694
Train - Loss (one batch): 0.01122
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01951, 0.01951, 0.13969, 0.08557, 166.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.02171, 0.02171, 0.14734, 0.08811, 142.18%
Time spent: 103.21s
- Epoch 004, ExpID 20694
Train - Loss (one batch): 0.01389
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01861, 0.01861, 0.13642, 0.08155, 149.43%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.02058, 0.02058, 0.14346, 0.08402, 126.78%
Time spent: 104.32s
- Epoch 005, ExpID 20694
Train - Loss (one batch): 0.01680
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01841, 0.01841, 0.13569, 0.08018, 157.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 5, 0.02013, 0.02013, 0.14187, 0.08253, 135.80%
Time spent: 99.49s
- Epoch 006, ExpID 20694
Train - Loss (one batch): 0.01090
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01846, 0.01846, 0.13585, 0.07963, 157.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 5, 0.02013, 0.02013, 0.14187, 0.08253, 135.80%
Time spent: 88.02s
- Epoch 007, ExpID 20694
Train - Loss (one batch): 0.02425
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01852, 0.01852, 0.13610, 0.08323, 182.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 5, 0.02013, 0.02013, 0.14187, 0.08253, 135.80%
Time spent: 85.67s
- Epoch 008, ExpID 20694
Train - Loss (one batch): 0.00648
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01766, 0.01766, 0.13288, 0.07631, 140.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 8, 0.01921, 0.01921, 0.13859, 0.07856, 121.00%
Time spent: 100.15s
- Epoch 009, ExpID 20694
Train - Loss (one batch): 0.00774
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01737, 0.01737, 0.13178, 0.07494, 143.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.01884, 0.01884, 0.13727, 0.07727, 126.15%
Time spent: 100.43s
- Epoch 010, ExpID 20694
Train - Loss (one batch): 0.00765
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01727, 0.01727, 0.13140, 0.07405, 126.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.01883, 0.01883, 0.13721, 0.07649, 109.10%
Time spent: 99.70s
- Epoch 011, ExpID 20694
Train - Loss (one batch): 0.01629
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01726, 0.01726, 0.13139, 0.07493, 117.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 11, 0.01868, 0.01868, 0.13668, 0.07704, 107.23%
Time spent: 99.96s
- Epoch 012, ExpID 20694
Train - Loss (one batch): 0.01366
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01752, 0.01752, 0.13236, 0.07654, 134.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 11, 0.01868, 0.01868, 0.13668, 0.07704, 107.23%
Time spent: 87.28s
- Epoch 013, ExpID 20694
Train - Loss (one batch): 0.01103
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01715, 0.01715, 0.13096, 0.07401, 123.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.01845, 0.01845, 0.13582, 0.07598, 112.50%
Time spent: 104.20s
- Epoch 014, ExpID 20694
Train - Loss (one batch): 0.01166
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01689, 0.01689, 0.12998, 0.07463, 140.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 14, 0.01825, 0.01825, 0.13508, 0.07646, 128.67%
Time spent: 103.71s
- Epoch 015, ExpID 20694
Train - Loss (one batch): 0.00535
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01699, 0.01699, 0.13034, 0.07384, 120.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 14, 0.01825, 0.01825, 0.13508, 0.07646, 128.67%
Time spent: 87.37s
- Epoch 016, ExpID 20694
Train - Loss (one batch): 0.01621
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01680, 0.01680, 0.12961, 0.07432, 147.83%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.01822, 0.01822, 0.13499, 0.07625, 131.82%
Time spent: 102.71s
- Epoch 017, ExpID 20694
Train - Loss (one batch): 0.00815
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01725, 0.01725, 0.13133, 0.07542, 134.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.01822, 0.01822, 0.13499, 0.07625, 131.82%
Time spent: 87.09s
- Epoch 018, ExpID 20694
Train - Loss (one batch): 0.01612
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01697, 0.01697, 0.13028, 0.07274, 110.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.01822, 0.01822, 0.13499, 0.07625, 131.82%
Time spent: 87.09s
- Epoch 019, ExpID 20694
Train - Loss (one batch): 0.01259
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01704, 0.01704, 0.13053, 0.07342, 114.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.01822, 0.01822, 0.13499, 0.07625, 131.82%
Time spent: 86.72s
- Epoch 020, ExpID 20694
Train - Loss (one batch): 0.00806
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01689, 0.01689, 0.12995, 0.07375, 131.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.01822, 0.01822, 0.13499, 0.07625, 131.82%
Time spent: 86.58s
- Epoch 021, ExpID 20694
Train - Loss (one batch): 0.00760
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01678, 0.01678, 0.12952, 0.07196, 116.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 21, 0.01806, 0.01806, 0.13439, 0.07394, 109.03%
Time spent: 102.51s
- Epoch 022, ExpID 20694
Train - Loss (one batch): 0.01430
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01705, 0.01705, 0.13056, 0.07527, 135.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 21, 0.01806, 0.01806, 0.13439, 0.07394, 109.03%
Time spent: 88.37s
- Epoch 023, ExpID 20694
Train - Loss (one batch): 0.01060
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01680, 0.01680, 0.12963, 0.07239, 121.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 21, 0.01806, 0.01806, 0.13439, 0.07394, 109.03%
Time spent: 86.45s
- Epoch 024, ExpID 20694
Train - Loss (one batch): 0.00497
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01666, 0.01666, 0.12907, 0.07277, 130.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 24, 0.01805, 0.01805, 0.13434, 0.07469, 122.93%
Time spent: 103.05s
- Epoch 025, ExpID 20694
Train - Loss (one batch): 0.00683
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01716, 0.01716, 0.13098, 0.07593, 147.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 24, 0.01805, 0.01805, 0.13434, 0.07469, 122.93%
Time spent: 87.38s
- Epoch 026, ExpID 20694
Train - Loss (one batch): 0.01583
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01671, 0.01671, 0.12928, 0.07243, 130.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 24, 0.01805, 0.01805, 0.13434, 0.07469, 122.93%
Time spent: 88.15s
- Epoch 027, ExpID 20694
Train - Loss (one batch): 0.01661
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01689, 0.01689, 0.12997, 0.07333, 126.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 24, 0.01805, 0.01805, 0.13434, 0.07469, 122.93%
Time spent: 89.50s
- Epoch 028, ExpID 20694
Train - Loss (one batch): 0.01621
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01673, 0.01673, 0.12933, 0.07146, 123.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 24, 0.01805, 0.01805, 0.13434, 0.07469, 122.93%
Time spent: 87.27s
- Epoch 029, ExpID 20694
Train - Loss (one batch): 0.02946
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01669, 0.01669, 0.12918, 0.07253, 135.09%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 24, 0.01805, 0.01805, 0.13434, 0.07469, 122.93%
Time spent: 88.00s
- Epoch 030, ExpID 20694
Train - Loss (one batch): 0.00654
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01679, 0.01679, 0.12959, 0.07158, 129.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 24, 0.01805, 0.01805, 0.13434, 0.07469, 122.93%
Time spent: 88.07s
- Epoch 031, ExpID 20694
Train - Loss (one batch): 0.01300
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01681, 0.01681, 0.12967, 0.07369, 142.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 24, 0.01805, 0.01805, 0.13434, 0.07469, 122.93%
Time spent: 89.77s
- Epoch 032, ExpID 20694
Train - Loss (one batch): 0.01131
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01687, 0.01687, 0.12988, 0.07292, 135.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 24, 0.01805, 0.01805, 0.13434, 0.07469, 122.93%
Time spent: 86.45s
- Epoch 033, ExpID 20694
Train - Loss (one batch): 0.00494
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01683, 0.01683, 0.12974, 0.07353, 136.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 24, 0.01805, 0.01805, 0.13434, 0.07469, 122.93%
Time spent: 88.35s
- Epoch 034, ExpID 20694
Train - Loss (one batch): 0.01016
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01679, 0.01679, 0.12959, 0.07305, 126.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 24, 0.01805, 0.01805, 0.13434, 0.07469, 122.93%
Time spent: 87.81s
