/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_iTransformer.py
2024-07-19 16:18:18
run_iTransformer.py --history 24 --model iTransformer --dataset mimic
Namespace(state='def', n=100000000, epoch=100, patience=10, history=24, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='mimic', quantization=0.0, model='iTransformer', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=24, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='0', seq_len=280, top_k=5, num_kernels=64, npatch=1, device=device(type='cuda', index=0), PID=1982474, pred_window=24, ndim=96, patch_layer=1, task_name='long_term_forecast', pred_len=720, output_attention=None, d_model=512, embed='timeF', freq='h', dropout=0.1, factor=3, d_ff=512, e_layers=4, n_heads=1, activation='gelu')
- Epoch 000, ExpID 73081
Train - Loss (one batch): 0.07365
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07125, 0.07125, 0.26694, 0.21656, 852.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07571, 0.07571, 0.27516, 0.21899, 790.50%
Time spent: 131.20s
- Epoch 001, ExpID 73081
Train - Loss (one batch): 0.07887
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07329, 0.07329, 0.27072, 0.22848, 993.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07571, 0.07571, 0.27516, 0.21899, 790.50%
Time spent: 115.44s
- Epoch 002, ExpID 73081
Train - Loss (one batch): 0.06916
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07150, 0.07150, 0.26739, 0.21918, 882.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07571, 0.07571, 0.27516, 0.21899, 790.50%
Time spent: 117.01s
- Epoch 003, ExpID 73081
Train - Loss (one batch): 0.08596
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07097, 0.07097, 0.26641, 0.21781, 886.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 128.35s
- Epoch 004, ExpID 73081
Train - Loss (one batch): 0.08150
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07133, 0.07133, 0.26708, 0.21706, 855.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.80s
- Epoch 005, ExpID 73081
Train - Loss (one batch): 0.07166
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07197, 0.07197, 0.26827, 0.22235, 916.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 114.95s
- Epoch 006, ExpID 73081
Train - Loss (one batch): 0.07363
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07270, 0.07270, 0.26964, 0.22601, 954.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.64s
- Epoch 007, ExpID 73081
Train - Loss (one batch): 0.07162
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07137, 0.07137, 0.26715, 0.21252, 798.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.14s
- Epoch 008, ExpID 73081
Train - Loss (one batch): 0.07471
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07512, 0.07512, 0.27408, 0.23413, 1033.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.36s
- Epoch 009, ExpID 73081
Train - Loss (one batch): 0.07832
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07154, 0.07154, 0.26747, 0.21919, 880.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.55s
- Epoch 010, ExpID 73081
Train - Loss (one batch): 0.07580
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07181, 0.07181, 0.26798, 0.22152, 907.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.71s
- Epoch 011, ExpID 73081
Train - Loss (one batch): 0.08061
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07143, 0.07143, 0.26727, 0.21856, 871.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.07s
- Epoch 012, ExpID 73081
Train - Loss (one batch): 0.07969
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07130, 0.07130, 0.26702, 0.21667, 850.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.38s
- Epoch 013, ExpID 73081
Train - Loss (one batch): 0.07767
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07130, 0.07130, 0.26702, 0.21794, 865.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.85s
- Epoch 014, ExpID 73081
Train - Loss (one batch): 0.06499
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07156, 0.07156, 0.26750, 0.21961, 883.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.86s
- Epoch 015, ExpID 73081
Train - Loss (one batch): 0.08354
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07153, 0.07153, 0.26745, 0.21933, 882.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 118.28s
- Epoch 016, ExpID 73081
Train - Loss (one batch): 0.06678
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07148, 0.07148, 0.26736, 0.21876, 875.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.71s
- Epoch 017, ExpID 73081
Train - Loss (one batch): 0.07432
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07125, 0.07125, 0.26693, 0.21602, 841.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.14s
- Epoch 018, ExpID 73081
Train - Loss (one batch): 0.07430
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07127, 0.07127, 0.26697, 0.21627, 836.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 119.68s
- Epoch 019, ExpID 73081
Train - Loss (one batch): 0.06997
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07114, 0.07114, 0.26673, 0.21500, 817.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 117.14s
- Epoch 020, ExpID 73081
Train - Loss (one batch): 0.07813
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07142, 0.07142, 0.26724, 0.22021, 876.85%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.88s
- Epoch 021, ExpID 73081
Train - Loss (one batch): 0.07206
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07121, 0.07121, 0.26686, 0.21781, 848.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.66s
- Epoch 022, ExpID 73081
Train - Loss (one batch): 0.05948
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07113, 0.07113, 0.26670, 0.21701, 838.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.60s
- Epoch 023, ExpID 73081
Train - Loss (one batch): 0.06662
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07168, 0.07168, 0.26774, 0.22227, 896.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.21s
- Epoch 024, ExpID 73081
Train - Loss (one batch): 0.08066
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07106, 0.07106, 0.26658, 0.21618, 826.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 127.12s
- Epoch 025, ExpID 73081
Train - Loss (one batch): 0.06856
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07140, 0.07140, 0.26721, 0.22056, 877.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 120.94s
- Epoch 026, ExpID 73081
Train - Loss (one batch): 0.07347
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07127, 0.07127, 0.26696, 0.21627, 830.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.29s
- Epoch 027, ExpID 73081
Train - Loss (one batch): 0.06779
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07116, 0.07116, 0.26677, 0.21673, 834.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.41s
- Epoch 028, ExpID 73081
Train - Loss (one batch): 0.07835
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07120, 0.07120, 0.26682, 0.21898, 856.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 117.12s
- Epoch 029, ExpID 73081
Train - Loss (one batch): 0.07401
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07126, 0.07126, 0.26695, 0.21554, 822.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.57s
- Epoch 030, ExpID 73081
Train - Loss (one batch): 0.07344
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07111, 0.07111, 0.26667, 0.21716, 835.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.86s
- Epoch 031, ExpID 73081
Train - Loss (one batch): 0.08243
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07123, 0.07123, 0.26690, 0.21809, 849.10%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.32s
- Epoch 032, ExpID 73081
Train - Loss (one batch): 0.07055
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07129, 0.07129, 0.26700, 0.21992, 865.99%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.14s
- Epoch 033, ExpID 73081
Train - Loss (one batch): 0.06930
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07132, 0.07132, 0.26706, 0.21956, 865.03%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 114.88s
- Epoch 034, ExpID 73081
Train - Loss (one batch): 0.07552
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07124, 0.07124, 0.26690, 0.21594, 826.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.76s
- Epoch 035, ExpID 73081
Train - Loss (one batch): 0.07577
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07124, 0.07124, 0.26691, 0.21640, 831.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.33s
- Epoch 036, ExpID 73081
Train - Loss (one batch): 0.07510
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07132, 0.07132, 0.26705, 0.21950, 864.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.36s
- Epoch 037, ExpID 73081
Train - Loss (one batch): 0.07726
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07116, 0.07116, 0.26676, 0.21851, 850.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.62s
- Epoch 038, ExpID 73081
Train - Loss (one batch): 0.08804
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07106, 0.07106, 0.26657, 0.21573, 818.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.61s
- Epoch 039, ExpID 73081
Train - Loss (one batch): 0.07107
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07121, 0.07121, 0.26684, 0.21606, 826.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.48s
- Epoch 040, ExpID 73081
Train - Loss (one batch): 0.07238
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07104, 0.07104, 0.26653, 0.21629, 823.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.70s
- Epoch 041, ExpID 73081
Train - Loss (one batch): 0.07449
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07115, 0.07115, 0.26675, 0.21747, 840.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.59s
- Epoch 042, ExpID 73081
Train - Loss (one batch): 0.07013
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07120, 0.07120, 0.26683, 0.21762, 843.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.46s
- Epoch 043, ExpID 73081
Train - Loss (one batch): 0.07588
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07111, 0.07111, 0.26666, 0.21731, 837.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.82s
- Epoch 044, ExpID 73081
Train - Loss (one batch): 0.07114
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07112, 0.07112, 0.26667, 0.21582, 821.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 122.10s
- Epoch 045, ExpID 73081
Train - Loss (one batch): 0.06885
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07107, 0.07107, 0.26659, 0.21716, 834.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 123.88s
- Epoch 046, ExpID 73081
Train - Loss (one batch): 0.07298
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07120, 0.07120, 0.26683, 0.21692, 836.35%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 114.91s
- Epoch 047, ExpID 73081
Train - Loss (one batch): 0.06961
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07125, 0.07125, 0.26693, 0.21564, 823.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 117.11s
- Epoch 048, ExpID 73081
Train - Loss (one batch): 0.07161
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07119, 0.07119, 0.26681, 0.21569, 822.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.86s
- Epoch 049, ExpID 73081
Train - Loss (one batch): 0.08031
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07117, 0.07117, 0.26678, 0.21685, 834.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.62s
- Epoch 050, ExpID 73081
Train - Loss (one batch): 0.07419
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07115, 0.07115, 0.26673, 0.21770, 842.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.19s
- Epoch 051, ExpID 73081
Train - Loss (one batch): 0.06886
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07115, 0.07115, 0.26674, 0.21600, 824.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.94s
- Epoch 052, ExpID 73081
Train - Loss (one batch): 0.07202
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07115, 0.07115, 0.26675, 0.21582, 822.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.70s
- Epoch 053, ExpID 73081
Train - Loss (one batch): 0.07465
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07118, 0.07118, 0.26679, 0.21690, 835.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.69s
- Epoch 054, ExpID 73081
Train - Loss (one batch): 0.08199
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07124, 0.07124, 0.26690, 0.21904, 857.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.46s
- Epoch 055, ExpID 73081
Train - Loss (one batch): 0.07070
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07119, 0.07119, 0.26681, 0.21668, 833.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.49s
- Epoch 056, ExpID 73081
Train - Loss (one batch): 0.08121
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07114, 0.07114, 0.26673, 0.21614, 826.03%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.50s
- Epoch 057, ExpID 73081
Train - Loss (one batch): 0.08086
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07103, 0.07103, 0.26652, 0.21672, 827.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.37s
- Epoch 058, ExpID 73081
Train - Loss (one batch): 0.07485
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07108, 0.07108, 0.26661, 0.21588, 826.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.93s
- Epoch 059, ExpID 73081
Train - Loss (one batch): 0.07399
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07114, 0.07114, 0.26672, 0.21677, 832.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 117.18s
- Epoch 060, ExpID 73081
Train - Loss (one batch): 0.06996
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07119, 0.07119, 0.26681, 0.21683, 835.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.28s
- Epoch 061, ExpID 73081
Train - Loss (one batch): 0.10100
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07112, 0.07112, 0.26668, 0.21681, 834.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.78s
- Epoch 062, ExpID 73081
Train - Loss (one batch): 0.07875
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07106, 0.07106, 0.26657, 0.21815, 851.74%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.68s
- Epoch 063, ExpID 73081
Train - Loss (one batch): 0.07986
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07106, 0.07106, 0.26658, 0.21743, 845.18%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.14s
- Epoch 064, ExpID 73081
Train - Loss (one batch): 0.07656
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07103, 0.07103, 0.26651, 0.21579, 828.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.91s
- Epoch 065, ExpID 73081
Train - Loss (one batch): 0.06816
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07104, 0.07104, 0.26653, 0.21634, 832.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.99s
- Epoch 066, ExpID 73081
Train - Loss (one batch): 0.07255
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07094, 0.07094, 0.26635, 0.21643, 831.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 129.60s
- Epoch 067, ExpID 73081
Train - Loss (one batch): 0.07563
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07105, 0.07105, 0.26655, 0.21843, 853.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 117.08s
- Epoch 068, ExpID 73081
Train - Loss (one batch): 0.06944
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07101, 0.07101, 0.26648, 0.21728, 842.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 117.05s
- Epoch 069, ExpID 73081
Train - Loss (one batch): 0.07557
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07097, 0.07097, 0.26640, 0.21552, 821.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 116.26s
- Epoch 070, ExpID 73081
Train - Loss (one batch): 0.07989
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07099, 0.07099, 0.26644, 0.21746, 844.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 116.66s
- Epoch 071, ExpID 73081
Train - Loss (one batch): 0.06703
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07102, 0.07102, 0.26649, 0.21660, 836.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 116.87s
- Epoch 072, ExpID 73081
Train - Loss (one batch): 0.07638
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07116, 0.07116, 0.26676, 0.21926, 863.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 116.04s
- Epoch 073, ExpID 73081
Train - Loss (one batch): 0.07265
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07108, 0.07108, 0.26660, 0.21683, 837.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 117.13s
- Epoch 074, ExpID 73081
Train - Loss (one batch): 0.07512
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07103, 0.07103, 0.26652, 0.21839, 854.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 116.38s
- Epoch 075, ExpID 73081
Train - Loss (one batch): 0.07964
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07102, 0.07102, 0.26649, 0.21817, 850.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 117.60s
- Epoch 076, ExpID 73081
Train - Loss (one batch): 0.06050
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07101, 0.07101, 0.26649, 0.21647, 833.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 115.59s
- Epoch 077, ExpID 73081
Train - Loss (one batch): 0.07476
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07118, 0.07118, 0.26680, 0.21842, 858.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 115.93s
- Epoch 078, ExpID 73081
Train - Loss (one batch): 0.07897
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07101, 0.07101, 0.26648, 0.21707, 840.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 117.45s
- Epoch 079, ExpID 73081
Train - Loss (one batch): 0.07489
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07096, 0.07096, 0.26639, 0.21732, 840.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 116.14s
- Epoch 080, ExpID 73081
Train - Loss (one batch): 0.06856
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07102, 0.07102, 0.26650, 0.21533, 821.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 116.71s
- Epoch 081, ExpID 73081
Train - Loss (one batch): 0.06949
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07101, 0.07101, 0.26649, 0.21864, 853.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 116.28s
- Epoch 082, ExpID 73081
Train - Loss (one batch): 0.07955
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07106, 0.07106, 0.26657, 0.21598, 831.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 116.11s
- Epoch 083, ExpID 73081
Train - Loss (one batch): 0.07740
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07098, 0.07098, 0.26641, 0.21623, 830.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 116.70s
- Epoch 084, ExpID 73081
Train - Loss (one batch): 0.08254
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07100, 0.07100, 0.26646, 0.21673, 835.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 116.29s
- Epoch 085, ExpID 73081
Train - Loss (one batch): 0.07830
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07090, 0.07090, 0.26628, 0.21671, 832.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 128.29s
- Epoch 086, ExpID 73081
Train - Loss (one batch): 0.06781
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07100, 0.07100, 0.26646, 0.21791, 846.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 119.50s
- Epoch 087, ExpID 73081
Train - Loss (one batch): 0.07804
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07093, 0.07093, 0.26633, 0.21604, 826.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 136.06s
- Epoch 088, ExpID 73081
Train - Loss (one batch): 0.06762
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07104, 0.07104, 0.26653, 0.21656, 835.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 137.13s
- Epoch 089, ExpID 73081
Train - Loss (one batch): 0.07889
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07097, 0.07097, 0.26640, 0.21654, 834.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 135.92s
- Epoch 090, ExpID 73081
Train - Loss (one batch): 0.07345
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07094, 0.07094, 0.26635, 0.21686, 836.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 135.24s
- Epoch 091, ExpID 73081
Train - Loss (one batch): 0.06858
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07100, 0.07100, 0.26646, 0.21851, 851.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 128.59s
- Epoch 092, ExpID 73081
Train - Loss (one batch): 0.06851
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07092, 0.07092, 0.26631, 0.21656, 832.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 114.66s
- Epoch 093, ExpID 73081
Train - Loss (one batch): 0.06977
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07111, 0.07111, 0.26667, 0.21729, 843.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 118.04s
- Epoch 094, ExpID 73081
Train - Loss (one batch): 0.06666
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07109, 0.07109, 0.26662, 0.21607, 832.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 115.63s
- Epoch 095, ExpID 73081
Train - Loss (one batch): 0.07040
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07104, 0.07104, 0.26653, 0.21835, 853.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 116.02s
- Epoch 096, ExpID 73081
Train - Loss (one batch): 0.07244
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07100, 0.07100, 0.26646, 0.21693, 838.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 115.36s
- Epoch 097, ExpID 73081
Train - Loss (one batch): 0.07578
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07100, 0.07100, 0.26646, 0.21729, 843.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 115.90s
- Epoch 098, ExpID 73081
Train - Loss (one batch): 0.07122
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07100, 0.07100, 0.26646, 0.21788, 847.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 117.12s
- Epoch 099, ExpID 73081
Train - Loss (one batch): 0.07353
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07098, 0.07098, 0.26641, 0.21736, 841.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 115.17s
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_iTransformer.py
2024-07-19 19:37:45
run_iTransformer.py --history 36 --model iTransformer --dataset mimic
Namespace(state='def', n=100000000, epoch=100, patience=10, history=36, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='mimic', quantization=0.0, model='iTransformer', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=24, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='0', seq_len=464, top_k=5, num_kernels=64, npatch=2, device=device(type='cuda', index=0), PID=2106113, pred_window=12, ndim=96, patch_layer=2, task_name='long_term_forecast', pred_len=720, output_attention=None, d_model=512, embed='timeF', freq='h', dropout=0.1, factor=3, d_ff=512, e_layers=4, n_heads=1, activation='gelu')
- Epoch 000, ExpID 30162
Train - Loss (one batch): 0.07799
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06866, 0.06866, 0.26202, 0.20672, 696.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 73.81s
- Epoch 001, ExpID 30162
Train - Loss (one batch): 0.07370
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26435, 0.21372, 778.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.69s
- Epoch 002, ExpID 30162
Train - Loss (one batch): 0.06950
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06964, 0.06964, 0.26389, 0.20873, 726.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 66.25s
- Epoch 003, ExpID 30162
Train - Loss (one batch): 0.05623
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07006, 0.07006, 0.26468, 0.21473, 787.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.16s
- Epoch 004, ExpID 30162
Train - Loss (one batch): 0.06341
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06981, 0.06981, 0.26421, 0.20987, 735.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.46s
- Epoch 005, ExpID 30162
Train - Loss (one batch): 0.07468
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06994, 0.06994, 0.26446, 0.21282, 765.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.27s
- Epoch 006, ExpID 30162
Train - Loss (one batch): 0.06581
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06997, 0.06997, 0.26451, 0.20701, 701.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.12s
- Epoch 007, ExpID 30162
Train - Loss (one batch): 0.05903
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06984, 0.06984, 0.26427, 0.21263, 766.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.90s
- Epoch 008, ExpID 30162
Train - Loss (one batch): 0.06444
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06981, 0.06981, 0.26421, 0.21172, 756.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.38s
- Epoch 009, ExpID 30162
Train - Loss (one batch): 0.06315
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07005, 0.07005, 0.26468, 0.21492, 790.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.62s
- Epoch 010, ExpID 30162
Train - Loss (one batch): 0.08195
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06999, 0.06999, 0.26456, 0.21424, 782.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.97s
- Epoch 011, ExpID 30162
Train - Loss (one batch): 0.05158
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06978, 0.06978, 0.26416, 0.21083, 746.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.72s
- Epoch 012, ExpID 30162
Train - Loss (one batch): 0.06563
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06981, 0.06981, 0.26421, 0.20911, 727.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.22s
- Epoch 013, ExpID 30162
Train - Loss (one batch): 0.06887
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06979, 0.06979, 0.26418, 0.21009, 738.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.20s
- Epoch 014, ExpID 30162
Train - Loss (one batch): 0.07258
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06981, 0.06981, 0.26421, 0.21127, 751.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.96s
- Epoch 015, ExpID 30162
Train - Loss (one batch): 0.06479
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06981, 0.06981, 0.26422, 0.21066, 744.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.62s
- Epoch 016, ExpID 30162
Train - Loss (one batch): 0.07007
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06984, 0.06984, 0.26426, 0.21135, 751.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.46s
- Epoch 017, ExpID 30162
Train - Loss (one batch): 0.06943
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21134, 751.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.18s
- Epoch 018, ExpID 30162
Train - Loss (one batch): 0.06164
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26432, 0.21098, 746.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.16s
- Epoch 019, ExpID 30162
Train - Loss (one batch): 0.06647
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06989, 0.06989, 0.26437, 0.20884, 722.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.36s
- Epoch 020, ExpID 30162
Train - Loss (one batch): 0.05979
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06985, 0.06985, 0.26429, 0.21031, 739.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.31s
- Epoch 021, ExpID 30162
Train - Loss (one batch): 0.07134
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06997, 0.06997, 0.26451, 0.21318, 770.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.68s
- Epoch 022, ExpID 30162
Train - Loss (one batch): 0.06677
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26434, 0.20932, 728.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.95s
- Epoch 023, ExpID 30162
Train - Loss (one batch): 0.07364
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26435, 0.21159, 753.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.31s
- Epoch 024, ExpID 30162
Train - Loss (one batch): 0.06939
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21008, 736.99%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.03s
- Epoch 025, ExpID 30162
Train - Loss (one batch): 0.06135
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06993, 0.06993, 0.26444, 0.21263, 764.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.36s
- Epoch 026, ExpID 30162
Train - Loss (one batch): 0.06466
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26434, 0.21154, 752.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.17s
- Epoch 027, ExpID 30162
Train - Loss (one batch): 0.07300
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06989, 0.06989, 0.26436, 0.21182, 756.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.66s
- Epoch 028, ExpID 30162
Train - Loss (one batch): 0.07631
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21045, 741.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.28s
- Epoch 029, ExpID 30162
Train - Loss (one batch): 0.07008
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26433, 0.20950, 730.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.22s
- Epoch 030, ExpID 30162
Train - Loss (one batch): 0.05081
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26434, 0.20924, 727.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 66.04s
- Epoch 031, ExpID 30162
Train - Loss (one batch): 0.05875
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21065, 743.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.13s
- Epoch 032, ExpID 30162
Train - Loss (one batch): 0.06896
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26432, 0.20963, 731.83%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.48s
- Epoch 033, ExpID 30162
Train - Loss (one batch): 0.06411
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26435, 0.21159, 753.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.58s
- Epoch 034, ExpID 30162
Train - Loss (one batch): 0.05163
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06989, 0.06989, 0.26437, 0.21190, 756.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.29s
- Epoch 035, ExpID 30162
Train - Loss (one batch): 0.06800
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21012, 737.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.13s
- Epoch 036, ExpID 30162
Train - Loss (one batch): 0.06504
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21078, 744.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.29s
- Epoch 037, ExpID 30162
Train - Loss (one batch): 0.06461
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21039, 740.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.09s
- Epoch 038, ExpID 30162
Train - Loss (one batch): 0.06054
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.20996, 735.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.36s
- Epoch 039, ExpID 30162
Train - Loss (one batch): 0.06059
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06998, 0.06998, 0.26454, 0.21342, 772.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.50s
- Epoch 040, ExpID 30162
Train - Loss (one batch): 0.05553
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26433, 0.21136, 751.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.25s
- Epoch 041, ExpID 30162
Train - Loss (one batch): 0.07474
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26433, 0.21117, 749.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.74s
- Epoch 042, ExpID 30162
Train - Loss (one batch): 0.06510
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26432, 0.21100, 747.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.28s
- Epoch 043, ExpID 30162
Train - Loss (one batch): 0.06436
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06996, 0.06996, 0.26451, 0.20777, 709.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.96s
- Epoch 044, ExpID 30162
Train - Loss (one batch): 0.06120
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21004, 736.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.46s
- Epoch 045, ExpID 30162
Train - Loss (one batch): 0.06275
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26436, 0.21172, 754.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.34s
- Epoch 046, ExpID 30162
Train - Loss (one batch): 0.06500
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26436, 0.21170, 754.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.27s
- Epoch 047, ExpID 30162
Train - Loss (one batch): 0.06222
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26432, 0.20972, 732.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.21s
- Epoch 048, ExpID 30162
Train - Loss (one batch): 0.05829
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26435, 0.21157, 753.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 75.16s
- Epoch 049, ExpID 30162
Train - Loss (one batch): 0.07969
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06990, 0.06990, 0.26438, 0.21205, 758.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 75.92s
- Epoch 050, ExpID 30162
Train - Loss (one batch): 0.07150
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26435, 0.21161, 753.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 77.23s
- Epoch 051, ExpID 30162
Train - Loss (one batch): 0.06871
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26432, 0.21095, 746.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 76.05s
- Epoch 052, ExpID 30162
Train - Loss (one batch): 0.07350
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06990, 0.06990, 0.26438, 0.21206, 758.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 76.73s
- Epoch 053, ExpID 30162
Train - Loss (one batch): 0.05681
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06989, 0.06989, 0.26436, 0.21173, 755.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 76.01s
- Epoch 054, ExpID 30162
Train - Loss (one batch): 0.06849
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26434, 0.21144, 751.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 76.06s
- Epoch 055, ExpID 30162
Train - Loss (one batch): 0.05925
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26434, 0.21147, 752.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 75.81s
- Epoch 056, ExpID 30162
Train - Loss (one batch): 0.06648
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26432, 0.21108, 748.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 76.84s
- Epoch 057, ExpID 30162
Train - Loss (one batch): 0.06768
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21030, 739.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 77.28s
- Epoch 058, ExpID 30162
Train - Loss (one batch): 0.07644
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21026, 738.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 76.51s
- Epoch 059, ExpID 30162
Train - Loss (one batch): 0.06258
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.20984, 734.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 76.66s
- Epoch 060, ExpID 30162
Train - Loss (one batch): 0.06767
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06991, 0.06991, 0.26440, 0.21225, 760.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 76.57s
- Epoch 061, ExpID 30162
Train - Loss (one batch): 0.07193
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21012, 737.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 90.01s
- Epoch 062, ExpID 30162
Train - Loss (one batch): 0.06308
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26434, 0.21147, 752.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 96.60s
- Epoch 063, ExpID 30162
Train - Loss (one batch): 0.06509
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21032, 739.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 96.67s
- Epoch 064, ExpID 30162
Train - Loss (one batch): 0.07536
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21071, 743.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 96.98s
- Epoch 065, ExpID 30162
Train - Loss (one batch): 0.07077
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21069, 743.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 97.73s
- Epoch 066, ExpID 30162
Train - Loss (one batch): 0.07006
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26432, 0.20977, 733.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 97.30s
- Epoch 067, ExpID 30162
Train - Loss (one batch): 0.08869
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26433, 0.20945, 729.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 97.59s
- Epoch 068, ExpID 30162
Train - Loss (one batch): 0.07095
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26433, 0.21121, 749.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 96.51s
- Epoch 069, ExpID 30162
Train - Loss (one batch): 0.06695
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06998, 0.06998, 0.26453, 0.21332, 771.85%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 96.20s
- Epoch 070, ExpID 30162
Train - Loss (one batch): 0.06173
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06989, 0.06989, 0.26436, 0.21173, 755.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 97.10s
- Epoch 071, ExpID 30162
Train - Loss (one batch): 0.06856
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21029, 739.30%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 96.60s
- Epoch 072, ExpID 30162
Train - Loss (one batch): 0.06192
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26432, 0.20969, 732.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 97.16s
- Epoch 073, ExpID 30162
Train - Loss (one batch): 0.07430
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21050, 741.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 97.20s
- Epoch 074, ExpID 30162
Train - Loss (one batch): 0.07602
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21032, 739.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 97.83s
- Epoch 075, ExpID 30162
Train - Loss (one batch): 0.06670
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26434, 0.21153, 752.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 97.15s
- Epoch 076, ExpID 30162
Train - Loss (one batch): 0.06597
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21032, 739.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 97.51s
- Epoch 077, ExpID 30162
Train - Loss (one batch): 0.06249
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21064, 743.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 97.03s
- Epoch 078, ExpID 30162
Train - Loss (one batch): 0.07370
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06991, 0.06991, 0.26440, 0.21223, 760.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 96.72s
- Epoch 079, ExpID 30162
Train - Loss (one batch): 0.06542
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26433, 0.21127, 750.09%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 97.17s
- Epoch 080, ExpID 30162
Train - Loss (one batch): 0.06014
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21070, 743.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 97.90s
- Epoch 081, ExpID 30162
Train - Loss (one batch): 0.06462
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26432, 0.21097, 746.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 96.69s
- Epoch 082, ExpID 30162
Train - Loss (one batch): 0.06923
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.20993, 735.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 96.23s
- Epoch 083, ExpID 30162
Train - Loss (one batch): 0.06024
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26434, 0.21150, 752.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 96.59s
- Epoch 084, ExpID 30162
Train - Loss (one batch): 0.06473
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21079, 744.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 95.84s
- Epoch 085, ExpID 30162
Train - Loss (one batch): 0.06807
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06989, 0.06989, 0.26436, 0.21182, 756.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 97.32s
- Epoch 086, ExpID 30162
Train - Loss (one batch): 0.06324
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26433, 0.21136, 751.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 97.54s
- Epoch 087, ExpID 30162
Train - Loss (one batch): 0.06317
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06992, 0.06992, 0.26443, 0.21250, 763.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 96.62s
- Epoch 088, ExpID 30162
Train - Loss (one batch): 0.06389
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26436, 0.21172, 754.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 97.14s
- Epoch 089, ExpID 30162
Train - Loss (one batch): 0.07835
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26433, 0.21121, 749.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 97.08s
- Epoch 090, ExpID 30162
Train - Loss (one batch): 0.06422
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21049, 741.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 97.17s
- Epoch 091, ExpID 30162
Train - Loss (one batch): 0.07513
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26432, 0.20968, 732.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 96.84s
- Epoch 092, ExpID 30162
Train - Loss (one batch): 0.06535
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21063, 743.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 98.04s
- Epoch 093, ExpID 30162
Train - Loss (one batch): 0.06454
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06991, 0.06991, 0.26440, 0.21222, 760.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 77.95s
- Epoch 094, ExpID 30162
Train - Loss (one batch): 0.05238
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26433, 0.21119, 749.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 76.44s
- Epoch 095, ExpID 30162
Train - Loss (one batch): 0.06385
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06993, 0.06993, 0.26445, 0.21270, 765.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 77.09s
- Epoch 096, ExpID 30162
Train - Loss (one batch): 0.05735
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21035, 739.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 77.01s
- Epoch 097, ExpID 30162
Train - Loss (one batch): 0.05959
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26432, 0.21115, 748.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 76.62s
- Epoch 098, ExpID 30162
Train - Loss (one batch): 0.06648
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26435, 0.21155, 753.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 76.73s
- Epoch 099, ExpID 30162
Train - Loss (one batch): 0.06690
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26432, 0.21112, 748.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 75.80s
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_iTransformer.py
2024-07-19 21:52:45
run_iTransformer.py --history 24 --model iTransformer --dataset mimic --gpu 2
Namespace(state='def', n=100000000, epoch=100, patience=10, history=24, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='mimic', quantization=0.0, model='iTransformer', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=24, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='2', seq_len=280, top_k=5, num_kernels=64, npatch=1, device=device(type='cuda', index=0), PID=2185121, pred_window=24, ndim=96, patch_layer=1, task_name='long_term_forecast', pred_len=720, output_attention=None, d_model=512, embed='timeF', freq='h', dropout=0.1, factor=3, d_ff=512, e_layers=4, n_heads=1, activation='gelu')
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_iTransformer.py
2024-07-19 21:53:45
run_iTransformer.py --history 12 --model iTransformer --dataset mimic
Namespace(state='def', n=100000000, epoch=100, patience=10, history=12, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='mimic', quantization=0.0, model='iTransformer', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=24, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='0', seq_len=133, top_k=5, num_kernels=64, npatch=1, device=device(type='cuda', index=0), PID=2185381, pred_window=36, ndim=96, patch_layer=1, task_name='long_term_forecast', pred_len=720, output_attention=None, d_model=512, embed='timeF', freq='h', dropout=0.1, factor=3, d_ff=512, e_layers=4, n_heads=1, activation='gelu')
- Epoch 000, ExpID 3720
Train - Loss (one batch): 0.07365
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07125, 0.07125, 0.26694, 0.21656, 852.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07571, 0.07571, 0.27516, 0.21899, 790.50%
Time spent: 150.99s
- Epoch 001, ExpID 3720
Train - Loss (one batch): 0.07887
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07329, 0.07329, 0.27072, 0.22848, 993.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07571, 0.07571, 0.27516, 0.21899, 790.50%
Time spent: 139.51s
- Epoch 002, ExpID 3720
Train - Loss (one batch): 0.06916
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07150, 0.07150, 0.26739, 0.21918, 882.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07571, 0.07571, 0.27516, 0.21899, 790.50%
Time spent: 141.91s
- Epoch 003, ExpID 3720
Train - Loss (one batch): 0.08596
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07097, 0.07097, 0.26641, 0.21781, 886.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 155.50s
- Epoch 004, ExpID 3720
Train - Loss (one batch): 0.08150
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07133, 0.07133, 0.26708, 0.21706, 855.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 141.00s
- Epoch 005, ExpID 3720
Train - Loss (one batch): 0.07166
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07197, 0.07197, 0.26827, 0.22235, 916.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 139.66s
- Epoch 006, ExpID 3720
Train - Loss (one batch): 0.07363
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07270, 0.07270, 0.26964, 0.22601, 954.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 139.89s
- Epoch 007, ExpID 3720
Train - Loss (one batch): 0.07162
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07137, 0.07137, 0.26715, 0.21252, 798.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 139.19s
- Epoch 008, ExpID 3720
Train - Loss (one batch): 0.07471
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07512, 0.07512, 0.27408, 0.23413, 1033.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 140.41s
- Epoch 009, ExpID 3720
Train - Loss (one batch): 0.07832
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07154, 0.07154, 0.26747, 0.21919, 880.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 141.52s
- Epoch 010, ExpID 3720
Train - Loss (one batch): 0.07580
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07181, 0.07181, 0.26798, 0.22152, 907.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 139.41s
- Epoch 011, ExpID 3720
Train - Loss (one batch): 0.08061
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07143, 0.07143, 0.26727, 0.21856, 871.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 140.00s
- Epoch 012, ExpID 3720
Train - Loss (one batch): 0.07969
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07130, 0.07130, 0.26702, 0.21667, 850.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 139.95s
- Epoch 013, ExpID 3720
Train - Loss (one batch): 0.07767
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07130, 0.07130, 0.26702, 0.21794, 865.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 140.62s
- Epoch 014, ExpID 3720
Train - Loss (one batch): 0.06499
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07156, 0.07156, 0.26750, 0.21961, 883.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 140.08s
- Epoch 015, ExpID 3720
Train - Loss (one batch): 0.08354
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07153, 0.07153, 0.26745, 0.21933, 882.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 141.03s
- Epoch 016, ExpID 3720
Train - Loss (one batch): 0.06678
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07148, 0.07148, 0.26736, 0.21876, 875.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 141.84s
- Epoch 017, ExpID 3720
Train - Loss (one batch): 0.07432
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07125, 0.07125, 0.26693, 0.21602, 841.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 139.16s
- Epoch 018, ExpID 3720
Train - Loss (one batch): 0.07430
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07127, 0.07127, 0.26697, 0.21627, 836.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 141.12s
- Epoch 019, ExpID 3720
Train - Loss (one batch): 0.06997
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07114, 0.07114, 0.26673, 0.21500, 817.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 142.45s
- Epoch 020, ExpID 3720
Train - Loss (one batch): 0.07813
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07142, 0.07142, 0.26724, 0.22021, 876.85%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 139.70s
- Epoch 021, ExpID 3720
Train - Loss (one batch): 0.07206
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07121, 0.07121, 0.26686, 0.21781, 848.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 139.86s
- Epoch 022, ExpID 3720
Train - Loss (one batch): 0.05948
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07113, 0.07113, 0.26670, 0.21701, 838.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 139.53s
- Epoch 023, ExpID 3720
Train - Loss (one batch): 0.06662
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07168, 0.07168, 0.26774, 0.22227, 896.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 140.32s
- Epoch 024, ExpID 3720
Train - Loss (one batch): 0.08066
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07106, 0.07106, 0.26658, 0.21618, 826.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 140.96s
- Epoch 025, ExpID 3720
Train - Loss (one batch): 0.06856
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07140, 0.07140, 0.26721, 0.22056, 877.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 140.69s
- Epoch 026, ExpID 3720
Train - Loss (one batch): 0.07347
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07127, 0.07127, 0.26696, 0.21627, 830.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 139.25s
- Epoch 027, ExpID 3720
Train - Loss (one batch): 0.06779
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07116, 0.07116, 0.26677, 0.21673, 834.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 139.36s
- Epoch 028, ExpID 3720
Train - Loss (one batch): 0.07835
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07120, 0.07120, 0.26682, 0.21898, 856.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 140.75s
- Epoch 029, ExpID 3720
Train - Loss (one batch): 0.07401
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07126, 0.07126, 0.26695, 0.21554, 822.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 139.85s
- Epoch 030, ExpID 3720
Train - Loss (one batch): 0.07344
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07111, 0.07111, 0.26667, 0.21716, 835.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 140.42s
- Epoch 031, ExpID 3720
Train - Loss (one batch): 0.08243
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07123, 0.07123, 0.26690, 0.21809, 849.10%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 139.57s
- Epoch 032, ExpID 3720
Train - Loss (one batch): 0.07055
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07129, 0.07129, 0.26700, 0.21992, 865.99%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 139.47s
- Epoch 033, ExpID 3720
Train - Loss (one batch): 0.06930
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07132, 0.07132, 0.26706, 0.21956, 865.03%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 138.36s
- Epoch 034, ExpID 3720
Train - Loss (one batch): 0.07552
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07124, 0.07124, 0.26690, 0.21594, 826.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 140.63s
- Epoch 035, ExpID 3720
Train - Loss (one batch): 0.07577
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07124, 0.07124, 0.26691, 0.21640, 831.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 139.97s
- Epoch 036, ExpID 3720
Train - Loss (one batch): 0.07510
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07132, 0.07132, 0.26705, 0.21950, 864.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 140.33s
- Epoch 037, ExpID 3720
Train - Loss (one batch): 0.07726
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07116, 0.07116, 0.26676, 0.21851, 850.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 139.18s
- Epoch 038, ExpID 3720
Train - Loss (one batch): 0.08804
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07106, 0.07106, 0.26657, 0.21573, 818.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 140.24s
- Epoch 039, ExpID 3720
Train - Loss (one batch): 0.07107
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07121, 0.07121, 0.26684, 0.21606, 826.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 141.37s
- Epoch 040, ExpID 3720
Train - Loss (one batch): 0.07238
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07104, 0.07104, 0.26653, 0.21629, 823.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 141.16s
- Epoch 041, ExpID 3720
Train - Loss (one batch): 0.07449
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07115, 0.07115, 0.26675, 0.21747, 840.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 140.46s
- Epoch 042, ExpID 3720
Train - Loss (one batch): 0.07013
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07120, 0.07120, 0.26683, 0.21762, 843.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 140.54s
- Epoch 043, ExpID 3720
Train - Loss (one batch): 0.07588
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07111, 0.07111, 0.26666, 0.21731, 837.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 146.08s
- Epoch 044, ExpID 3720
Train - Loss (one batch): 0.07114
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07112, 0.07112, 0.26667, 0.21582, 821.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 148.68s
- Epoch 045, ExpID 3720
Train - Loss (one batch): 0.06885
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07107, 0.07107, 0.26659, 0.21716, 834.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 147.90s
- Epoch 046, ExpID 3720
Train - Loss (one batch): 0.07298
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07120, 0.07120, 0.26683, 0.21692, 836.35%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 136.57s
- Epoch 047, ExpID 3720
Train - Loss (one batch): 0.06961
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07125, 0.07125, 0.26693, 0.21564, 823.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 136.47s
- Epoch 048, ExpID 3720
Train - Loss (one batch): 0.07161
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07119, 0.07119, 0.26681, 0.21569, 822.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 130.55s
- Epoch 049, ExpID 3720
Train - Loss (one batch): 0.08031
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07117, 0.07117, 0.26678, 0.21685, 834.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 136.51s
- Epoch 050, ExpID 3720
Train - Loss (one batch): 0.07419
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07115, 0.07115, 0.26673, 0.21770, 842.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 135.84s
- Epoch 051, ExpID 3720
Train - Loss (one batch): 0.06886
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07115, 0.07115, 0.26674, 0.21600, 824.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 136.50s
- Epoch 052, ExpID 3720
Train - Loss (one batch): 0.07202
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07115, 0.07115, 0.26675, 0.21582, 822.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 136.72s
- Epoch 053, ExpID 3720
Train - Loss (one batch): 0.07465
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07118, 0.07118, 0.26679, 0.21690, 835.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 118.99s
- Epoch 054, ExpID 3720
Train - Loss (one batch): 0.08199
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07124, 0.07124, 0.26690, 0.21904, 857.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.38s
- Epoch 055, ExpID 3720
Train - Loss (one batch): 0.07070
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07119, 0.07119, 0.26681, 0.21668, 833.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.14s
- Epoch 056, ExpID 3720
Train - Loss (one batch): 0.08121
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07114, 0.07114, 0.26673, 0.21614, 826.03%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 117.56s
- Epoch 057, ExpID 3720
Train - Loss (one batch): 0.08086
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07103, 0.07103, 0.26652, 0.21672, 827.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.14s
- Epoch 058, ExpID 3720
Train - Loss (one batch): 0.07485
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07108, 0.07108, 0.26661, 0.21588, 826.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.99s
- Epoch 059, ExpID 3720
Train - Loss (one batch): 0.07399
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07114, 0.07114, 0.26672, 0.21677, 832.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.59s
- Epoch 060, ExpID 3720
Train - Loss (one batch): 0.06996
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07119, 0.07119, 0.26681, 0.21683, 835.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 116.42s
- Epoch 061, ExpID 3720
Train - Loss (one batch): 0.10100
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07112, 0.07112, 0.26668, 0.21681, 834.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.42s
- Epoch 062, ExpID 3720
Train - Loss (one batch): 0.07875
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07106, 0.07106, 0.26657, 0.21815, 851.74%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.38s
- Epoch 063, ExpID 3720
Train - Loss (one batch): 0.07986
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07106, 0.07106, 0.26658, 0.21743, 845.18%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.10s
- Epoch 064, ExpID 3720
Train - Loss (one batch): 0.07656
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07103, 0.07103, 0.26651, 0.21579, 828.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.59s
- Epoch 065, ExpID 3720
Train - Loss (one batch): 0.06816
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07104, 0.07104, 0.26653, 0.21634, 832.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.07540, 0.07540, 0.27458, 0.22036, 823.14%
Time spent: 115.78s
- Epoch 066, ExpID 3720
Train - Loss (one batch): 0.07255
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07094, 0.07094, 0.26635, 0.21643, 831.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 130.15s
- Epoch 067, ExpID 3720
Train - Loss (one batch): 0.07563
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07105, 0.07105, 0.26655, 0.21843, 853.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 116.22s
- Epoch 068, ExpID 3720
Train - Loss (one batch): 0.06944
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07101, 0.07101, 0.26648, 0.21728, 842.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 116.58s
- Epoch 069, ExpID 3720
Train - Loss (one batch): 0.07557
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07097, 0.07097, 0.26640, 0.21552, 821.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 115.92s
- Epoch 070, ExpID 3720
Train - Loss (one batch): 0.07989
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07099, 0.07099, 0.26644, 0.21746, 844.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 115.95s
- Epoch 071, ExpID 3720
Train - Loss (one batch): 0.06703
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07102, 0.07102, 0.26649, 0.21660, 836.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 116.37s
- Epoch 072, ExpID 3720
Train - Loss (one batch): 0.07638
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07116, 0.07116, 0.26676, 0.21926, 863.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 116.16s
- Epoch 073, ExpID 3720
Train - Loss (one batch): 0.07265
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07108, 0.07108, 0.26660, 0.21683, 837.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 117.12s
- Epoch 074, ExpID 3720
Train - Loss (one batch): 0.07512
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07103, 0.07103, 0.26652, 0.21839, 854.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 116.33s
- Epoch 075, ExpID 3720
Train - Loss (one batch): 0.07964
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07102, 0.07102, 0.26649, 0.21817, 850.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 117.17s
- Epoch 076, ExpID 3720
Train - Loss (one batch): 0.06050
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07101, 0.07101, 0.26649, 0.21647, 833.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 115.37s
- Epoch 077, ExpID 3720
Train - Loss (one batch): 0.07476
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07118, 0.07118, 0.26680, 0.21842, 858.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 115.82s
- Epoch 078, ExpID 3720
Train - Loss (one batch): 0.07897
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07101, 0.07101, 0.26648, 0.21707, 840.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 117.01s
- Epoch 079, ExpID 3720
Train - Loss (one batch): 0.07489
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07096, 0.07096, 0.26639, 0.21732, 840.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 116.18s
- Epoch 080, ExpID 3720
Train - Loss (one batch): 0.06856
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07102, 0.07102, 0.26650, 0.21533, 821.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 116.86s
- Epoch 081, ExpID 3720
Train - Loss (one batch): 0.06949
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07101, 0.07101, 0.26649, 0.21864, 853.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 116.67s
- Epoch 082, ExpID 3720
Train - Loss (one batch): 0.07955
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07106, 0.07106, 0.26657, 0.21598, 831.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 116.26s
- Epoch 083, ExpID 3720
Train - Loss (one batch): 0.07740
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07098, 0.07098, 0.26641, 0.21623, 830.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 116.22s
- Epoch 084, ExpID 3720
Train - Loss (one batch): 0.08254
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07100, 0.07100, 0.26646, 0.21673, 835.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 66, 0.07545, 0.07545, 0.27468, 0.21893, 772.17%
Time spent: 115.74s
- Epoch 085, ExpID 3720
Train - Loss (one batch): 0.07830
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07090, 0.07090, 0.26628, 0.21671, 832.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 128.39s
- Epoch 086, ExpID 3720
Train - Loss (one batch): 0.06781
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07100, 0.07100, 0.26646, 0.21791, 846.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 115.45s
- Epoch 087, ExpID 3720
Train - Loss (one batch): 0.07804
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07093, 0.07093, 0.26633, 0.21604, 826.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 116.44s
- Epoch 088, ExpID 3720
Train - Loss (one batch): 0.06762
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07104, 0.07104, 0.26653, 0.21656, 835.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 116.95s
- Epoch 089, ExpID 3720
Train - Loss (one batch): 0.07889
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07097, 0.07097, 0.26640, 0.21654, 834.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 115.67s
- Epoch 090, ExpID 3720
Train - Loss (one batch): 0.07345
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07094, 0.07094, 0.26635, 0.21686, 836.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 114.98s
- Epoch 091, ExpID 3720
Train - Loss (one batch): 0.06858
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07100, 0.07100, 0.26646, 0.21851, 851.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 118.12s
- Epoch 092, ExpID 3720
Train - Loss (one batch): 0.06851
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07092, 0.07092, 0.26631, 0.21656, 832.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 114.25s
- Epoch 093, ExpID 3720
Train - Loss (one batch): 0.06977
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07111, 0.07111, 0.26667, 0.21729, 843.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 117.72s
- Epoch 094, ExpID 3720
Train - Loss (one batch): 0.06666
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07109, 0.07109, 0.26662, 0.21607, 832.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 115.69s
- Epoch 095, ExpID 3720
Train - Loss (one batch): 0.07040
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07104, 0.07104, 0.26653, 0.21835, 853.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 116.07s
- Epoch 096, ExpID 3720
Train - Loss (one batch): 0.07244
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07100, 0.07100, 0.26646, 0.21693, 838.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 115.28s
- Epoch 097, ExpID 3720
Train - Loss (one batch): 0.07578
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07100, 0.07100, 0.26646, 0.21729, 843.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 115.98s
- Epoch 098, ExpID 3720
Train - Loss (one batch): 0.07122
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07100, 0.07100, 0.26646, 0.21788, 847.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 117.07s
- Epoch 099, ExpID 3720
Train - Loss (one batch): 0.07353
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07098, 0.07098, 0.26641, 0.21736, 841.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 85, 0.07540, 0.07540, 0.27459, 0.21919, 772.52%
Time spent: 115.38s
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_iTransformer.py
2024-07-20 01:31:10
run_iTransformer.py --history 36 --model iTransformer --dataset mimic --gpu 2
Namespace(state='def', n=100000000, epoch=100, patience=10, history=36, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='mimic', quantization=0.0, model='iTransformer', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=24, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='2', seq_len=464, top_k=5, num_kernels=64, npatch=2, device=device(type='cuda', index=0), PID=2310886, pred_window=12, ndim=96, patch_layer=2, task_name='long_term_forecast', pred_len=720, output_attention=None, d_model=512, embed='timeF', freq='h', dropout=0.1, factor=3, d_ff=512, e_layers=4, n_heads=1, activation='gelu')
- Epoch 000, ExpID 2376
Train - Loss (one batch): 0.07799
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06866, 0.06866, 0.26202, 0.20672, 696.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 72.71s
- Epoch 001, ExpID 2376
Train - Loss (one batch): 0.07370
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26435, 0.21372, 778.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.29s
- Epoch 002, ExpID 2376
Train - Loss (one batch): 0.06950
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06964, 0.06964, 0.26389, 0.20873, 726.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.92s
- Epoch 003, ExpID 2376
Train - Loss (one batch): 0.05623
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07006, 0.07006, 0.26468, 0.21473, 787.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.66s
- Epoch 004, ExpID 2376
Train - Loss (one batch): 0.06341
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06981, 0.06981, 0.26421, 0.20987, 735.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.20s
- Epoch 005, ExpID 2376
Train - Loss (one batch): 0.07468
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06994, 0.06994, 0.26446, 0.21282, 765.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.13s
- Epoch 006, ExpID 2376
Train - Loss (one batch): 0.06581
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06997, 0.06997, 0.26451, 0.20701, 701.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.93s
- Epoch 007, ExpID 2376
Train - Loss (one batch): 0.05903
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06984, 0.06984, 0.26427, 0.21263, 766.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.89s
- Epoch 008, ExpID 2376
Train - Loss (one batch): 0.06444
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06981, 0.06981, 0.26421, 0.21172, 756.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.01s
- Epoch 009, ExpID 2376
Train - Loss (one batch): 0.06315
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07005, 0.07005, 0.26468, 0.21492, 790.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.74s
- Epoch 010, ExpID 2376
Train - Loss (one batch): 0.08195
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06999, 0.06999, 0.26456, 0.21424, 782.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.57s
- Epoch 011, ExpID 2376
Train - Loss (one batch): 0.05158
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06978, 0.06978, 0.26416, 0.21083, 746.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.36s
- Epoch 012, ExpID 2376
Train - Loss (one batch): 0.06563
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06981, 0.06981, 0.26421, 0.20911, 727.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.17s
- Epoch 013, ExpID 2376
Train - Loss (one batch): 0.06887
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06979, 0.06979, 0.26418, 0.21009, 738.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.97s
- Epoch 014, ExpID 2376
Train - Loss (one batch): 0.07258
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06981, 0.06981, 0.26421, 0.21127, 751.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.92s
- Epoch 015, ExpID 2376
Train - Loss (one batch): 0.06479
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06981, 0.06981, 0.26422, 0.21066, 744.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.48s
- Epoch 016, ExpID 2376
Train - Loss (one batch): 0.07007
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06984, 0.06984, 0.26426, 0.21135, 751.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.42s
- Epoch 017, ExpID 2376
Train - Loss (one batch): 0.06943
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21134, 751.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.05s
- Epoch 018, ExpID 2376
Train - Loss (one batch): 0.06164
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26432, 0.21098, 746.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.51s
- Epoch 019, ExpID 2376
Train - Loss (one batch): 0.06647
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06989, 0.06989, 0.26437, 0.20884, 722.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.22s
- Epoch 020, ExpID 2376
Train - Loss (one batch): 0.05979
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06985, 0.06985, 0.26429, 0.21031, 739.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.30s
- Epoch 021, ExpID 2376
Train - Loss (one batch): 0.07134
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06997, 0.06997, 0.26451, 0.21318, 770.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.17s
- Epoch 022, ExpID 2376
Train - Loss (one batch): 0.06677
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26434, 0.20932, 728.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.90s
- Epoch 023, ExpID 2376
Train - Loss (one batch): 0.07364
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26435, 0.21159, 753.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.30s
- Epoch 024, ExpID 2376
Train - Loss (one batch): 0.06939
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21008, 736.99%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.28s
- Epoch 025, ExpID 2376
Train - Loss (one batch): 0.06135
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06993, 0.06993, 0.26444, 0.21263, 764.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.88s
- Epoch 026, ExpID 2376
Train - Loss (one batch): 0.06466
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26434, 0.21154, 752.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.53s
- Epoch 027, ExpID 2376
Train - Loss (one batch): 0.07300
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06989, 0.06989, 0.26436, 0.21182, 756.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.87s
- Epoch 028, ExpID 2376
Train - Loss (one batch): 0.07631
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21045, 741.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.22s
- Epoch 029, ExpID 2376
Train - Loss (one batch): 0.07008
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26433, 0.20950, 730.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.02s
- Epoch 030, ExpID 2376
Train - Loss (one batch): 0.05081
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26434, 0.20924, 727.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.53s
- Epoch 031, ExpID 2376
Train - Loss (one batch): 0.05875
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21065, 743.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.52s
- Epoch 032, ExpID 2376
Train - Loss (one batch): 0.06896
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26432, 0.20963, 731.83%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 66.02s
- Epoch 033, ExpID 2376
Train - Loss (one batch): 0.06411
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26435, 0.21159, 753.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.71s
- Epoch 034, ExpID 2376
Train - Loss (one batch): 0.05163
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06989, 0.06989, 0.26437, 0.21190, 756.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.22s
- Epoch 035, ExpID 2376
Train - Loss (one batch): 0.06800
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21012, 737.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.39s
- Epoch 036, ExpID 2376
Train - Loss (one batch): 0.06504
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21078, 744.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.48s
- Epoch 037, ExpID 2376
Train - Loss (one batch): 0.06461
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21039, 740.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.05s
- Epoch 038, ExpID 2376
Train - Loss (one batch): 0.06054
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.20996, 735.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.49s
- Epoch 039, ExpID 2376
Train - Loss (one batch): 0.06059
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06998, 0.06998, 0.26454, 0.21342, 772.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.01s
- Epoch 040, ExpID 2376
Train - Loss (one batch): 0.05553
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26433, 0.21136, 751.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.21s
- Epoch 041, ExpID 2376
Train - Loss (one batch): 0.07474
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26433, 0.21117, 749.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.85s
- Epoch 042, ExpID 2376
Train - Loss (one batch): 0.06510
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26432, 0.21100, 747.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.67s
- Epoch 043, ExpID 2376
Train - Loss (one batch): 0.06436
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06996, 0.06996, 0.26451, 0.20777, 709.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.06s
- Epoch 044, ExpID 2376
Train - Loss (one batch): 0.06120
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21004, 736.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.87s
- Epoch 045, ExpID 2376
Train - Loss (one batch): 0.06275
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26436, 0.21172, 754.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.28s
- Epoch 046, ExpID 2376
Train - Loss (one batch): 0.06500
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26436, 0.21170, 754.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.76s
- Epoch 047, ExpID 2376
Train - Loss (one batch): 0.06222
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26432, 0.20972, 732.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.92s
- Epoch 048, ExpID 2376
Train - Loss (one batch): 0.05829
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26435, 0.21157, 753.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.74s
- Epoch 049, ExpID 2376
Train - Loss (one batch): 0.07969
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06990, 0.06990, 0.26438, 0.21205, 758.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.49s
- Epoch 050, ExpID 2376
Train - Loss (one batch): 0.07150
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26435, 0.21161, 753.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.42s
- Epoch 051, ExpID 2376
Train - Loss (one batch): 0.06871
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26432, 0.21095, 746.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.78s
- Epoch 052, ExpID 2376
Train - Loss (one batch): 0.07350
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06990, 0.06990, 0.26438, 0.21206, 758.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.34s
- Epoch 053, ExpID 2376
Train - Loss (one batch): 0.05681
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06989, 0.06989, 0.26436, 0.21173, 755.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.49s
- Epoch 054, ExpID 2376
Train - Loss (one batch): 0.06849
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26434, 0.21144, 751.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.26s
- Epoch 055, ExpID 2376
Train - Loss (one batch): 0.05925
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26434, 0.21147, 752.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.03s
- Epoch 056, ExpID 2376
Train - Loss (one batch): 0.06648
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26432, 0.21108, 748.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.67s
- Epoch 057, ExpID 2376
Train - Loss (one batch): 0.06768
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21030, 739.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 66.17s
- Epoch 058, ExpID 2376
Train - Loss (one batch): 0.07644
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21026, 738.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.47s
- Epoch 059, ExpID 2376
Train - Loss (one batch): 0.06258
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.20984, 734.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.68s
- Epoch 060, ExpID 2376
Train - Loss (one batch): 0.06767
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06991, 0.06991, 0.26440, 0.21225, 760.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.48s
- Epoch 061, ExpID 2376
Train - Loss (one batch): 0.07193
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21012, 737.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.96s
- Epoch 062, ExpID 2376
Train - Loss (one batch): 0.06308
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26434, 0.21147, 752.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.12s
- Epoch 063, ExpID 2376
Train - Loss (one batch): 0.06509
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21032, 739.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.35s
- Epoch 064, ExpID 2376
Train - Loss (one batch): 0.07536
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21071, 743.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.36s
- Epoch 065, ExpID 2376
Train - Loss (one batch): 0.07077
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21069, 743.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.82s
- Epoch 066, ExpID 2376
Train - Loss (one batch): 0.07006
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26432, 0.20977, 733.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.11s
- Epoch 067, ExpID 2376
Train - Loss (one batch): 0.08869
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26433, 0.20945, 729.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.42s
- Epoch 068, ExpID 2376
Train - Loss (one batch): 0.07095
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26433, 0.21121, 749.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.33s
- Epoch 069, ExpID 2376
Train - Loss (one batch): 0.06695
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06998, 0.06998, 0.26453, 0.21332, 771.85%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.26s
- Epoch 070, ExpID 2376
Train - Loss (one batch): 0.06173
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06989, 0.06989, 0.26436, 0.21173, 755.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.70s
- Epoch 071, ExpID 2376
Train - Loss (one batch): 0.06856
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21029, 739.30%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.05s
- Epoch 072, ExpID 2376
Train - Loss (one batch): 0.06192
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26432, 0.20969, 732.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.25s
- Epoch 073, ExpID 2376
Train - Loss (one batch): 0.07430
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21050, 741.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.01s
- Epoch 074, ExpID 2376
Train - Loss (one batch): 0.07602
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21032, 739.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.84s
- Epoch 075, ExpID 2376
Train - Loss (one batch): 0.06670
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26434, 0.21153, 752.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.48s
- Epoch 076, ExpID 2376
Train - Loss (one batch): 0.06597
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21032, 739.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.38s
- Epoch 077, ExpID 2376
Train - Loss (one batch): 0.06249
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21064, 743.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.74s
- Epoch 078, ExpID 2376
Train - Loss (one batch): 0.07370
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06991, 0.06991, 0.26440, 0.21223, 760.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.86s
- Epoch 079, ExpID 2376
Train - Loss (one batch): 0.06542
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26433, 0.21127, 750.09%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.80s
- Epoch 080, ExpID 2376
Train - Loss (one batch): 0.06014
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21070, 743.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.78s
- Epoch 081, ExpID 2376
Train - Loss (one batch): 0.06462
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26432, 0.21097, 746.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.84s
- Epoch 082, ExpID 2376
Train - Loss (one batch): 0.06923
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.20993, 735.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.02s
- Epoch 083, ExpID 2376
Train - Loss (one batch): 0.06024
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26434, 0.21150, 752.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.31s
- Epoch 084, ExpID 2376
Train - Loss (one batch): 0.06473
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21079, 744.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.87s
- Epoch 085, ExpID 2376
Train - Loss (one batch): 0.06807
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06989, 0.06989, 0.26436, 0.21182, 756.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.28s
- Epoch 086, ExpID 2376
Train - Loss (one batch): 0.06324
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26433, 0.21136, 751.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.30s
- Epoch 087, ExpID 2376
Train - Loss (one batch): 0.06317
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06992, 0.06992, 0.26443, 0.21250, 763.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.68s
- Epoch 088, ExpID 2376
Train - Loss (one batch): 0.06389
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26436, 0.21172, 754.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.33s
- Epoch 089, ExpID 2376
Train - Loss (one batch): 0.07835
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26433, 0.21121, 749.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.41s
- Epoch 090, ExpID 2376
Train - Loss (one batch): 0.06422
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21049, 741.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.43s
- Epoch 091, ExpID 2376
Train - Loss (one batch): 0.07513
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26432, 0.20968, 732.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.93s
- Epoch 092, ExpID 2376
Train - Loss (one batch): 0.06535
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21063, 743.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 66.31s
- Epoch 093, ExpID 2376
Train - Loss (one batch): 0.06454
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06991, 0.06991, 0.26440, 0.21222, 760.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.83s
- Epoch 094, ExpID 2376
Train - Loss (one batch): 0.05238
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26433, 0.21119, 749.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.03s
- Epoch 095, ExpID 2376
Train - Loss (one batch): 0.06385
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06993, 0.06993, 0.26445, 0.21270, 765.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.58s
- Epoch 096, ExpID 2376
Train - Loss (one batch): 0.05735
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.21035, 739.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.45s
- Epoch 097, ExpID 2376
Train - Loss (one batch): 0.05959
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26432, 0.21115, 748.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 64.96s
- Epoch 098, ExpID 2376
Train - Loss (one batch): 0.06648
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26435, 0.21155, 753.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.47s
- Epoch 099, ExpID 2376
Train - Loss (one batch): 0.06690
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26432, 0.21112, 748.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07077, 0.07077, 0.26602, 0.21111, 647.58%
Time spent: 65.81s
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_iTransformer.py
2024-07-20 03:22:47
run_iTransformer.py --history 12 --model iTransformer --dataset mimic --gpu 2
Namespace(state='def', n=100000000, epoch=100, patience=10, history=12, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='mimic', quantization=0.0, model='iTransformer', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=24, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='2', seq_len=133, top_k=5, num_kernels=64, npatch=1, device=device(type='cuda', index=0), PID=2373153, pred_window=36, ndim=96, patch_layer=1, task_name='long_term_forecast', pred_len=720, output_attention=None, d_model=512, embed='timeF', freq='h', dropout=0.1, factor=3, d_ff=512, e_layers=4, n_heads=1, activation='gelu')
- Epoch 000, ExpID 22244
Train - Loss (one batch): 0.06495
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07103, 0.07103, 0.26651, 0.21105, 813.18%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 178.85s
- Epoch 001, ExpID 22244
Train - Loss (one batch): 0.06884
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07253, 0.07253, 0.26931, 0.22236, 955.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.33s
- Epoch 002, ExpID 22244
Train - Loss (one batch): 0.06704
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07226, 0.07226, 0.26882, 0.21947, 922.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.02s
- Epoch 003, ExpID 22244
Train - Loss (one batch): 0.07194
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07213, 0.07213, 0.26858, 0.21958, 923.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.67s
- Epoch 004, ExpID 22244
Train - Loss (one batch): 0.07580
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07229, 0.07229, 0.26888, 0.22094, 932.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 156.97s
- Epoch 005, ExpID 22244
Train - Loss (one batch): 0.07726
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07203, 0.07203, 0.26839, 0.21554, 857.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.09s
- Epoch 006, ExpID 22244
Train - Loss (one batch): 0.07064
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07208, 0.07208, 0.26848, 0.21951, 908.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.37s
- Epoch 007, ExpID 22244
Train - Loss (one batch): 0.07242
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07204, 0.07204, 0.26841, 0.21827, 896.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 158.58s
- Epoch 008, ExpID 22244
Train - Loss (one batch): 0.07432
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07210, 0.07210, 0.26851, 0.21856, 895.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.72s
- Epoch 009, ExpID 22244
Train - Loss (one batch): 0.06681
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07220, 0.07220, 0.26870, 0.22065, 927.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.01s
- Epoch 010, ExpID 22244
Train - Loss (one batch): 0.07218
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07239, 0.07239, 0.26905, 0.22246, 947.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.63s
- Epoch 011, ExpID 22244
Train - Loss (one batch): 0.06702
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07200, 0.07200, 0.26833, 0.21824, 891.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 158.17s
- Epoch 012, ExpID 22244
Train - Loss (one batch): 0.06826
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07222, 0.07222, 0.26873, 0.21932, 916.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 158.75s
- Epoch 013, ExpID 22244
Train - Loss (one batch): 0.07064
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07209, 0.07209, 0.26850, 0.21430, 835.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 158.97s
- Epoch 014, ExpID 22244
Train - Loss (one batch): 0.07232
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07204, 0.07204, 0.26840, 0.21581, 859.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.60s
- Epoch 015, ExpID 22244
Train - Loss (one batch): 0.07648
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07197, 0.07197, 0.26827, 0.21722, 880.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 157.93s
- Epoch 016, ExpID 22244
Train - Loss (one batch): 0.08501
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07194, 0.07194, 0.26822, 0.21827, 883.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.33s
- Epoch 017, ExpID 22244
Train - Loss (one batch): 0.06939
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07221, 0.07221, 0.26871, 0.21879, 910.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 158.04s
- Epoch 018, ExpID 22244
Train - Loss (one batch): 0.07540
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07189, 0.07189, 0.26812, 0.21914, 898.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 156.88s
- Epoch 019, ExpID 22244
Train - Loss (one batch): 0.07396
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07191, 0.07191, 0.26816, 0.21928, 903.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.40s
- Epoch 020, ExpID 22244
Train - Loss (one batch): 0.06606
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07183, 0.07183, 0.26801, 0.21836, 887.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.86s
- Epoch 021, ExpID 22244
Train - Loss (one batch): 0.07300
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07202, 0.07202, 0.26837, 0.21667, 872.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.05s
- Epoch 022, ExpID 22244
Train - Loss (one batch): 0.06097
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07198, 0.07198, 0.26830, 0.21569, 855.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 158.61s
- Epoch 023, ExpID 22244
Train - Loss (one batch): 0.07039
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07202, 0.07202, 0.26837, 0.21977, 905.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.98s
- Epoch 024, ExpID 22244
Train - Loss (one batch): 0.07421
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07178, 0.07178, 0.26792, 0.21809, 881.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.60s
- Epoch 025, ExpID 22244
Train - Loss (one batch): 0.07533
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07182, 0.07182, 0.26800, 0.21653, 870.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.31s
- Epoch 026, ExpID 22244
Train - Loss (one batch): 0.08312
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07184, 0.07184, 0.26803, 0.21624, 855.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.08s
- Epoch 027, ExpID 22244
Train - Loss (one batch): 0.07130
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07187, 0.07187, 0.26809, 0.21914, 903.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.83s
- Epoch 028, ExpID 22244
Train - Loss (one batch): 0.07493
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07186, 0.07186, 0.26808, 0.21925, 901.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.10s
- Epoch 029, ExpID 22244
Train - Loss (one batch): 0.07353
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07204, 0.07204, 0.26841, 0.21690, 870.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 158.97s
- Epoch 030, ExpID 22244
Train - Loss (one batch): 0.07199
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07180, 0.07180, 0.26796, 0.21818, 890.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.61s
- Epoch 031, ExpID 22244
Train - Loss (one batch): 0.06651
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07180, 0.07180, 0.26795, 0.21931, 904.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 158.86s
- Epoch 032, ExpID 22244
Train - Loss (one batch): 0.06514
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07178, 0.07178, 0.26792, 0.21679, 871.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 158.70s
- Epoch 033, ExpID 22244
Train - Loss (one batch): 0.07114
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07186, 0.07186, 0.26807, 0.21695, 875.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.66s
- Epoch 034, ExpID 22244
Train - Loss (one batch): 0.07302
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07185, 0.07185, 0.26804, 0.22038, 914.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.32s
- Epoch 035, ExpID 22244
Train - Loss (one batch): 0.07421
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07167, 0.07167, 0.26771, 0.21791, 876.48%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.64s
- Epoch 036, ExpID 22244
Train - Loss (one batch): 0.07787
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07189, 0.07189, 0.26813, 0.21975, 905.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 158.42s
- Epoch 037, ExpID 22244
Train - Loss (one batch): 0.06949
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07175, 0.07175, 0.26787, 0.21923, 900.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.82s
- Epoch 038, ExpID 22244
Train - Loss (one batch): 0.08452
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07214, 0.07214, 0.26858, 0.21534, 855.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.29s
- Epoch 039, ExpID 22244
Train - Loss (one batch): 0.06715
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07200, 0.07200, 0.26832, 0.22059, 913.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.59s
- Epoch 040, ExpID 22244
Train - Loss (one batch): 0.07220
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07177, 0.07177, 0.26790, 0.21731, 876.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.48s
- Epoch 041, ExpID 22244
Train - Loss (one batch): 0.07408
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07183, 0.07183, 0.26800, 0.21914, 896.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 161.08s
- Epoch 042, ExpID 22244
Train - Loss (one batch): 0.07416
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07182, 0.07182, 0.26799, 0.21947, 901.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.77s
- Epoch 043, ExpID 22244
Train - Loss (one batch): 0.06634
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07187, 0.07187, 0.26809, 0.21804, 886.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.33s
- Epoch 044, ExpID 22244
Train - Loss (one batch): 0.07995
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07186, 0.07186, 0.26806, 0.21809, 891.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.26s
- Epoch 045, ExpID 22244
Train - Loss (one batch): 0.06779
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07167, 0.07167, 0.26771, 0.21706, 866.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.26s
- Epoch 046, ExpID 22244
Train - Loss (one batch): 0.06909
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07188, 0.07188, 0.26811, 0.21633, 864.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 158.05s
- Epoch 047, ExpID 22244
Train - Loss (one batch): 0.07562
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07173, 0.07173, 0.26782, 0.21721, 871.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.30s
- Epoch 048, ExpID 22244
Train - Loss (one batch): 0.06512
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07188, 0.07188, 0.26810, 0.21876, 893.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 158.98s
- Epoch 049, ExpID 22244
Train - Loss (one batch): 0.07073
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07214, 0.07214, 0.26860, 0.21871, 905.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.12s
- Epoch 050, ExpID 22244
Train - Loss (one batch): 0.07230
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07191, 0.07191, 0.26816, 0.21931, 901.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 161.34s
- Epoch 051, ExpID 22244
Train - Loss (one batch): 0.06896
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07174, 0.07174, 0.26785, 0.21814, 880.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.18s
- Epoch 052, ExpID 22244
Train - Loss (one batch): 0.07258
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07176, 0.07176, 0.26788, 0.21615, 859.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.49s
- Epoch 053, ExpID 22244
Train - Loss (one batch): 0.06891
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07172, 0.07172, 0.26781, 0.21832, 882.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 158.88s
- Epoch 054, ExpID 22244
Train - Loss (one batch): 0.07492
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07176, 0.07176, 0.26787, 0.21906, 893.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.04s
- Epoch 055, ExpID 22244
Train - Loss (one batch): 0.07914
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07179, 0.07179, 0.26794, 0.21755, 878.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 157.62s
- Epoch 056, ExpID 22244
Train - Loss (one batch): 0.07242
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07161, 0.07161, 0.26761, 0.21820, 882.09%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.28s
- Epoch 057, ExpID 22244
Train - Loss (one batch): 0.07299
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07196, 0.07196, 0.26826, 0.21775, 882.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.81s
- Epoch 058, ExpID 22244
Train - Loss (one batch): 0.06909
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07165, 0.07165, 0.26768, 0.21736, 874.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.78s
- Epoch 059, ExpID 22244
Train - Loss (one batch): 0.07114
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07168, 0.07168, 0.26773, 0.21885, 887.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 158.67s
- Epoch 060, ExpID 22244
Train - Loss (one batch): 0.07805
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07183, 0.07183, 0.26801, 0.22023, 906.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.46s
- Epoch 061, ExpID 22244
Train - Loss (one batch): 0.07095
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07161, 0.07161, 0.26761, 0.21737, 872.09%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.05s
- Epoch 062, ExpID 22244
Train - Loss (one batch): 0.06991
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07188, 0.07188, 0.26810, 0.21996, 903.48%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.06s
- Epoch 063, ExpID 22244
Train - Loss (one batch): 0.06869
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07165, 0.07165, 0.26768, 0.21747, 874.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.55s
- Epoch 064, ExpID 22244
Train - Loss (one batch): 0.07082
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07175, 0.07175, 0.26786, 0.21619, 859.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.82s
- Epoch 065, ExpID 22244
Train - Loss (one batch): 0.07960
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07175, 0.07175, 0.26787, 0.21714, 873.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.22s
- Epoch 066, ExpID 22244
Train - Loss (one batch): 0.06960
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07167, 0.07167, 0.26771, 0.21821, 887.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.33s
- Epoch 067, ExpID 22244
Train - Loss (one batch): 0.07726
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07175, 0.07175, 0.26785, 0.21721, 871.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.64s
- Epoch 068, ExpID 22244
Train - Loss (one batch): 0.07264
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07168, 0.07168, 0.26774, 0.21777, 879.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.07s
- Epoch 069, ExpID 22244
Train - Loss (one batch): 0.07323
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07173, 0.07173, 0.26783, 0.21779, 880.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.52s
- Epoch 070, ExpID 22244
Train - Loss (one batch): 0.07985
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07169, 0.07169, 0.26775, 0.21760, 876.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 158.99s
- Epoch 071, ExpID 22244
Train - Loss (one batch): 0.06565
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07200, 0.07200, 0.26832, 0.21729, 880.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 161.25s
- Epoch 072, ExpID 22244
Train - Loss (one batch): 0.06875
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07174, 0.07174, 0.26784, 0.21913, 892.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.82s
- Epoch 073, ExpID 22244
Train - Loss (one batch): 0.07126
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07163, 0.07163, 0.26765, 0.21816, 879.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.18s
- Epoch 074, ExpID 22244
Train - Loss (one batch): 0.08190
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07182, 0.07182, 0.26800, 0.22067, 909.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 161.73s
- Epoch 075, ExpID 22244
Train - Loss (one batch): 0.07293
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07171, 0.07171, 0.26778, 0.21876, 890.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 158.62s
- Epoch 076, ExpID 22244
Train - Loss (one batch): 0.07923
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07194, 0.07194, 0.26822, 0.22023, 905.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.11s
- Epoch 077, ExpID 22244
Train - Loss (one batch): 0.06913
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07172, 0.07172, 0.26780, 0.21763, 875.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.91s
- Epoch 078, ExpID 22244
Train - Loss (one batch): 0.07423
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07157, 0.07157, 0.26753, 0.21801, 880.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 158.63s
- Epoch 079, ExpID 22244
Train - Loss (one batch): 0.06755
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07164, 0.07164, 0.26765, 0.21827, 883.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.59s
- Epoch 080, ExpID 22244
Train - Loss (one batch): 0.07495
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07165, 0.07165, 0.26768, 0.21877, 887.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.99s
- Epoch 081, ExpID 22244
Train - Loss (one batch): 0.07062
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07188, 0.07188, 0.26810, 0.21784, 883.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.27s
- Epoch 082, ExpID 22244
Train - Loss (one batch): 0.06474
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07167, 0.07167, 0.26771, 0.21848, 887.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.42s
- Epoch 083, ExpID 22244
Train - Loss (one batch): 0.06644
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07184, 0.07184, 0.26803, 0.22004, 907.74%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 158.75s
- Epoch 084, ExpID 22244
Train - Loss (one batch): 0.07381
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07164, 0.07164, 0.26765, 0.21743, 874.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 158.12s
- Epoch 085, ExpID 22244
Train - Loss (one batch): 0.06837
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07158, 0.07158, 0.26754, 0.21776, 876.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.04s
- Epoch 086, ExpID 22244
Train - Loss (one batch): 0.07196
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07157, 0.07157, 0.26753, 0.21745, 869.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.09s
- Epoch 087, ExpID 22244
Train - Loss (one batch): 0.06639
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07159, 0.07159, 0.26757, 0.21809, 879.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.23s
- Epoch 088, ExpID 22244
Train - Loss (one batch): 0.07379
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07158, 0.07158, 0.26755, 0.21690, 867.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 161.20s
- Epoch 089, ExpID 22244
Train - Loss (one batch): 0.07599
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07162, 0.07162, 0.26762, 0.21761, 875.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 158.13s
- Epoch 090, ExpID 22244
Train - Loss (one batch): 0.07194
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07169, 0.07169, 0.26775, 0.21863, 890.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.39s
- Epoch 091, ExpID 22244
Train - Loss (one batch): 0.07592
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07165, 0.07165, 0.26767, 0.21805, 880.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.40s
- Epoch 092, ExpID 22244
Train - Loss (one batch): 0.07437
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07169, 0.07169, 0.26775, 0.21949, 897.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 157.88s
- Epoch 093, ExpID 22244
Train - Loss (one batch): 0.06807
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07160, 0.07160, 0.26758, 0.21742, 874.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 159.71s
- Epoch 094, ExpID 22244
Train - Loss (one batch): 0.07475
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07157, 0.07157, 0.26752, 0.21749, 872.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 158.36s
- Epoch 095, ExpID 22244
Train - Loss (one batch): 0.06745
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07153, 0.07153, 0.26745, 0.21741, 870.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.56s
- Epoch 096, ExpID 22244
Train - Loss (one batch): 0.07040
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07167, 0.07167, 0.26771, 0.21883, 890.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.19s
- Epoch 097, ExpID 22244
Train - Loss (one batch): 0.06239
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07167, 0.07167, 0.26771, 0.21872, 889.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.87s
- Epoch 098, ExpID 22244
Train - Loss (one batch): 0.07099
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07157, 0.07157, 0.26752, 0.21705, 868.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 162.48s
- Epoch 099, ExpID 22244
Train - Loss (one batch): 0.07441
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07171, 0.07171, 0.26778, 0.21853, 884.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07519, 0.07519, 0.27421, 0.21246, 764.78%
Time spent: 160.76s
