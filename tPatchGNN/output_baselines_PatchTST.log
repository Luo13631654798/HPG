nohup: ignoring input
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_baselines.py
2024-07-19 10:53:44
run_baselines.py --history 24 --model PatchTST --dataset physionet
Namespace(state='def', n=100000000, epoch=100, patience=10, history=24, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='physionet', quantization=0.0, model='PatchTST', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=8, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='0', seq_len=128, top_k=5, num_kernels=64, npatch=1, device=device(type='cuda', index=0), PID=1790166, pred_window=24, ndim=41, patch_layer=1, task_name='long_term_forecast', label_len=48, pred_len=96, patch_len=16, d_model=64, dropout=0.1, output_attention=None, n_heads=1, d_ff=64, activation='gelu', e_layers=2, factor=3, enc_in=321)
- Epoch 000, ExpID 28586
Train - Loss (one batch): 0.04709
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05985, 0.05985, 0.24465, 0.15573, 449.74%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05764, 0.05764, 0.24008, 0.15282, 474.68%
Time spent: 11.26s
- Epoch 001, ExpID 28586
Train - Loss (one batch): 0.04568
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05128, 0.05128, 0.22646, 0.15875, 1117.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.04978, 0.04978, 0.22312, 0.15756, 1209.65%
Time spent: 10.58s
- Epoch 002, ExpID 28586
Train - Loss (one batch): 0.04514
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04703, 0.04703, 0.21686, 0.15220, 984.18%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.04586, 0.04586, 0.21416, 0.15145, 1060.11%
Time spent: 10.25s
- Epoch 003, ExpID 28586
Train - Loss (one batch): 0.05115
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04568, 0.04568, 0.21373, 0.14212, 620.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.04404, 0.04404, 0.20986, 0.14036, 662.80%
Time spent: 10.19s
- Epoch 004, ExpID 28586
Train - Loss (one batch): 0.03840
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04565, 0.04565, 0.21366, 0.14710, 1069.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.04427, 0.04427, 0.21041, 0.14602, 1161.65%
Time spent: 9.83s
- Epoch 005, ExpID 28586
Train - Loss (one batch): 0.04466
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05095, 0.05095, 0.22572, 0.15124, 983.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.04427, 0.04427, 0.21041, 0.14602, 1161.65%
Time spent: 8.33s
- Epoch 006, ExpID 28586
Train - Loss (one batch): 0.04189
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04272, 0.04272, 0.20668, 0.13934, 670.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.04118, 0.04118, 0.20292, 0.13805, 726.61%
Time spent: 8.46s
- Epoch 007, ExpID 28586
Train - Loss (one batch): 0.04390
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04470, 0.04470, 0.21143, 0.13949, 724.99%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.04118, 0.04118, 0.20292, 0.13805, 726.61%
Time spent: 6.72s
- Epoch 008, ExpID 28586
Train - Loss (one batch): 0.03950
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04157, 0.04157, 0.20389, 0.13798, 764.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 8, 0.03993, 0.03993, 0.19983, 0.13662, 832.88%
Time spent: 8.89s
- Epoch 009, ExpID 28586
Train - Loss (one batch): 0.03725
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04343, 0.04343, 0.20841, 0.13994, 751.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 8, 0.03993, 0.03993, 0.19983, 0.13662, 832.88%
Time spent: 8.09s
- Epoch 010, ExpID 28586
Train - Loss (one batch): 0.03976
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04085, 0.04085, 0.20210, 0.14250, 809.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.03983, 0.03983, 0.19958, 0.14222, 880.61%
Time spent: 9.20s
- Epoch 011, ExpID 28586
Train - Loss (one batch): 0.04021
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04167, 0.04167, 0.20413, 0.13981, 642.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.03983, 0.03983, 0.19958, 0.14222, 880.61%
Time spent: 7.51s
- Epoch 012, ExpID 28586
Train - Loss (one batch): 0.03941
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04169, 0.04169, 0.20418, 0.13856, 868.83%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.03983, 0.03983, 0.19958, 0.14222, 880.61%
Time spent: 7.59s
- Epoch 013, ExpID 28586
Train - Loss (one batch): 0.04141
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04435, 0.04435, 0.21059, 0.13965, 779.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.03983, 0.03983, 0.19958, 0.14222, 880.61%
Time spent: 6.69s
- Epoch 014, ExpID 28586
Train - Loss (one batch): 0.04902
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04315, 0.04315, 0.20773, 0.13479, 470.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.03983, 0.03983, 0.19958, 0.14222, 880.61%
Time spent: 7.55s
- Epoch 015, ExpID 28586
Train - Loss (one batch): 0.03376
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03954, 0.03954, 0.19884, 0.13456, 649.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.03801, 0.03801, 0.19497, 0.13325, 715.31%
Time spent: 7.57s
- Epoch 016, ExpID 28586
Train - Loss (one batch): 0.03696
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04359, 0.04359, 0.20878, 0.13503, 561.85%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.03801, 0.03801, 0.19497, 0.13325, 715.31%
Time spent: 6.70s
- Epoch 017, ExpID 28586
Train - Loss (one batch): 0.03621
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04673, 0.04673, 0.21617, 0.13924, 585.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.03801, 0.03801, 0.19497, 0.13325, 715.31%
Time spent: 7.52s
- Epoch 018, ExpID 28586
Train - Loss (one batch): 0.03412
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05537, 0.05537, 0.23532, 0.15192, 788.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.03801, 0.03801, 0.19497, 0.13325, 715.31%
Time spent: 7.99s
- Epoch 019, ExpID 28586
Train - Loss (one batch): 0.04259
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04306, 0.04306, 0.20750, 0.13556, 586.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.03801, 0.03801, 0.19497, 0.13325, 715.31%
Time spent: 7.79s
- Epoch 020, ExpID 28586
Train - Loss (one batch): 0.03780
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03847, 0.03847, 0.19613, 0.13493, 862.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.03741, 0.03741, 0.19341, 0.13438, 947.12%
Time spent: 8.12s
- Epoch 021, ExpID 28586
Train - Loss (one batch): 0.03978
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04054, 0.04054, 0.20134, 0.13371, 640.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.03741, 0.03741, 0.19341, 0.13438, 947.12%
Time spent: 7.50s
- Epoch 022, ExpID 28586
Train - Loss (one batch): 0.03549
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04005, 0.04005, 0.20012, 0.13326, 836.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.03741, 0.03741, 0.19341, 0.13438, 947.12%
Time spent: 7.82s
- Epoch 023, ExpID 28586
Train - Loss (one batch): 0.03437
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04068, 0.04068, 0.20169, 0.13180, 659.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.03741, 0.03741, 0.19341, 0.13438, 947.12%
Time spent: 7.12s
- Epoch 024, ExpID 28586
Train - Loss (one batch): 0.03706
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04185, 0.04185, 0.20457, 0.13081, 536.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.03741, 0.03741, 0.19341, 0.13438, 947.12%
Time spent: 6.81s
- Epoch 025, ExpID 28586
Train - Loss (one batch): 0.03607
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04569, 0.04569, 0.21376, 0.13622, 618.03%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.03741, 0.03741, 0.19341, 0.13438, 947.12%
Time spent: 7.51s
- Epoch 026, ExpID 28586
Train - Loss (one batch): 0.03930
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03834, 0.03834, 0.19580, 0.12921, 725.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 26, 0.03709, 0.03709, 0.19258, 0.12869, 804.53%
Time spent: 8.47s
- Epoch 027, ExpID 28586
Train - Loss (one batch): 0.04131
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04757, 0.04757, 0.21810, 0.13710, 421.30%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 26, 0.03709, 0.03709, 0.19258, 0.12869, 804.53%
Time spent: 7.12s
- Epoch 028, ExpID 28586
Train - Loss (one batch): 0.03812
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04446, 0.04446, 0.21086, 0.13477, 629.83%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 26, 0.03709, 0.03709, 0.19258, 0.12869, 804.53%
Time spent: 6.34s
- Epoch 029, ExpID 28586
Train - Loss (one batch): 0.03655
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03930, 0.03930, 0.19823, 0.13102, 674.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 26, 0.03709, 0.03709, 0.19258, 0.12869, 804.53%
Time spent: 6.66s
- Epoch 030, ExpID 28586
Train - Loss (one batch): 0.03174
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04103, 0.04103, 0.20256, 0.13195, 700.99%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 26, 0.03709, 0.03709, 0.19258, 0.12869, 804.53%
Time spent: 7.32s
- Epoch 031, ExpID 28586
Train - Loss (one batch): 0.03354
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04502, 0.04502, 0.21217, 0.13562, 790.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 26, 0.03709, 0.03709, 0.19258, 0.12869, 804.53%
Time spent: 7.37s
- Epoch 032, ExpID 28586
Train - Loss (one batch): 0.03434
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03881, 0.03881, 0.19700, 0.12716, 584.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 26, 0.03709, 0.03709, 0.19258, 0.12869, 804.53%
Time spent: 6.96s
- Epoch 033, ExpID 28586
Train - Loss (one batch): 0.03388
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04158, 0.04158, 0.20391, 0.13142, 573.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 26, 0.03709, 0.03709, 0.19258, 0.12869, 804.53%
Time spent: 6.35s
- Epoch 034, ExpID 28586
Train - Loss (one batch): 0.04234
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04015, 0.04015, 0.20037, 0.12945, 582.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 26, 0.03709, 0.03709, 0.19258, 0.12869, 804.53%
Time spent: 7.38s
- Epoch 035, ExpID 28586
Train - Loss (one batch): 0.03722
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03884, 0.03884, 0.19708, 0.12887, 611.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 26, 0.03709, 0.03709, 0.19258, 0.12869, 804.53%
Time spent: 6.74s
- Epoch 036, ExpID 28586
Train - Loss (one batch): 0.03608
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04350, 0.04350, 0.20857, 0.13391, 708.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 26, 0.03709, 0.03709, 0.19258, 0.12869, 804.53%
Time spent: 7.93s
- Epoch 037, ExpID 28586
Train - Loss (one batch): 0.05014
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04292, 0.04292, 0.20717, 0.13093, 467.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 26, 0.03709, 0.03709, 0.19258, 0.12869, 804.53%
Time spent: 7.58s
- Epoch 038, ExpID 28586
Train - Loss (one batch): 0.03608
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04208, 0.04208, 0.20513, 0.13099, 582.43%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 26, 0.03709, 0.03709, 0.19258, 0.12869, 804.53%
Time spent: 7.84s
- Epoch 039, ExpID 28586
Train - Loss (one batch): 0.04545
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03759, 0.03759, 0.19388, 0.13093, 995.43%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 39, 0.03655, 0.03655, 0.19119, 0.13064, 1085.80%
Time spent: 8.72s
- Epoch 040, ExpID 28586
Train - Loss (one batch): 0.04366
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04232, 0.04232, 0.20571, 0.13047, 513.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 39, 0.03655, 0.03655, 0.19119, 0.13064, 1085.80%
Time spent: 7.15s
- Epoch 041, ExpID 28586
Train - Loss (one batch): 0.03806
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03638, 0.03638, 0.19075, 0.12594, 589.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 8.65s
- Epoch 042, ExpID 28586
Train - Loss (one batch): 0.03671
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04495, 0.04495, 0.21201, 0.13552, 544.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 7.81s
- Epoch 043, ExpID 28586
Train - Loss (one batch): 0.03721
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05021, 0.05021, 0.22408, 0.14166, 450.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 7.88s
- Epoch 044, ExpID 28586
Train - Loss (one batch): 0.04095
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03973, 0.03973, 0.19932, 0.12815, 630.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 7.99s
- Epoch 045, ExpID 28586
Train - Loss (one batch): 0.03115
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04149, 0.04149, 0.20370, 0.13055, 639.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 8.06s
- Epoch 046, ExpID 28586
Train - Loss (one batch): 0.03785
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04783, 0.04783, 0.21870, 0.13808, 633.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 7.90s
- Epoch 047, ExpID 28586
Train - Loss (one batch): 0.03390
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04182, 0.04182, 0.20450, 0.13174, 695.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 7.94s
- Epoch 048, ExpID 28586
Train - Loss (one batch): 0.04044
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04434, 0.04434, 0.21056, 0.13476, 647.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 7.70s
- Epoch 049, ExpID 28586
Train - Loss (one batch): 0.03380
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04348, 0.04348, 0.20853, 0.13329, 531.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 7.49s
- Epoch 050, ExpID 28586
Train - Loss (one batch): 0.03187
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04126, 0.04126, 0.20312, 0.12899, 530.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 7.50s
- Epoch 051, ExpID 28586
Train - Loss (one batch): 0.03514
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03712, 0.03712, 0.19266, 0.12616, 554.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 7.63s
- Epoch 052, ExpID 28586
Train - Loss (one batch): 0.03469
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03943, 0.03943, 0.19857, 0.12751, 633.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 6.41s
- Epoch 053, ExpID 28586
Train - Loss (one batch): 0.03289
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04167, 0.04167, 0.20414, 0.12987, 623.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 7.50s
- Epoch 054, ExpID 28586
Train - Loss (one batch): 0.03214
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04075, 0.04075, 0.20187, 0.12813, 589.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 7.36s
- Epoch 055, ExpID 28586
Train - Loss (one batch): 0.03258
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03952, 0.03952, 0.19881, 0.12633, 561.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 7.16s
- Epoch 056, ExpID 28586
Train - Loss (one batch): 0.03738
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04383, 0.04383, 0.20936, 0.13294, 567.85%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 7.02s
- Epoch 057, ExpID 28586
Train - Loss (one batch): 0.03627
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04105, 0.04105, 0.20262, 0.12849, 466.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 7.62s
- Epoch 058, ExpID 28586
Train - Loss (one batch): 0.03270
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04080, 0.04080, 0.20199, 0.12732, 511.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 6.93s
- Epoch 059, ExpID 28586
Train - Loss (one batch): 0.03993
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04476, 0.04476, 0.21156, 0.13281, 605.99%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 6.11s
- Epoch 060, ExpID 28586
Train - Loss (one batch): 0.03575
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04138, 0.04138, 0.20341, 0.12954, 623.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 7.77s
- Epoch 061, ExpID 28586
Train - Loss (one batch): 0.03227
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04303, 0.04303, 0.20743, 0.13265, 509.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 7.41s
- Epoch 062, ExpID 28586
Train - Loss (one batch): 0.04085
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03695, 0.03695, 0.19222, 0.12479, 645.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 6.97s
- Epoch 063, ExpID 28586
Train - Loss (one batch): 0.03248
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04264, 0.04264, 0.20649, 0.13322, 590.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 7.40s
- Epoch 064, ExpID 28586
Train - Loss (one batch): 0.04019
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04954, 0.04954, 0.22259, 0.14107, 536.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 6.90s
- Epoch 065, ExpID 28586
Train - Loss (one batch): 0.03125
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04593, 0.04593, 0.21432, 0.13724, 757.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 7.66s
- Epoch 066, ExpID 28586
Train - Loss (one batch): 0.03703
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03796, 0.03796, 0.19483, 0.12532, 545.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 7.72s
- Epoch 067, ExpID 28586
Train - Loss (one batch): 0.03606
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04796, 0.04796, 0.21899, 0.13697, 487.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 7.26s
- Epoch 068, ExpID 28586
Train - Loss (one batch): 0.04539
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04611, 0.04611, 0.21474, 0.13567, 674.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 6.36s
- Epoch 069, ExpID 28586
Train - Loss (one batch): 0.03582
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03874, 0.03874, 0.19683, 0.12717, 695.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 6.36s
- Epoch 070, ExpID 28586
Train - Loss (one batch): 0.03322
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04578, 0.04578, 0.21397, 0.13375, 488.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 6.31s
- Epoch 071, ExpID 28586
Train - Loss (one batch): 0.02830
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04964, 0.04964, 0.22280, 0.14015, 450.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 41, 0.03513, 0.03513, 0.18743, 0.12434, 659.63%
Time spent: 6.99s
- Epoch 072, ExpID 28586
Train - Loss (one batch): 0.03717
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03515, 0.03515, 0.18749, 0.12281, 524.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 7.98s
- Epoch 073, ExpID 28586
Train - Loss (one batch): 0.03300
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04372, 0.04372, 0.20909, 0.13152, 403.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 7.24s
- Epoch 074, ExpID 28586
Train - Loss (one batch): 0.03743
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03927, 0.03927, 0.19817, 0.12630, 575.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 6.93s
- Epoch 075, ExpID 28586
Train - Loss (one batch): 0.03534
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04258, 0.04258, 0.20635, 0.13035, 574.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 6.18s
- Epoch 076, ExpID 28586
Train - Loss (one batch): 0.03757
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03798, 0.03798, 0.19489, 0.12451, 452.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 6.36s
- Epoch 077, ExpID 28586
Train - Loss (one batch): 0.03657
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03833, 0.03833, 0.19579, 0.12695, 646.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 6.23s
- Epoch 078, ExpID 28586
Train - Loss (one batch): 0.03952
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04072, 0.04072, 0.20178, 0.13078, 757.99%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 6.04s
- Epoch 079, ExpID 28586
Train - Loss (one batch): 0.03693
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04230, 0.04230, 0.20567, 0.12974, 491.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 6.04s
- Epoch 080, ExpID 28586
Train - Loss (one batch): 0.03666
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04449, 0.04449, 0.21092, 0.13352, 642.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 6.16s
- Epoch 081, ExpID 28586
Train - Loss (one batch): 0.03093
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04660, 0.04660, 0.21586, 0.13656, 467.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 6.66s
- Epoch 082, ExpID 28586
Train - Loss (one batch): 0.03072
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04058, 0.04058, 0.20144, 0.12769, 513.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 6.58s
- Epoch 083, ExpID 28586
Train - Loss (one batch): 0.04391
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03821, 0.03821, 0.19548, 0.12487, 537.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 7.42s
- Epoch 084, ExpID 28586
Train - Loss (one batch): 0.03497
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04731, 0.04731, 0.21750, 0.13814, 573.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 7.61s
- Epoch 085, ExpID 28586
Train - Loss (one batch): 0.03356
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04329, 0.04329, 0.20807, 0.13282, 735.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 7.80s
- Epoch 086, ExpID 28586
Train - Loss (one batch): 0.03653
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04848, 0.04848, 0.22018, 0.13704, 528.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 6.51s
- Epoch 087, ExpID 28586
Train - Loss (one batch): 0.03778
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03559, 0.03559, 0.18866, 0.12240, 543.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 6.31s
- Epoch 088, ExpID 28586
Train - Loss (one batch): 0.03320
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04478, 0.04478, 0.21162, 0.13370, 523.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 7.33s
- Epoch 089, ExpID 28586
Train - Loss (one batch): 0.04091
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05080, 0.05080, 0.22539, 0.14033, 559.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 6.32s
- Epoch 090, ExpID 28586
Train - Loss (one batch): 0.03079
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05036, 0.05036, 0.22442, 0.14168, 541.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 6.11s
- Epoch 091, ExpID 28586
Train - Loss (one batch): 0.02942
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04168, 0.04168, 0.20417, 0.12922, 487.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 6.96s
- Epoch 092, ExpID 28586
Train - Loss (one batch): 0.03631
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05323, 0.05323, 0.23072, 0.14512, 613.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 7.39s
- Epoch 093, ExpID 28586
Train - Loss (one batch): 0.03756
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03925, 0.03925, 0.19813, 0.12483, 501.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 6.83s
- Epoch 094, ExpID 28586
Train - Loss (one batch): 0.03159
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04252, 0.04252, 0.20620, 0.13284, 606.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 7.62s
- Epoch 095, ExpID 28586
Train - Loss (one batch): 0.03472
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03933, 0.03933, 0.19831, 0.12727, 518.03%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 7.39s
- Epoch 096, ExpID 28586
Train - Loss (one batch): 0.02805
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04000, 0.04000, 0.20001, 0.12932, 600.48%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 7.56s
- Epoch 097, ExpID 28586
Train - Loss (one batch): 0.04485
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04317, 0.04317, 0.20778, 0.13106, 581.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 7.78s
- Epoch 098, ExpID 28586
Train - Loss (one batch): 0.03437
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03990, 0.03990, 0.19975, 0.12990, 571.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 7.63s
- Epoch 099, ExpID 28586
Train - Loss (one batch): 0.03434
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04507, 0.04507, 0.21231, 0.13461, 547.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.03421, 0.03421, 0.18497, 0.12213, 583.74%
Time spent: 7.22s
True
Couldn't import umap
PID, device: 1790166 cuda:0
Total records: 12000
Dataset n_samples: 12000 7200 2400 2400
Test record ids (first 20): ['141035', '147605', '135375', '161896', '139505', '162915', '146059', '161471', '137723', '146625', '137197', '133811', '142577', '138349', '145848', '156467', '139420', '145445', '141972', '132617']
Test record ids (last 20): ['151541', '135141', '148664', '151895', '137025', '143410', '132799', '160417', '143342', '157915', '143290', '141428', '147807', '145320', '146007', '136354', '153098', '148397', '138869', '145810']
data_max: tensor([9.0000e+01, 1.0000e+00, 4.6230e+02, 4.0000e+00, 3.0000e+02, 5.3000e+00,
        4.6950e+03, 1.6920e+04, 2.3950e+04, 6.2100e+01, 2.0900e+02, 3.6000e+02,
        2.2000e+01, 2.8300e+02, 1.0000e+00, 1.5000e+01, 1.5910e+03, 5.2000e+01,
        6.1800e+01, 3.0000e+02, 1.9600e+01, 3.1000e+01, 3.7500e+01, 3.0000e+02,
        1.0000e+00, 1.8000e+02, 2.1100e+02, 2.2800e+02, 3.0000e+02, 1.0000e+02,
        5.0000e+02, 7.3300e+02, 2.2920e+03, 1.0000e+02, 1.0000e+02, 2.9500e+02,
        4.2200e+01, 4.9600e+01, 2.9910e+01, 1.1000e+04, 6.2519e+03],
       device='cuda:0')
data_min: tensor([ 1.5000e+01, -1.0000e+00, -1.0000e+00,  1.0000e+00, -1.0000e+00,
         1.0000e+00,  8.0000e+00,  1.0000e+00,  4.0000e+00,  0.0000e+00,
         0.0000e+00,  2.8000e+01,  1.0000e-01, -1.0000e+00,  2.1000e-01,
         3.0000e+00,  8.0000e+00,  5.0000e+00,  5.5000e+00,  0.0000e+00,
         1.5000e+00,  3.0000e-01,  6.0000e-01,  0.0000e+00,  1.0000e+00,
         9.9000e+01, -1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  5.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00, -1.7800e+01,  1.0000e-01,  1.0000e-02,  0.0000e+00,
         1.0000e-01], device='cuda:0')
time_max: tensor(48., device='cuda:0')
model Model(
  (patch_embedding): PatchEmbedding(
    (padding_patch_layer): ReplicationPad1d((0, 8))
    (value_embedding): Linear(in_features=16, out_features=64, bias=False)
    (position_embedding): PositionalEmbedding()
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): Encoder(
    (attn_layers): ModuleList(
      (0-1): 2 x EncoderLayer(
        (attention): AttentionLayer(
          (inner_attention): FullAttention(
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (query_projection): Linear(in_features=64, out_features=64, bias=True)
          (key_projection): Linear(in_features=64, out_features=64, bias=True)
          (value_projection): Linear(in_features=64, out_features=64, bias=True)
          (out_projection): Linear(in_features=64, out_features=64, bias=True)
        )
        (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): Sequential(
      (0): Transpose()
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Transpose()
    )
  )
  (te_scale): Linear(in_features=1, out_features=1, bias=True)
  (te_periodic): Linear(in_features=1, out_features=63, bias=True)
  (decoder): Sequential(
    (0): Linear(in_features=128, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=1, bias=True)
  )
)
parameters: 64193
n_train_batches: 225
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_baselines.py
2024-07-19 11:07:34
run_baselines.py --history 36 --model PatchTST --dataset physionet
Namespace(state='def', n=100000000, epoch=100, patience=10, history=36, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='physionet', quantization=0.0, model='PatchTST', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=8, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='0', seq_len=175, top_k=5, num_kernels=64, npatch=2, device=device(type='cuda', index=0), PID=1799768, pred_window=12, ndim=41, patch_layer=2, task_name='long_term_forecast', label_len=48, pred_len=96, patch_len=16, d_model=64, dropout=0.1, output_attention=None, n_heads=1, d_ff=64, activation='gelu', e_layers=2, factor=3, enc_in=321)
- Epoch 000, ExpID 76954
Train - Loss (one batch): 0.04787
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05622, 0.05622, 0.23711, 0.15849, 677.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05496, 0.05496, 0.23443, 0.15663, 661.46%
Time spent: 9.40s
- Epoch 001, ExpID 76954
Train - Loss (one batch): 0.04082
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04479, 0.04479, 0.21163, 0.14426, 744.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.04394, 0.04394, 0.20962, 0.14288, 723.45%
Time spent: 8.74s
- Epoch 002, ExpID 76954
Train - Loss (one batch): 0.04024
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04652, 0.04652, 0.21568, 0.15638, 1170.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.04394, 0.04394, 0.20962, 0.14288, 723.45%
Time spent: 7.59s
- Epoch 003, ExpID 76954
Train - Loss (one batch): 0.05126
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05030, 0.05030, 0.22428, 0.14590, 765.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.04394, 0.04394, 0.20962, 0.14288, 723.45%
Time spent: 7.18s
- Epoch 004, ExpID 76954
Train - Loss (one batch): 0.04106
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04707, 0.04707, 0.21697, 0.14630, 1104.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.04394, 0.04394, 0.20962, 0.14288, 723.45%
Time spent: 6.60s
- Epoch 005, ExpID 76954
Train - Loss (one batch): 0.03949
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04092, 0.04092, 0.20229, 0.13773, 966.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 5, 0.04045, 0.04045, 0.20113, 0.13634, 928.74%
Time spent: 7.52s
- Epoch 006, ExpID 76954
Train - Loss (one batch): 0.03817
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03795, 0.03795, 0.19480, 0.13763, 890.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.03789, 0.03789, 0.19464, 0.13702, 846.53%
Time spent: 7.33s
- Epoch 007, ExpID 76954
Train - Loss (one batch): 0.03526
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04555, 0.04555, 0.21342, 0.13779, 747.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.03789, 0.03789, 0.19464, 0.13702, 846.53%
Time spent: 7.12s
- Epoch 008, ExpID 76954
Train - Loss (one batch): 0.03951
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04459, 0.04459, 0.21117, 0.14248, 1106.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.03789, 0.03789, 0.19464, 0.13702, 846.53%
Time spent: 7.15s
- Epoch 009, ExpID 76954
Train - Loss (one batch): 0.04342
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04232, 0.04232, 0.20572, 0.13349, 602.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.03789, 0.03789, 0.19464, 0.13702, 846.53%
Time spent: 7.32s
- Epoch 010, ExpID 76954
Train - Loss (one batch): 0.04905
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04348, 0.04348, 0.20851, 0.13919, 858.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.03789, 0.03789, 0.19464, 0.13702, 846.53%
Time spent: 6.39s
- Epoch 011, ExpID 76954
Train - Loss (one batch): 0.03758
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03883, 0.03883, 0.19706, 0.14332, 1250.99%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.03789, 0.03789, 0.19464, 0.13702, 846.53%
Time spent: 6.40s
- Epoch 012, ExpID 76954
Train - Loss (one batch): 0.03691
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03614, 0.03614, 0.19010, 0.13387, 1026.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 12, 0.03623, 0.03623, 0.19035, 0.13331, 981.42%
Time spent: 9.02s
- Epoch 013, ExpID 76954
Train - Loss (one batch): 0.03133
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03609, 0.03609, 0.18997, 0.13640, 1013.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.03602, 0.03602, 0.18978, 0.13557, 967.33%
Time spent: 8.57s
- Epoch 014, ExpID 76954
Train - Loss (one batch): 0.03843
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04178, 0.04178, 0.20441, 0.13201, 641.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.03602, 0.03602, 0.18978, 0.13557, 967.33%
Time spent: 6.58s
- Epoch 015, ExpID 76954
Train - Loss (one batch): 0.04337
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04562, 0.04562, 0.21359, 0.13405, 396.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.03602, 0.03602, 0.18978, 0.13557, 967.33%
Time spent: 7.49s
- Epoch 016, ExpID 76954
Train - Loss (one batch): 0.03233
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03950, 0.03950, 0.19874, 0.12830, 638.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.03602, 0.03602, 0.18978, 0.13557, 967.33%
Time spent: 7.92s
- Epoch 017, ExpID 76954
Train - Loss (one batch): 0.03667
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04024, 0.04024, 0.20060, 0.13015, 687.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.03602, 0.03602, 0.18978, 0.13557, 967.33%
Time spent: 7.16s
- Epoch 018, ExpID 76954
Train - Loss (one batch): 0.03379
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03973, 0.03973, 0.19932, 0.12906, 718.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.03602, 0.03602, 0.18978, 0.13557, 967.33%
Time spent: 7.11s
- Epoch 019, ExpID 76954
Train - Loss (one batch): 0.03130
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05429, 0.05429, 0.23300, 0.14638, 522.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.03602, 0.03602, 0.18978, 0.13557, 967.33%
Time spent: 7.38s
- Epoch 020, ExpID 76954
Train - Loss (one batch): 0.03529
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04048, 0.04048, 0.20120, 0.13004, 621.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.03602, 0.03602, 0.18978, 0.13557, 967.33%
Time spent: 7.32s
- Epoch 021, ExpID 76954
Train - Loss (one batch): 0.03697
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03688, 0.03688, 0.19205, 0.12990, 1020.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.03602, 0.03602, 0.18978, 0.13557, 967.33%
Time spent: 7.55s
- Epoch 022, ExpID 76954
Train - Loss (one batch): 0.03267
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04677, 0.04677, 0.21625, 0.13363, 360.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.03602, 0.03602, 0.18978, 0.13557, 967.33%
Time spent: 6.61s
- Epoch 023, ExpID 76954
Train - Loss (one batch): 0.03687
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03936, 0.03936, 0.19840, 0.12552, 444.57%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.03602, 0.03602, 0.18978, 0.13557, 967.33%
Time spent: 7.61s
- Epoch 024, ExpID 76954
Train - Loss (one batch): 0.04854
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04097, 0.04097, 0.20242, 0.12911, 657.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.03602, 0.03602, 0.18978, 0.13557, 967.33%
Time spent: 7.89s
- Epoch 025, ExpID 76954
Train - Loss (one batch): 0.03573
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03919, 0.03919, 0.19796, 0.12908, 819.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.03602, 0.03602, 0.18978, 0.13557, 967.33%
Time spent: 6.29s
- Epoch 026, ExpID 76954
Train - Loss (one batch): 0.04173
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03869, 0.03869, 0.19669, 0.12798, 747.62%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.03602, 0.03602, 0.18978, 0.13557, 967.33%
Time spent: 6.00s
- Epoch 027, ExpID 76954
Train - Loss (one batch): 0.03498
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03563, 0.03563, 0.18875, 0.13050, 777.43%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.03587, 0.03587, 0.18940, 0.13083, 725.00%
Time spent: 7.88s
- Epoch 028, ExpID 76954
Train - Loss (one batch): 0.03621
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04616, 0.04616, 0.21484, 0.13732, 503.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.03587, 0.03587, 0.18940, 0.13083, 725.00%
Time spent: 7.39s
- Epoch 029, ExpID 76954
Train - Loss (one batch): 0.04046
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03719, 0.03719, 0.19285, 0.12377, 564.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.03587, 0.03587, 0.18940, 0.13083, 725.00%
Time spent: 7.09s
- Epoch 030, ExpID 76954
Train - Loss (one batch): 0.04340
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03971, 0.03971, 0.19927, 0.13271, 919.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.03587, 0.03587, 0.18940, 0.13083, 725.00%
Time spent: 6.55s
- Epoch 031, ExpID 76954
Train - Loss (one batch): 0.02905
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04154, 0.04154, 0.20380, 0.13240, 737.48%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.03587, 0.03587, 0.18940, 0.13083, 725.00%
Time spent: 6.36s
- Epoch 032, ExpID 76954
Train - Loss (one batch): 0.03948
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04036, 0.04036, 0.20090, 0.12824, 673.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.03587, 0.03587, 0.18940, 0.13083, 725.00%
Time spent: 6.34s
- Epoch 033, ExpID 76954
Train - Loss (one batch): 0.02888
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04569, 0.04569, 0.21374, 0.13484, 628.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.03587, 0.03587, 0.18940, 0.13083, 725.00%
Time spent: 7.69s
- Epoch 034, ExpID 76954
Train - Loss (one batch): 0.03166
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04329, 0.04329, 0.20807, 0.12707, 193.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.03587, 0.03587, 0.18940, 0.13083, 725.00%
Time spent: 7.46s
- Epoch 035, ExpID 76954
Train - Loss (one batch): 0.03492
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03806, 0.03806, 0.19509, 0.12407, 558.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.03587, 0.03587, 0.18940, 0.13083, 725.00%
Time spent: 6.62s
- Epoch 036, ExpID 76954
Train - Loss (one batch): 0.04041
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03620, 0.03620, 0.19026, 0.12282, 613.02%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.03587, 0.03587, 0.18940, 0.13083, 725.00%
Time spent: 6.36s
- Epoch 037, ExpID 76954
Train - Loss (one batch): 0.03081
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03977, 0.03977, 0.19944, 0.12482, 479.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.03587, 0.03587, 0.18940, 0.13083, 725.00%
Time spent: 7.80s
- Epoch 038, ExpID 76954
Train - Loss (one batch): 0.03916
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03772, 0.03772, 0.19421, 0.12778, 869.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.03587, 0.03587, 0.18940, 0.13083, 725.00%
Time spent: 7.76s
- Epoch 039, ExpID 76954
Train - Loss (one batch): 0.03414
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04108, 0.04108, 0.20268, 0.12785, 517.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.03587, 0.03587, 0.18940, 0.13083, 725.00%
Time spent: 6.15s
- Epoch 040, ExpID 76954
Train - Loss (one batch): 0.03375
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03538, 0.03538, 0.18809, 0.11956, 466.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.03481, 0.03481, 0.18658, 0.11872, 430.89%
Time spent: 7.85s
- Epoch 041, ExpID 76954
Train - Loss (one batch): 0.03613
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03749, 0.03749, 0.19362, 0.12174, 545.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.03481, 0.03481, 0.18658, 0.11872, 430.89%
Time spent: 5.89s
- Epoch 042, ExpID 76954
Train - Loss (one batch): 0.03604
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04216, 0.04216, 0.20533, 0.13227, 663.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.03481, 0.03481, 0.18658, 0.11872, 430.89%
Time spent: 5.95s
- Epoch 043, ExpID 76954
Train - Loss (one batch): 0.03133
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04543, 0.04543, 0.21315, 0.13470, 624.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.03481, 0.03481, 0.18658, 0.11872, 430.89%
Time spent: 5.96s
- Epoch 044, ExpID 76954
Train - Loss (one batch): 0.04033
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03403, 0.03403, 0.18448, 0.12141, 584.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 44, 0.03365, 0.03365, 0.18344, 0.12072, 541.63%
Time spent: 8.17s
- Epoch 045, ExpID 76954
Train - Loss (one batch): 0.04413
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04365, 0.04365, 0.20892, 0.12982, 501.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 44, 0.03365, 0.03365, 0.18344, 0.12072, 541.63%
Time spent: 7.62s
- Epoch 046, ExpID 76954
Train - Loss (one batch): 0.03591
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03545, 0.03545, 0.18828, 0.11944, 505.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 44, 0.03365, 0.03365, 0.18344, 0.12072, 541.63%
Time spent: 6.57s
- Epoch 047, ExpID 76954
Train - Loss (one batch): 0.03394
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03644, 0.03644, 0.19090, 0.12121, 538.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 44, 0.03365, 0.03365, 0.18344, 0.12072, 541.63%
Time spent: 7.14s
- Epoch 048, ExpID 76954
Train - Loss (one batch): 0.03261
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03731, 0.03731, 0.19315, 0.12462, 667.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 44, 0.03365, 0.03365, 0.18344, 0.12072, 541.63%
Time spent: 7.49s
- Epoch 049, ExpID 76954
Train - Loss (one batch): 0.02954
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03892, 0.03892, 0.19729, 0.12495, 628.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 44, 0.03365, 0.03365, 0.18344, 0.12072, 541.63%
Time spent: 7.83s
- Epoch 050, ExpID 76954
Train - Loss (one batch): 0.03383
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03400, 0.03400, 0.18439, 0.11841, 703.74%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 50, 0.03351, 0.03351, 0.18306, 0.11700, 648.55%
Time spent: 8.24s
- Epoch 051, ExpID 76954
Train - Loss (one batch): 0.03434
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04093, 0.04093, 0.20232, 0.13169, 862.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 50, 0.03351, 0.03351, 0.18306, 0.11700, 648.55%
Time spent: 7.55s
- Epoch 052, ExpID 76954
Train - Loss (one batch): 0.03886
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04413, 0.04413, 0.21007, 0.13329, 722.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 50, 0.03351, 0.03351, 0.18306, 0.11700, 648.55%
Time spent: 7.79s
- Epoch 053, ExpID 76954
Train - Loss (one batch): 0.02797
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03846, 0.03846, 0.19612, 0.12605, 725.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 50, 0.03351, 0.03351, 0.18306, 0.11700, 648.55%
Time spent: 7.72s
- Epoch 054, ExpID 76954
Train - Loss (one batch): 0.02904
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04133, 0.04133, 0.20329, 0.12807, 617.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 50, 0.03351, 0.03351, 0.18306, 0.11700, 648.55%
Time spent: 7.76s
- Epoch 055, ExpID 76954
Train - Loss (one batch): 0.02972
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03549, 0.03549, 0.18839, 0.11919, 559.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 50, 0.03351, 0.03351, 0.18306, 0.11700, 648.55%
Time spent: 7.72s
- Epoch 056, ExpID 76954
Train - Loss (one batch): 0.02994
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03430, 0.03430, 0.18520, 0.11902, 688.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 50, 0.03351, 0.03351, 0.18306, 0.11700, 648.55%
Time spent: 6.71s
- Epoch 057, ExpID 76954
Train - Loss (one batch): 0.02722
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04071, 0.04071, 0.20178, 0.12675, 508.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 50, 0.03351, 0.03351, 0.18306, 0.11700, 648.55%
Time spent: 6.96s
- Epoch 058, ExpID 76954
Train - Loss (one batch): 0.03054
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04173, 0.04173, 0.20429, 0.12593, 452.18%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 50, 0.03351, 0.03351, 0.18306, 0.11700, 648.55%
Time spent: 7.26s
- Epoch 059, ExpID 76954
Train - Loss (one batch): 0.03096
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03727, 0.03727, 0.19306, 0.12215, 509.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 50, 0.03351, 0.03351, 0.18306, 0.11700, 648.55%
Time spent: 5.84s
- Epoch 060, ExpID 76954
Train - Loss (one batch): 0.03252
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03909, 0.03909, 0.19771, 0.12666, 857.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 50, 0.03351, 0.03351, 0.18306, 0.11700, 648.55%
Time spent: 5.92s
- Epoch 061, ExpID 76954
Train - Loss (one batch): 0.04186
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03636, 0.03636, 0.19069, 0.12111, 543.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 50, 0.03351, 0.03351, 0.18306, 0.11700, 648.55%
Time spent: 6.24s
- Epoch 062, ExpID 76954
Train - Loss (one batch): 0.03966
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03437, 0.03437, 0.18539, 0.11843, 473.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 50, 0.03351, 0.03351, 0.18306, 0.11700, 648.55%
Time spent: 6.22s
- Epoch 063, ExpID 76954
Train - Loss (one batch): 0.03193
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03430, 0.03430, 0.18521, 0.12061, 778.48%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 50, 0.03351, 0.03351, 0.18306, 0.11700, 648.55%
Time spent: 5.66s
- Epoch 064, ExpID 76954
Train - Loss (one batch): 0.03572
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03165, 0.03165, 0.17790, 0.11400, 539.99%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 7.55s
- Epoch 065, ExpID 76954
Train - Loss (one batch): 0.02781
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03757, 0.03757, 0.19384, 0.12256, 587.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.66s
- Epoch 066, ExpID 76954
Train - Loss (one batch): 0.03133
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03324, 0.03324, 0.18230, 0.11575, 559.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 5.98s
- Epoch 067, ExpID 76954
Train - Loss (one batch): 0.02697
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03610, 0.03610, 0.19001, 0.12055, 604.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 5.97s
- Epoch 068, ExpID 76954
Train - Loss (one batch): 0.03582
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04345, 0.04345, 0.20845, 0.13119, 493.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 5.97s
- Epoch 069, ExpID 76954
Train - Loss (one batch): 0.03092
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04077, 0.04077, 0.20190, 0.12791, 527.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.29s
- Epoch 070, ExpID 76954
Train - Loss (one batch): 0.03413
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03631, 0.03631, 0.19055, 0.12066, 585.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.38s
- Epoch 071, ExpID 76954
Train - Loss (one batch): 0.03298
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04593, 0.04593, 0.21432, 0.13135, 325.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.18s
- Epoch 072, ExpID 76954
Train - Loss (one batch): 0.03353
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04226, 0.04226, 0.20558, 0.13032, 648.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.38s
- Epoch 073, ExpID 76954
Train - Loss (one batch): 0.03703
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05076, 0.05076, 0.22531, 0.14344, 630.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.10s
- Epoch 074, ExpID 76954
Train - Loss (one batch): 0.03319
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03877, 0.03877, 0.19689, 0.12325, 519.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.30s
- Epoch 075, ExpID 76954
Train - Loss (one batch): 0.03026
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04298, 0.04298, 0.20730, 0.12937, 666.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.35s
- Epoch 076, ExpID 76954
Train - Loss (one batch): 0.02862
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03979, 0.03979, 0.19948, 0.12534, 565.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.09s
- Epoch 077, ExpID 76954
Train - Loss (one batch): 0.03096
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03533, 0.03533, 0.18797, 0.11959, 501.85%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.18s
- Epoch 078, ExpID 76954
Train - Loss (one batch): 0.02987
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04159, 0.04159, 0.20395, 0.12824, 648.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.58s
- Epoch 079, ExpID 76954
Train - Loss (one batch): 0.03263
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03546, 0.03546, 0.18831, 0.12023, 684.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.51s
- Epoch 080, ExpID 76954
Train - Loss (one batch): 0.02887
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04023, 0.04023, 0.20058, 0.12650, 670.18%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.22s
- Epoch 081, ExpID 76954
Train - Loss (one batch): 0.03576
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03720, 0.03720, 0.19288, 0.12243, 634.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 5.90s
- Epoch 082, ExpID 76954
Train - Loss (one batch): 0.02893
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04064, 0.04064, 0.20159, 0.12936, 503.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.41s
- Epoch 083, ExpID 76954
Train - Loss (one batch): 0.03686
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04033, 0.04033, 0.20082, 0.12500, 584.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.38s
- Epoch 084, ExpID 76954
Train - Loss (one batch): 0.02927
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03828, 0.03828, 0.19566, 0.12239, 548.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.25s
- Epoch 085, ExpID 76954
Train - Loss (one batch): 0.03003
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03274, 0.03274, 0.18093, 0.11643, 498.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.45s
- Epoch 086, ExpID 76954
Train - Loss (one batch): 0.02904
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03838, 0.03838, 0.19592, 0.12391, 612.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.43s
- Epoch 087, ExpID 76954
Train - Loss (one batch): 0.02872
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05098, 0.05098, 0.22579, 0.14424, 720.48%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.37s
- Epoch 088, ExpID 76954
Train - Loss (one batch): 0.03302
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03656, 0.03656, 0.19120, 0.12333, 659.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.28s
- Epoch 089, ExpID 76954
Train - Loss (one batch): 0.03646
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04765, 0.04765, 0.21829, 0.13539, 570.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.20s
- Epoch 090, ExpID 76954
Train - Loss (one batch): 0.03751
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05193, 0.05193, 0.22787, 0.14154, 591.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.08s
- Epoch 091, ExpID 76954
Train - Loss (one batch): 0.03728
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03872, 0.03872, 0.19677, 0.12224, 410.86%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.25s
- Epoch 092, ExpID 76954
Train - Loss (one batch): 0.03127
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04366, 0.04366, 0.20894, 0.13266, 672.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 6.19s
- Epoch 093, ExpID 76954
Train - Loss (one batch): 0.02504
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03684, 0.03684, 0.19193, 0.12154, 661.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 5.80s
- Epoch 094, ExpID 76954
Train - Loss (one batch): 0.04089
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03997, 0.03997, 0.19993, 0.12515, 465.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 5.79s
- Epoch 095, ExpID 76954
Train - Loss (one batch): 0.03419
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04570, 0.04570, 0.21377, 0.13339, 633.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 5.75s
- Epoch 096, ExpID 76954
Train - Loss (one batch): 0.03224
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04448, 0.04448, 0.21089, 0.13185, 673.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 5.81s
- Epoch 097, ExpID 76954
Train - Loss (one batch): 0.02427
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03558, 0.03558, 0.18862, 0.12025, 756.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 5.79s
- Epoch 098, ExpID 76954
Train - Loss (one batch): 0.03467
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03420, 0.03420, 0.18493, 0.11554, 525.18%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 5.36s
- Epoch 099, ExpID 76954
Train - Loss (one batch): 0.02645
Val - Loss, MSE, RMSE, MAE, MAPE: 0.03547, 0.03547, 0.18833, 0.12070, 665.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 64, 0.03132, 0.03132, 0.17697, 0.11220, 501.70%
Time spent: 4.91s
True
Couldn't import umap
PID, device: 1799768 cuda:0
Total records: 12000
Dataset n_samples: 12000 7200 2400 2400
Test record ids (first 20): ['141035', '147605', '135375', '161896', '139505', '162915', '146059', '161471', '137723', '146625', '137197', '133811', '142577', '138349', '145848', '156467', '139420', '145445', '141972', '132617']
Test record ids (last 20): ['151541', '135141', '148664', '151895', '137025', '143410', '132799', '160417', '143342', '157915', '143290', '141428', '147807', '145320', '146007', '136354', '153098', '148397', '138869', '145810']
data_max: tensor([9.0000e+01, 1.0000e+00, 4.6230e+02, 4.0000e+00, 3.0000e+02, 5.3000e+00,
        4.6950e+03, 1.6920e+04, 2.3950e+04, 6.2100e+01, 2.0900e+02, 3.6000e+02,
        2.2000e+01, 2.8300e+02, 1.0000e+00, 1.5000e+01, 1.5910e+03, 5.2000e+01,
        6.1800e+01, 3.0000e+02, 1.9600e+01, 3.1000e+01, 3.7500e+01, 3.0000e+02,
        1.0000e+00, 1.8000e+02, 2.1100e+02, 2.2800e+02, 3.0000e+02, 1.0000e+02,
        5.0000e+02, 7.3300e+02, 2.2920e+03, 1.0000e+02, 1.0000e+02, 2.9500e+02,
        4.2200e+01, 4.9600e+01, 2.9910e+01, 1.1000e+04, 6.2519e+03],
       device='cuda:0')
data_min: tensor([ 1.5000e+01, -1.0000e+00, -1.0000e+00,  1.0000e+00, -1.0000e+00,
         1.0000e+00,  8.0000e+00,  1.0000e+00,  4.0000e+00,  0.0000e+00,
         0.0000e+00,  2.8000e+01,  1.0000e-01, -1.0000e+00,  2.1000e-01,
         3.0000e+00,  8.0000e+00,  5.0000e+00,  5.5000e+00,  0.0000e+00,
         1.5000e+00,  3.0000e-01,  6.0000e-01,  0.0000e+00,  1.0000e+00,
         9.9000e+01, -1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  5.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00, -1.7800e+01,  1.0000e-01,  1.0000e-02,  0.0000e+00,
         1.0000e-01], device='cuda:0')
time_max: tensor(48., device='cuda:0')
model Model(
  (patch_embedding): PatchEmbedding(
    (padding_patch_layer): ReplicationPad1d((0, 8))
    (value_embedding): Linear(in_features=16, out_features=64, bias=False)
    (position_embedding): PositionalEmbedding()
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): Encoder(
    (attn_layers): ModuleList(
      (0-1): 2 x EncoderLayer(
        (attention): AttentionLayer(
          (inner_attention): FullAttention(
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (query_projection): Linear(in_features=64, out_features=64, bias=True)
          (key_projection): Linear(in_features=64, out_features=64, bias=True)
          (value_projection): Linear(in_features=64, out_features=64, bias=True)
          (out_projection): Linear(in_features=64, out_features=64, bias=True)
        )
        (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): Sequential(
      (0): Transpose()
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Transpose()
    )
  )
  (te_scale): Linear(in_features=1, out_features=1, bias=True)
  (te_periodic): Linear(in_features=1, out_features=63, bias=True)
  (decoder): Sequential(
    (0): Linear(in_features=128, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=1, bias=True)
  )
)
parameters: 64193
n_train_batches: 225
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_baselines.py
2024-07-19 11:19:43
run_baselines.py --history 12 --model PatchTST --dataset physionet
Namespace(state='def', n=100000000, epoch=100, patience=10, history=12, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='physionet', quantization=0.0, model='PatchTST', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=8, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='0', seq_len=83, top_k=5, num_kernels=64, npatch=1, device=device(type='cuda', index=0), PID=1809119, pred_window=36, ndim=41, patch_layer=1, task_name='long_term_forecast', label_len=48, pred_len=96, patch_len=16, d_model=64, dropout=0.1, output_attention=None, n_heads=1, d_ff=64, activation='gelu', e_layers=2, factor=3, enc_in=321)
- Epoch 000, ExpID 3107
Train - Loss (one batch): 0.05770
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05646, 0.05646, 0.23760, 0.17093, 1355.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05508, 0.05508, 0.23470, 0.16882, 1398.84%
Time spent: 8.68s
- Epoch 001, ExpID 3107
Train - Loss (one batch): 0.04785
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05965, 0.05965, 0.24424, 0.17142, 1385.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.05508, 0.05508, 0.23470, 0.16882, 1398.84%
Time spent: 7.39s
- Epoch 002, ExpID 3107
Train - Loss (one batch): 0.04948
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05449, 0.05449, 0.23344, 0.17057, 1571.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.05346, 0.05346, 0.23121, 0.16917, 1624.95%
Time spent: 8.07s
- Epoch 003, ExpID 3107
Train - Loss (one batch): 0.05273
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05200, 0.05200, 0.22803, 0.16393, 1419.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.05098, 0.05098, 0.22579, 0.16224, 1464.92%
Time spent: 7.58s
- Epoch 004, ExpID 3107
Train - Loss (one batch): 0.05705
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05852, 0.05852, 0.24190, 0.16727, 1360.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.05098, 0.05098, 0.22579, 0.16224, 1464.92%
Time spent: 6.01s
- Epoch 005, ExpID 3107
Train - Loss (one batch): 0.05293
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04861, 0.04861, 0.22047, 0.16221, 1075.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 5, 0.04798, 0.04798, 0.21904, 0.16097, 1099.76%
Time spent: 7.08s
- Epoch 006, ExpID 3107
Train - Loss (one batch): 0.04995
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04810, 0.04810, 0.21932, 0.16274, 1271.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.04770, 0.04770, 0.21841, 0.16138, 1295.40%
Time spent: 6.58s
- Epoch 007, ExpID 3107
Train - Loss (one batch): 0.04811
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04943, 0.04943, 0.22233, 0.15651, 1125.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.04770, 0.04770, 0.21841, 0.16138, 1295.40%
Time spent: 6.44s
- Epoch 008, ExpID 3107
Train - Loss (one batch): 0.04646
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04876, 0.04876, 0.22082, 0.15988, 1398.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.04770, 0.04770, 0.21841, 0.16138, 1295.40%
Time spent: 6.61s
- Epoch 009, ExpID 3107
Train - Loss (one batch): 0.04090
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04716, 0.04716, 0.21716, 0.15786, 1076.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.04680, 0.04680, 0.21633, 0.15709, 1104.23%
Time spent: 6.73s
- Epoch 010, ExpID 3107
Train - Loss (one batch): 0.04354
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04877, 0.04877, 0.22083, 0.15487, 1189.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.04680, 0.04680, 0.21633, 0.15709, 1104.23%
Time spent: 5.96s
- Epoch 011, ExpID 3107
Train - Loss (one batch): 0.04447
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04893, 0.04893, 0.22120, 0.15013, 796.03%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.04680, 0.04680, 0.21633, 0.15709, 1104.23%
Time spent: 6.48s
- Epoch 012, ExpID 3107
Train - Loss (one batch): 0.04606
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04789, 0.04789, 0.21884, 0.15510, 1066.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.04680, 0.04680, 0.21633, 0.15709, 1104.23%
Time spent: 6.64s
- Epoch 013, ExpID 3107
Train - Loss (one batch): 0.05335
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04794, 0.04794, 0.21896, 0.15680, 1048.57%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.04680, 0.04680, 0.21633, 0.15709, 1104.23%
Time spent: 6.26s
- Epoch 014, ExpID 3107
Train - Loss (one batch): 0.05548
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04891, 0.04891, 0.22115, 0.16692, 1410.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.04680, 0.04680, 0.21633, 0.15709, 1104.23%
Time spent: 6.75s
- Epoch 015, ExpID 3107
Train - Loss (one batch): 0.05779
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05031, 0.05031, 0.22430, 0.15378, 950.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.04680, 0.04680, 0.21633, 0.15709, 1104.23%
Time spent: 5.57s
- Epoch 016, ExpID 3107
Train - Loss (one batch): 0.04950
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04720, 0.04720, 0.21725, 0.15094, 1024.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.04680, 0.04680, 0.21633, 0.15709, 1104.23%
Time spent: 5.65s
- Epoch 017, ExpID 3107
Train - Loss (one batch): 0.04492
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04721, 0.04721, 0.21729, 0.15362, 1062.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 9, 0.04680, 0.04680, 0.21633, 0.15709, 1104.23%
Time spent: 5.22s
- Epoch 018, ExpID 3107
Train - Loss (one batch): 0.04384
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04619, 0.04619, 0.21492, 0.15150, 1064.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.04529, 0.04529, 0.21281, 0.14976, 1100.71%
Time spent: 6.80s
- Epoch 019, ExpID 3107
Train - Loss (one batch): 0.04313
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04568, 0.04568, 0.21373, 0.15307, 974.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 19, 0.04522, 0.04522, 0.21265, 0.15210, 1014.72%
Time spent: 7.95s
- Epoch 020, ExpID 3107
Train - Loss (one batch): 0.05680
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04609, 0.04609, 0.21469, 0.15145, 1002.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 19, 0.04522, 0.04522, 0.21265, 0.15210, 1014.72%
Time spent: 6.73s
- Epoch 021, ExpID 3107
Train - Loss (one batch): 0.04150
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04709, 0.04709, 0.21700, 0.14794, 868.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 19, 0.04522, 0.04522, 0.21265, 0.15210, 1014.72%
Time spent: 7.01s
- Epoch 022, ExpID 3107
Train - Loss (one batch): 0.04264
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04689, 0.04689, 0.21655, 0.14806, 939.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 19, 0.04522, 0.04522, 0.21265, 0.15210, 1014.72%
Time spent: 6.63s
- Epoch 023, ExpID 3107
Train - Loss (one batch): 0.04556
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04964, 0.04964, 0.22280, 0.14987, 906.30%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 19, 0.04522, 0.04522, 0.21265, 0.15210, 1014.72%
Time spent: 6.66s
- Epoch 024, ExpID 3107
Train - Loss (one batch): 0.04583
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04529, 0.04529, 0.21283, 0.15085, 877.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 24, 0.04472, 0.04472, 0.21148, 0.14955, 913.82%
Time spent: 7.33s
- Epoch 025, ExpID 3107
Train - Loss (one batch): 0.05284
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04867, 0.04867, 0.22062, 0.15324, 1018.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 24, 0.04472, 0.04472, 0.21148, 0.14955, 913.82%
Time spent: 6.01s
- Epoch 026, ExpID 3107
Train - Loss (one batch): 0.05441
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04672, 0.04672, 0.21616, 0.15072, 1116.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 24, 0.04472, 0.04472, 0.21148, 0.14955, 913.82%
Time spent: 5.84s
- Epoch 027, ExpID 3107
Train - Loss (one batch): 0.05250
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04455, 0.04455, 0.21107, 0.14671, 884.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.04394, 0.04394, 0.20962, 0.14527, 926.96%
Time spent: 6.02s
- Epoch 028, ExpID 3107
Train - Loss (one batch): 0.04483
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05259, 0.05259, 0.22933, 0.15171, 798.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.04394, 0.04394, 0.20962, 0.14527, 926.96%
Time spent: 5.86s
- Epoch 029, ExpID 3107
Train - Loss (one batch): 0.04842
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05206, 0.05206, 0.22817, 0.15526, 974.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.04394, 0.04394, 0.20962, 0.14527, 926.96%
Time spent: 5.72s
- Epoch 030, ExpID 3107
Train - Loss (one batch): 0.04538
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04844, 0.04844, 0.22009, 0.15127, 1008.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.04394, 0.04394, 0.20962, 0.14527, 926.96%
Time spent: 5.69s
- Epoch 031, ExpID 3107
Train - Loss (one batch): 0.04828
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04699, 0.04699, 0.21676, 0.14610, 829.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.04394, 0.04394, 0.20962, 0.14527, 926.96%
Time spent: 5.53s
- Epoch 032, ExpID 3107
Train - Loss (one batch): 0.04579
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04577, 0.04577, 0.21394, 0.15125, 1047.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.04394, 0.04394, 0.20962, 0.14527, 926.96%
Time spent: 6.02s
- Epoch 033, ExpID 3107
Train - Loss (one batch): 0.04615
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04570, 0.04570, 0.21378, 0.14967, 811.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.04394, 0.04394, 0.20962, 0.14527, 926.96%
Time spent: 5.41s
- Epoch 034, ExpID 3107
Train - Loss (one batch): 0.04938
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04769, 0.04769, 0.21838, 0.14943, 999.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.04394, 0.04394, 0.20962, 0.14527, 926.96%
Time spent: 5.52s
- Epoch 035, ExpID 3107
Train - Loss (one batch): 0.05328
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04847, 0.04847, 0.22017, 0.14601, 768.85%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.04394, 0.04394, 0.20962, 0.14527, 926.96%
Time spent: 5.52s
- Epoch 036, ExpID 3107
Train - Loss (one batch): 0.05146
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04680, 0.04680, 0.21633, 0.14655, 883.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.04394, 0.04394, 0.20962, 0.14527, 926.96%
Time spent: 6.15s
- Epoch 037, ExpID 3107
Train - Loss (one batch): 0.04541
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04822, 0.04822, 0.21959, 0.14884, 885.09%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.04394, 0.04394, 0.20962, 0.14527, 926.96%
Time spent: 6.49s
- Epoch 038, ExpID 3107
Train - Loss (one batch): 0.04473
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04570, 0.04570, 0.21378, 0.14809, 875.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 27, 0.04394, 0.04394, 0.20962, 0.14527, 926.96%
Time spent: 6.37s
- Epoch 039, ExpID 3107
Train - Loss (one batch): 0.04003
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04447, 0.04447, 0.21087, 0.14648, 862.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 39, 0.04345, 0.04345, 0.20844, 0.14487, 895.53%
Time spent: 7.39s
- Epoch 040, ExpID 3107
Train - Loss (one batch): 0.04644
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04465, 0.04465, 0.21131, 0.14361, 819.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 39, 0.04345, 0.04345, 0.20844, 0.14487, 895.53%
Time spent: 5.98s
- Epoch 041, ExpID 3107
Train - Loss (one batch): 0.04243
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04919, 0.04919, 0.22180, 0.14777, 769.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 39, 0.04345, 0.04345, 0.20844, 0.14487, 895.53%
Time spent: 5.49s
- Epoch 042, ExpID 3107
Train - Loss (one batch): 0.04402
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04646, 0.04646, 0.21555, 0.14673, 864.18%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 39, 0.04345, 0.04345, 0.20844, 0.14487, 895.53%
Time spent: 5.79s
- Epoch 043, ExpID 3107
Train - Loss (one batch): 0.04821
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04611, 0.04611, 0.21474, 0.14564, 817.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 39, 0.04345, 0.04345, 0.20844, 0.14487, 895.53%
Time spent: 6.35s
- Epoch 044, ExpID 3107
Train - Loss (one batch): 0.04210
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04397, 0.04397, 0.20968, 0.14282, 758.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 44, 0.04270, 0.04270, 0.20665, 0.14064, 787.07%
Time spent: 6.58s
- Epoch 045, ExpID 3107
Train - Loss (one batch): 0.05073
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04460, 0.04460, 0.21118, 0.14562, 800.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 44, 0.04270, 0.04270, 0.20665, 0.14064, 787.07%
Time spent: 6.92s
- Epoch 046, ExpID 3107
Train - Loss (one batch): 0.04347
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04355, 0.04355, 0.20867, 0.14470, 837.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 46, 0.04220, 0.04220, 0.20543, 0.14253, 863.28%
Time spent: 7.27s
- Epoch 047, ExpID 3107
Train - Loss (one batch): 0.03736
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04771, 0.04771, 0.21844, 0.14729, 858.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 46, 0.04220, 0.04220, 0.20543, 0.14253, 863.28%
Time spent: 6.98s
- Epoch 048, ExpID 3107
Train - Loss (one batch): 0.04704
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04971, 0.04971, 0.22295, 0.14892, 902.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 46, 0.04220, 0.04220, 0.20543, 0.14253, 863.28%
Time spent: 6.32s
- Epoch 049, ExpID 3107
Train - Loss (one batch): 0.03995
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04430, 0.04430, 0.21049, 0.14407, 994.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 46, 0.04220, 0.04220, 0.20543, 0.14253, 863.28%
Time spent: 5.94s
- Epoch 050, ExpID 3107
Train - Loss (one batch): 0.04144
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04931, 0.04931, 0.22205, 0.14859, 809.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 46, 0.04220, 0.04220, 0.20543, 0.14253, 863.28%
Time spent: 5.86s
- Epoch 051, ExpID 3107
Train - Loss (one batch): 0.04146
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04372, 0.04372, 0.20908, 0.14368, 844.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 46, 0.04220, 0.04220, 0.20543, 0.14253, 863.28%
Time spent: 6.66s
- Epoch 052, ExpID 3107
Train - Loss (one batch): 0.03786
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04438, 0.04438, 0.21067, 0.14397, 836.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 46, 0.04220, 0.04220, 0.20543, 0.14253, 863.28%
Time spent: 6.84s
- Epoch 053, ExpID 3107
Train - Loss (one batch): 0.04666
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04705, 0.04705, 0.21690, 0.14557, 841.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 46, 0.04220, 0.04220, 0.20543, 0.14253, 863.28%
Time spent: 6.18s
- Epoch 054, ExpID 3107
Train - Loss (one batch): 0.04505
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04592, 0.04592, 0.21429, 0.14466, 849.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 46, 0.04220, 0.04220, 0.20543, 0.14253, 863.28%
Time spent: 5.20s
- Epoch 055, ExpID 3107
Train - Loss (one batch): 0.03912
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04352, 0.04352, 0.20861, 0.14335, 875.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 55, 0.04298, 0.04298, 0.20731, 0.14213, 921.20%
Time spent: 6.03s
- Epoch 056, ExpID 3107
Train - Loss (one batch): 0.04859
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04461, 0.04461, 0.21122, 0.14309, 836.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 55, 0.04298, 0.04298, 0.20731, 0.14213, 921.20%
Time spent: 5.32s
- Epoch 057, ExpID 3107
Train - Loss (one batch): 0.04366
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04449, 0.04449, 0.21091, 0.14470, 870.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 55, 0.04298, 0.04298, 0.20731, 0.14213, 921.20%
Time spent: 5.41s
- Epoch 058, ExpID 3107
Train - Loss (one batch): 0.04621
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05096, 0.05096, 0.22574, 0.15006, 811.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 55, 0.04298, 0.04298, 0.20731, 0.14213, 921.20%
Time spent: 6.76s
- Epoch 059, ExpID 3107
Train - Loss (one batch): 0.04480
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04519, 0.04519, 0.21258, 0.14415, 814.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 55, 0.04298, 0.04298, 0.20731, 0.14213, 921.20%
Time spent: 6.66s
- Epoch 060, ExpID 3107
Train - Loss (one batch): 0.04642
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04561, 0.04561, 0.21357, 0.14430, 811.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 55, 0.04298, 0.04298, 0.20731, 0.14213, 921.20%
Time spent: 6.95s
- Epoch 061, ExpID 3107
Train - Loss (one batch): 0.04175
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04488, 0.04488, 0.21186, 0.14198, 833.74%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 55, 0.04298, 0.04298, 0.20731, 0.14213, 921.20%
Time spent: 6.94s
- Epoch 062, ExpID 3107
Train - Loss (one batch): 0.04371
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04367, 0.04367, 0.20897, 0.13953, 702.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 55, 0.04298, 0.04298, 0.20731, 0.14213, 921.20%
Time spent: 6.45s
- Epoch 063, ExpID 3107
Train - Loss (one batch): 0.04871
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04961, 0.04961, 0.22273, 0.14873, 855.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 55, 0.04298, 0.04298, 0.20731, 0.14213, 921.20%
Time spent: 6.92s
- Epoch 064, ExpID 3107
Train - Loss (one batch): 0.04005
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04528, 0.04528, 0.21280, 0.14556, 797.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 55, 0.04298, 0.04298, 0.20731, 0.14213, 921.20%
Time spent: 6.30s
- Epoch 065, ExpID 3107
Train - Loss (one batch): 0.04250
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04728, 0.04728, 0.21743, 0.14633, 839.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 55, 0.04298, 0.04298, 0.20731, 0.14213, 921.20%
Time spent: 6.89s
- Epoch 066, ExpID 3107
Train - Loss (one batch): 0.04112
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04390, 0.04390, 0.20953, 0.14312, 784.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 55, 0.04298, 0.04298, 0.20731, 0.14213, 921.20%
Time spent: 6.65s
- Epoch 067, ExpID 3107
Train - Loss (one batch): 0.04036
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04757, 0.04757, 0.21811, 0.14694, 794.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 55, 0.04298, 0.04298, 0.20731, 0.14213, 921.20%
Time spent: 6.29s
- Epoch 068, ExpID 3107
Train - Loss (one batch): 0.03929
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04746, 0.04746, 0.21786, 0.14541, 797.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 55, 0.04298, 0.04298, 0.20731, 0.14213, 921.20%
Time spent: 7.00s
- Epoch 069, ExpID 3107
Train - Loss (one batch): 0.03902
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04496, 0.04496, 0.21203, 0.14492, 891.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 55, 0.04298, 0.04298, 0.20731, 0.14213, 921.20%
Time spent: 6.23s
- Epoch 070, ExpID 3107
Train - Loss (one batch): 0.04177
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04540, 0.04540, 0.21308, 0.14688, 925.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 55, 0.04298, 0.04298, 0.20731, 0.14213, 921.20%
Time spent: 6.21s
- Epoch 071, ExpID 3107
Train - Loss (one batch): 0.03942
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04337, 0.04337, 0.20824, 0.14223, 770.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 71, 0.04262, 0.04262, 0.20646, 0.14051, 809.11%
Time spent: 7.16s
- Epoch 072, ExpID 3107
Train - Loss (one batch): 0.03500
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04230, 0.04230, 0.20568, 0.14135, 820.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.04162, 0.04162, 0.20400, 0.13951, 835.16%
Time spent: 7.68s
- Epoch 073, ExpID 3107
Train - Loss (one batch): 0.03838
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04441, 0.04441, 0.21074, 0.14372, 836.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.04162, 0.04162, 0.20400, 0.13951, 835.16%
Time spent: 6.87s
- Epoch 074, ExpID 3107
Train - Loss (one batch): 0.03645
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04536, 0.04536, 0.21299, 0.14399, 822.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.04162, 0.04162, 0.20400, 0.13951, 835.16%
Time spent: 6.63s
- Epoch 075, ExpID 3107
Train - Loss (one batch): 0.04493
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04484, 0.04484, 0.21176, 0.14358, 876.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 72, 0.04162, 0.04162, 0.20400, 0.13951, 835.16%
Time spent: 7.34s
- Epoch 076, ExpID 3107
Train - Loss (one batch): 0.05191
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04139, 0.04139, 0.20345, 0.14125, 914.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 7.46s
- Epoch 077, ExpID 3107
Train - Loss (one batch): 0.04440
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04496, 0.04496, 0.21204, 0.14398, 817.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 6.35s
- Epoch 078, ExpID 3107
Train - Loss (one batch): 0.04163
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04478, 0.04478, 0.21161, 0.14252, 831.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 5.23s
- Epoch 079, ExpID 3107
Train - Loss (one batch): 0.04415
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04543, 0.04543, 0.21315, 0.14329, 823.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 5.40s
- Epoch 080, ExpID 3107
Train - Loss (one batch): 0.03469
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04214, 0.04214, 0.20527, 0.14249, 883.57%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 5.65s
- Epoch 081, ExpID 3107
Train - Loss (one batch): 0.03788
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04802, 0.04802, 0.21914, 0.14462, 797.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 5.53s
- Epoch 082, ExpID 3107
Train - Loss (one batch): 0.04899
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05074, 0.05074, 0.22525, 0.15038, 925.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 5.53s
- Epoch 083, ExpID 3107
Train - Loss (one batch): 0.04104
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04481, 0.04481, 0.21169, 0.14237, 885.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 5.53s
- Epoch 084, ExpID 3107
Train - Loss (one batch): 0.04076
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05358, 0.05358, 0.23147, 0.15264, 869.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 5.52s
- Epoch 085, ExpID 3107
Train - Loss (one batch): 0.05003
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05043, 0.05043, 0.22456, 0.14839, 824.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 5.53s
- Epoch 086, ExpID 3107
Train - Loss (one batch): 0.04473
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04195, 0.04195, 0.20481, 0.14060, 813.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 5.55s
- Epoch 087, ExpID 3107
Train - Loss (one batch): 0.04021
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05159, 0.05159, 0.22713, 0.14949, 739.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 6.24s
- Epoch 088, ExpID 3107
Train - Loss (one batch): 0.04828
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04399, 0.04399, 0.20973, 0.14449, 879.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 6.42s
- Epoch 089, ExpID 3107
Train - Loss (one batch): 0.03801
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04560, 0.04560, 0.21355, 0.14405, 792.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 6.30s
- Epoch 090, ExpID 3107
Train - Loss (one batch): 0.03896
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05008, 0.05008, 0.22378, 0.14931, 824.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 6.63s
- Epoch 091, ExpID 3107
Train - Loss (one batch): 0.03622
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04534, 0.04534, 0.21292, 0.14270, 848.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 6.56s
- Epoch 092, ExpID 3107
Train - Loss (one batch): 0.04567
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05117, 0.05117, 0.22620, 0.14824, 777.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 5.40s
- Epoch 093, ExpID 3107
Train - Loss (one batch): 0.03947
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04840, 0.04840, 0.22000, 0.14607, 862.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 5.21s
- Epoch 094, ExpID 3107
Train - Loss (one batch): 0.04562
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04396, 0.04396, 0.20968, 0.13947, 834.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 5.23s
- Epoch 095, ExpID 3107
Train - Loss (one batch): 0.03647
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04547, 0.04547, 0.21324, 0.14490, 908.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 5.20s
- Epoch 096, ExpID 3107
Train - Loss (one batch): 0.04306
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04649, 0.04649, 0.21561, 0.14403, 823.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 6.01s
- Epoch 097, ExpID 3107
Train - Loss (one batch): 0.04272
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04245, 0.04245, 0.20604, 0.14115, 836.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 6.59s
- Epoch 098, ExpID 3107
Train - Loss (one batch): 0.03913
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04796, 0.04796, 0.21900, 0.14726, 862.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 6.88s
- Epoch 099, ExpID 3107
Train - Loss (one batch): 0.04081
Val - Loss, MSE, RMSE, MAE, MAPE: 0.04545, 0.04545, 0.21319, 0.14219, 870.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 76, 0.04067, 0.04067, 0.20166, 0.13987, 958.25%
Time spent: 7.00s
True
Couldn't import umap
PID, device: 1809119 cuda:0
Total records: 12000
Dataset n_samples: 12000 7200 2400 2400
Test record ids (first 20): ['141035', '147605', '135375', '161896', '139505', '162915', '146059', '161471', '137723', '146625', '137197', '133811', '142577', '138349', '145848', '156467', '139420', '145445', '141972', '132617']
Test record ids (last 20): ['151541', '135141', '148664', '151895', '137025', '143410', '132799', '160417', '143342', '157915', '143290', '141428', '147807', '145320', '146007', '136354', '153098', '148397', '138869', '145810']
data_max: tensor([9.0000e+01, 1.0000e+00, 4.6230e+02, 4.0000e+00, 3.0000e+02, 5.3000e+00,
        4.6950e+03, 1.6920e+04, 2.3950e+04, 6.2100e+01, 2.0900e+02, 3.6000e+02,
        2.2000e+01, 2.8300e+02, 1.0000e+00, 1.5000e+01, 1.5910e+03, 5.2000e+01,
        6.1800e+01, 3.0000e+02, 1.9600e+01, 3.1000e+01, 3.7500e+01, 3.0000e+02,
        1.0000e+00, 1.8000e+02, 2.1100e+02, 2.2800e+02, 3.0000e+02, 1.0000e+02,
        5.0000e+02, 7.3300e+02, 2.2920e+03, 1.0000e+02, 1.0000e+02, 2.9500e+02,
        4.2200e+01, 4.9600e+01, 2.9910e+01, 1.1000e+04, 6.2519e+03],
       device='cuda:0')
data_min: tensor([ 1.5000e+01, -1.0000e+00, -1.0000e+00,  1.0000e+00, -1.0000e+00,
         1.0000e+00,  8.0000e+00,  1.0000e+00,  4.0000e+00,  0.0000e+00,
         0.0000e+00,  2.8000e+01,  1.0000e-01, -1.0000e+00,  2.1000e-01,
         3.0000e+00,  8.0000e+00,  5.0000e+00,  5.5000e+00,  0.0000e+00,
         1.5000e+00,  3.0000e-01,  6.0000e-01,  0.0000e+00,  1.0000e+00,
         9.9000e+01, -1.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00,  0.0000e+00,  5.0000e+00,  0.0000e+00,  0.0000e+00,
         0.0000e+00, -1.7800e+01,  1.0000e-01,  1.0000e-02,  0.0000e+00,
         1.0000e-01], device='cuda:0')
time_max: tensor(48., device='cuda:0')
model Model(
  (patch_embedding): PatchEmbedding(
    (padding_patch_layer): ReplicationPad1d((0, 8))
    (value_embedding): Linear(in_features=16, out_features=64, bias=False)
    (position_embedding): PositionalEmbedding()
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): Encoder(
    (attn_layers): ModuleList(
      (0-1): 2 x EncoderLayer(
        (attention): AttentionLayer(
          (inner_attention): FullAttention(
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (query_projection): Linear(in_features=64, out_features=64, bias=True)
          (key_projection): Linear(in_features=64, out_features=64, bias=True)
          (value_projection): Linear(in_features=64, out_features=64, bias=True)
          (out_projection): Linear(in_features=64, out_features=64, bias=True)
        )
        (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): Sequential(
      (0): Transpose()
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Transpose()
    )
  )
  (te_scale): Linear(in_features=1, out_features=1, bias=True)
  (te_periodic): Linear(in_features=1, out_features=63, bias=True)
  (decoder): Sequential(
    (0): Linear(in_features=128, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=1, bias=True)
  )
)
parameters: 64193
n_train_batches: 225
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_baselines.py
2024-07-19 11:33:05
run_baselines.py --history 24 --model PatchTST --dataset mimic
Namespace(state='def', n=100000000, epoch=100, patience=10, history=24, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='mimic', quantization=0.0, model='PatchTST', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=8, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='0', seq_len=280, top_k=5, num_kernels=64, npatch=1, device=device(type='cuda', index=0), PID=1816613, pred_window=24, ndim=96, patch_layer=1, task_name='long_term_forecast', label_len=48, pred_len=96, patch_len=16, d_model=64, dropout=0.1, output_attention=None, n_heads=1, d_ff=64, activation='gelu', e_layers=2, factor=3, enc_in=321)
- Epoch 000, ExpID 52171
Train - Loss (one batch): 0.05954
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06688, 0.06688, 0.25861, 0.20610, 838.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07137, 0.07137, 0.26716, 0.20938, 771.99%
Time spent: 31.14s
- Epoch 001, ExpID 52171
Train - Loss (one batch): 0.05762
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06062, 0.06062, 0.24622, 0.18580, 631.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.06530, 0.06530, 0.25554, 0.18956, 582.03%
Time spent: 30.60s
- Epoch 002, ExpID 52171
Train - Loss (one batch): 0.06440
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06010, 0.06010, 0.24515, 0.18267, 547.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.06488, 0.06488, 0.25472, 0.18675, 494.62%
Time spent: 30.57s
- Epoch 003, ExpID 52171
Train - Loss (one batch): 0.05775
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06957, 0.06957, 0.26376, 0.18403, 362.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.06488, 0.06488, 0.25472, 0.18675, 494.62%
Time spent: 26.80s
- Epoch 004, ExpID 52171
Train - Loss (one batch): 0.05314
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06262, 0.06262, 0.25024, 0.18541, 601.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.06488, 0.06488, 0.25472, 0.18675, 494.62%
Time spent: 26.67s
- Epoch 005, ExpID 52171
Train - Loss (one batch): 0.05074
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06909, 0.06909, 0.26286, 0.17873, 320.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.06488, 0.06488, 0.25472, 0.18675, 494.62%
Time spent: 26.92s
- Epoch 006, ExpID 52171
Train - Loss (one batch): 0.05796
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06469, 0.06469, 0.25434, 0.18321, 481.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.06488, 0.06488, 0.25472, 0.18675, 494.62%
Time spent: 26.87s
- Epoch 007, ExpID 52171
Train - Loss (one batch): 0.05367
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05980, 0.05980, 0.24455, 0.18036, 534.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.06529, 0.06529, 0.25552, 0.18491, 496.44%
Time spent: 30.53s
- Epoch 008, ExpID 52171
Train - Loss (one batch): 0.04742
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06717, 0.06717, 0.25918, 0.18728, 526.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.06529, 0.06529, 0.25552, 0.18491, 496.44%
Time spent: 26.74s
- Epoch 009, ExpID 52171
Train - Loss (one batch): 0.07581
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06524, 0.06524, 0.25542, 0.18019, 402.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.06529, 0.06529, 0.25552, 0.18491, 496.44%
Time spent: 26.68s
- Epoch 010, ExpID 52171
Train - Loss (one batch): 0.05829
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06042, 0.06042, 0.24580, 0.18157, 554.03%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.06529, 0.06529, 0.25552, 0.18491, 496.44%
Time spent: 26.52s
- Epoch 011, ExpID 52171
Train - Loss (one batch): 0.05613
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06645, 0.06645, 0.25778, 0.18472, 476.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.06529, 0.06529, 0.25552, 0.18491, 496.44%
Time spent: 26.70s
- Epoch 012, ExpID 52171
Train - Loss (one batch): 0.05960
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06584, 0.06584, 0.25659, 0.18452, 492.74%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.06529, 0.06529, 0.25552, 0.18491, 496.44%
Time spent: 26.56s
- Epoch 013, ExpID 52171
Train - Loss (one batch): 0.07100
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05892, 0.05892, 0.24274, 0.18000, 509.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 30.32s
- Epoch 014, ExpID 52171
Train - Loss (one batch): 0.04505
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06642, 0.06642, 0.25773, 0.18638, 523.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 26.65s
- Epoch 015, ExpID 52171
Train - Loss (one batch): 0.05841
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06028, 0.06028, 0.24552, 0.17407, 401.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 26.76s
- Epoch 016, ExpID 52171
Train - Loss (one batch): 0.06130
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06419, 0.06419, 0.25336, 0.17837, 388.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 26.79s
- Epoch 017, ExpID 52171
Train - Loss (one batch): 0.08024
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07292, 0.07292, 0.27004, 0.19330, 468.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 26.70s
- Epoch 018, ExpID 52171
Train - Loss (one batch): 0.05434
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06461, 0.06461, 0.25418, 0.18176, 409.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 26.79s
- Epoch 019, ExpID 52171
Train - Loss (one batch): 0.06502
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06810, 0.06810, 0.26097, 0.18573, 530.02%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 26.90s
- Epoch 020, ExpID 52171
Train - Loss (one batch): 0.05099
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06689, 0.06689, 0.25864, 0.18482, 444.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 26.80s
- Epoch 021, ExpID 52171
Train - Loss (one batch): 0.05639
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06365, 0.06365, 0.25228, 0.18240, 523.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 26.86s
- Epoch 022, ExpID 52171
Train - Loss (one batch): 0.06235
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06473, 0.06473, 0.25443, 0.18516, 508.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 26.83s
- Epoch 023, ExpID 52171
Train - Loss (one batch): 0.06901
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06358, 0.06358, 0.25216, 0.18092, 483.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 26.70s
- Epoch 024, ExpID 52171
Train - Loss (one batch): 0.05806
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06254, 0.06254, 0.25009, 0.18147, 459.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.06355, 0.06355, 0.25210, 0.18392, 459.98%
Time spent: 26.79s
- Epoch 025, ExpID 52171
Train - Loss (one batch): 0.05409
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05691, 0.05691, 0.23855, 0.17278, 433.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 30.60s
- Epoch 026, ExpID 52171
Train - Loss (one batch): 0.05728
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07110, 0.07110, 0.26665, 0.19044, 457.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.70s
- Epoch 027, ExpID 52171
Train - Loss (one batch): 0.05246
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06433, 0.06433, 0.25364, 0.18002, 461.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.84s
- Epoch 028, ExpID 52171
Train - Loss (one batch): 0.06580
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06631, 0.06631, 0.25751, 0.18268, 438.30%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.76s
- Epoch 029, ExpID 52171
Train - Loss (one batch): 0.05533
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06566, 0.06566, 0.25624, 0.18470, 464.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.57s
- Epoch 030, ExpID 52171
Train - Loss (one batch): 0.05791
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06586, 0.06586, 0.25663, 0.18353, 429.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.74s
- Epoch 031, ExpID 52171
Train - Loss (one batch): 0.05938
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06176, 0.06176, 0.24852, 0.17981, 450.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.84s
- Epoch 032, ExpID 52171
Train - Loss (one batch): 0.06691
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06602, 0.06602, 0.25694, 0.18440, 446.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.65s
- Epoch 033, ExpID 52171
Train - Loss (one batch): 0.05785
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06313, 0.06313, 0.25127, 0.18154, 477.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.61s
- Epoch 034, ExpID 52171
Train - Loss (one batch): 0.06269
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07152, 0.07152, 0.26743, 0.19238, 455.62%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.58s
- Epoch 035, ExpID 52171
Train - Loss (one batch): 0.04843
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07760, 0.07760, 0.27857, 0.19712, 408.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.80s
- Epoch 036, ExpID 52171
Train - Loss (one batch): 0.05906
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07289, 0.07289, 0.26997, 0.19130, 449.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.74s
- Epoch 037, ExpID 52171
Train - Loss (one batch): 0.05096
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07064, 0.07064, 0.26578, 0.18666, 430.43%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.75s
- Epoch 038, ExpID 52171
Train - Loss (one batch): 0.04780
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06553, 0.06553, 0.25599, 0.18448, 496.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.75s
- Epoch 039, ExpID 52171
Train - Loss (one batch): 0.05301
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06646, 0.06646, 0.25781, 0.18307, 429.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.90s
- Epoch 040, ExpID 52171
Train - Loss (one batch): 0.05280
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07166, 0.07166, 0.26769, 0.18706, 381.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.85s
- Epoch 041, ExpID 52171
Train - Loss (one batch): 0.05824
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07449, 0.07449, 0.27292, 0.19305, 436.09%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.83s
- Epoch 042, ExpID 52171
Train - Loss (one batch): 0.05728
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07619, 0.07619, 0.27602, 0.19474, 421.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.57s
- Epoch 043, ExpID 52171
Train - Loss (one batch): 0.05905
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06646, 0.06646, 0.25779, 0.18428, 433.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.50s
- Epoch 044, ExpID 52171
Train - Loss (one batch): 0.06824
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06684, 0.06684, 0.25853, 0.18527, 477.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.61s
- Epoch 045, ExpID 52171
Train - Loss (one batch): 0.05941
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07407, 0.07407, 0.27215, 0.19475, 445.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.66s
- Epoch 046, ExpID 52171
Train - Loss (one batch): 0.05059
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07008, 0.07008, 0.26472, 0.18999, 518.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.72s
- Epoch 047, ExpID 52171
Train - Loss (one batch): 0.05329
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06723, 0.06723, 0.25929, 0.18173, 430.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.63s
- Epoch 048, ExpID 52171
Train - Loss (one batch): 0.05501
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07446, 0.07446, 0.27288, 0.19367, 459.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.52s
- Epoch 049, ExpID 52171
Train - Loss (one batch): 0.05354
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06719, 0.06719, 0.25920, 0.18589, 494.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.77s
- Epoch 050, ExpID 52171
Train - Loss (one batch): 0.05783
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06369, 0.06369, 0.25237, 0.17867, 421.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.65s
- Epoch 051, ExpID 52171
Train - Loss (one batch): 0.04322
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07535, 0.07535, 0.27451, 0.19229, 368.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.68s
- Epoch 052, ExpID 52171
Train - Loss (one batch): 0.06436
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06581, 0.06581, 0.25653, 0.17985, 381.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.75s
- Epoch 053, ExpID 52171
Train - Loss (one batch): 0.05101
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07948, 0.07948, 0.28192, 0.19954, 438.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.59s
- Epoch 054, ExpID 52171
Train - Loss (one batch): 0.06559
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06612, 0.06612, 0.25714, 0.18516, 458.09%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.62s
- Epoch 055, ExpID 52171
Train - Loss (one batch): 0.05119
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07901, 0.07901, 0.28108, 0.19825, 402.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.50s
- Epoch 056, ExpID 52171
Train - Loss (one batch): 0.05599
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06736, 0.06736, 0.25954, 0.18479, 432.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.76s
- Epoch 057, ExpID 52171
Train - Loss (one batch): 0.05126
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06349, 0.06349, 0.25197, 0.18050, 510.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.67s
- Epoch 058, ExpID 52171
Train - Loss (one batch): 0.06088
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07000, 0.07000, 0.26458, 0.18849, 443.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.83s
- Epoch 059, ExpID 52171
Train - Loss (one batch): 0.05532
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06570, 0.06570, 0.25631, 0.18163, 445.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.67s
- Epoch 060, ExpID 52171
Train - Loss (one batch): 0.04378
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07023, 0.07023, 0.26501, 0.18715, 440.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.70s
- Epoch 061, ExpID 52171
Train - Loss (one batch): 0.06052
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07327, 0.07327, 0.27069, 0.19180, 427.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.77s
- Epoch 062, ExpID 52171
Train - Loss (one batch): 0.05813
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07509, 0.07509, 0.27403, 0.19464, 506.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.86s
- Epoch 063, ExpID 52171
Train - Loss (one batch): 0.05643
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07525, 0.07525, 0.27431, 0.19356, 430.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.88s
- Epoch 064, ExpID 52171
Train - Loss (one batch): 0.04769
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06681, 0.06681, 0.25847, 0.18354, 473.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.83s
- Epoch 065, ExpID 52171
Train - Loss (one batch): 0.05969
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06817, 0.06817, 0.26109, 0.18637, 451.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.83s
- Epoch 066, ExpID 52171
Train - Loss (one batch): 0.06095
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07098, 0.07098, 0.26642, 0.18917, 425.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.88s
- Epoch 067, ExpID 52171
Train - Loss (one batch): 0.06390
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06909, 0.06909, 0.26284, 0.18631, 454.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.73s
- Epoch 068, ExpID 52171
Train - Loss (one batch): 0.07276
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07137, 0.07137, 0.26715, 0.19007, 441.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.91s
- Epoch 069, ExpID 52171
Train - Loss (one batch): 0.06222
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07728, 0.07728, 0.27800, 0.19645, 439.43%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.74s
- Epoch 070, ExpID 52171
Train - Loss (one batch): 0.05183
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06118, 0.06118, 0.24735, 0.17818, 451.99%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.68s
- Epoch 071, ExpID 52171
Train - Loss (one batch): 0.05735
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07187, 0.07187, 0.26809, 0.19212, 506.18%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.52s
- Epoch 072, ExpID 52171
Train - Loss (one batch): 0.04974
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06616, 0.06616, 0.25721, 0.18292, 436.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.78s
- Epoch 073, ExpID 52171
Train - Loss (one batch): 0.05988
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06558, 0.06558, 0.25609, 0.18503, 492.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.82s
- Epoch 074, ExpID 52171
Train - Loss (one batch): 0.05534
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06568, 0.06568, 0.25627, 0.18462, 476.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.84s
- Epoch 075, ExpID 52171
Train - Loss (one batch): 0.05370
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07772, 0.07772, 0.27878, 0.19664, 420.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.87s
- Epoch 076, ExpID 52171
Train - Loss (one batch): 0.05334
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06443, 0.06443, 0.25383, 0.18022, 431.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.87s
- Epoch 077, ExpID 52171
Train - Loss (one batch): 0.04616
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06807, 0.06807, 0.26090, 0.18524, 480.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.76s
- Epoch 078, ExpID 52171
Train - Loss (one batch): 0.05548
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07414, 0.07414, 0.27228, 0.19174, 405.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.79s
- Epoch 079, ExpID 52171
Train - Loss (one batch): 0.06853
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07043, 0.07043, 0.26539, 0.18847, 462.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.92s
- Epoch 080, ExpID 52171
Train - Loss (one batch): 0.05832
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05935, 0.05935, 0.24362, 0.17514, 525.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.86s
- Epoch 081, ExpID 52171
Train - Loss (one batch): 0.05791
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06352, 0.06352, 0.25203, 0.17971, 450.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.82s
- Epoch 082, ExpID 52171
Train - Loss (one batch): 0.04314
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07049, 0.07049, 0.26550, 0.18758, 433.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.90s
- Epoch 083, ExpID 52171
Train - Loss (one batch): 0.06227
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05741, 0.05741, 0.23960, 0.17434, 523.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.83s
- Epoch 084, ExpID 52171
Train - Loss (one batch): 0.06032
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07075, 0.07075, 0.26599, 0.18787, 434.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.79s
- Epoch 085, ExpID 52171
Train - Loss (one batch): 0.05246
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07263, 0.07263, 0.26949, 0.19166, 434.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.77s
- Epoch 086, ExpID 52171
Train - Loss (one batch): 0.05567
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06743, 0.06743, 0.25966, 0.18328, 457.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.82s
- Epoch 087, ExpID 52171
Train - Loss (one batch): 0.04889
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06582, 0.06582, 0.25656, 0.17972, 399.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.86s
- Epoch 088, ExpID 52171
Train - Loss (one batch): 0.06828
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06576, 0.06576, 0.25644, 0.18364, 488.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.77s
- Epoch 089, ExpID 52171
Train - Loss (one batch): 0.05127
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07920, 0.07920, 0.28142, 0.19844, 436.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 27.05s
- Epoch 090, ExpID 52171
Train - Loss (one batch): 0.05450
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07006, 0.07006, 0.26469, 0.18795, 449.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.82s
- Epoch 091, ExpID 52171
Train - Loss (one batch): 0.05408
Val - Loss, MSE, RMSE, MAE, MAPE: 0.08422, 0.08422, 0.29020, 0.20661, 452.99%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.69s
- Epoch 092, ExpID 52171
Train - Loss (one batch): 0.04821
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06495, 0.06495, 0.25485, 0.18042, 432.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.60s
- Epoch 093, ExpID 52171
Train - Loss (one batch): 0.06708
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06531, 0.06531, 0.25556, 0.18132, 441.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.80s
- Epoch 094, ExpID 52171
Train - Loss (one batch): 0.04805
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06998, 0.06998, 0.26454, 0.18414, 371.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.59s
- Epoch 095, ExpID 52171
Train - Loss (one batch): 0.05035
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07547, 0.07547, 0.27471, 0.19360, 437.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.77s
- Epoch 096, ExpID 52171
Train - Loss (one batch): 0.06174
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06517, 0.06517, 0.25528, 0.18300, 466.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.84s
- Epoch 097, ExpID 52171
Train - Loss (one batch): 0.04107
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07900, 0.07900, 0.28107, 0.19539, 375.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.75s
- Epoch 098, ExpID 52171
Train - Loss (one batch): 0.05678
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06741, 0.06741, 0.25964, 0.18336, 433.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.60s
- Epoch 099, ExpID 52171
Train - Loss (one batch): 0.05363
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06935, 0.06935, 0.26335, 0.18586, 416.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 25, 0.06288, 0.06288, 0.25076, 0.17741, 394.79%
Time spent: 26.73s
True
Couldn't import umap
PID, device: 1816613 cuda:0
Total records: 23457
Dataset n_samples: 23457 14073 4692 4692
Test record ids (first 20): [20539, 3274, 10159, 3501, 7505, 21021, 12964, 12250, 9303, 13430, 247, 8922, 3778, 6354, 9236, 17756, 21529, 17436, 10901, 19808]
Test record ids (last 20): [5183, 5610, 19849, 20653, 16941, 20849, 22721, 18864, 6285, 23347, 42, 14912, 3570, 22992, 17801, 4049, 5466, 795, 396, 18120]
data_max: tensor([5.6000e+01, 5.0000e+01, 2.3300e+01, 1.5500e+02, 2.7800e+01, 2.3400e+03,
        3.7500e+01, 3.2800e+01, 1.5600e+01, 1.8200e+02, 4.0240e+03, 3.6400e+04,
        8.2800e+01, 2.8000e+02, 4.0000e+01, 5.1000e+01, 7.0600e+01, 2.2300e+01,
        1.0000e+02, 4.8000e+01, 3.9800e+01, 1.3900e+02, 1.0000e+02, 9.9000e+01,
        2.2920e+03, 2.9700e+01, 8.4400e+00, 6.0020e+02, 1.6260e+02, 3.1000e+01,
        1.5000e+02, 1.5030e+04, 9.0000e+00, 1.0800e+00, 1.0000e+01, 5.0000e+00,
        2.0000e+01, 2.0000e+00, 1.6667e+01, 1.1000e+04, 4.2000e+01, 2.5000e+03,
        9.2967e+01, 9.0000e+02, 1.8750e+02, 5.3333e+01, 5.0000e+01, 1.5571e+01,
        2.9000e+01, 6.5000e+01, 1.7400e+02, 7.7500e+02, 6.3000e+00, 3.1000e+03,
        2.7000e+02, 6.5000e+02, 9.0000e+01, 1.0000e+02, 3.7500e+02, 1.6390e+01,
        2.5000e+00, 2.5000e+01, 2.9000e+01, 1.0000e+02, 4.0000e+01, 5.2000e+02,
        6.0000e+01, 1.2500e+01, 1.5000e+02, 1.0000e+03, 4.8000e+03, 6.2500e+01,
        4.5000e+02, 3.0000e+02, 2.6000e+01, 2.5000e+02, 3.7000e+03, 1.0000e+02,
        4.0000e+01, 8.0000e+00, 1.0000e+03, 1.5000e+03, 3.0000e+01, 5.0000e+03,
        2.8000e+02, 2.7041e+03, 1.0500e+03, 5.0000e+00, 2.0640e+00, 1.4286e+02,
        5.0000e+02, 7.0000e+02, 1.0200e+03, 6.0000e+02, 1.5000e+03, 2.5000e+02],
       device='cuda:0')
data_min: tensor([2.0000e+00, 5.0000e+00, 1.8000e+00, 3.9000e+01, 0.0000e+00, 0.0000e+00,
        2.0000e-01, 0.0000e+00, 8.0000e-01, 8.2000e+01, 5.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e-01, 1.2500e+01, 1.0000e-01,
        8.2000e+00, 1.0000e+00, 1.0000e+00, 1.5000e-02, 3.0000e+00, 1.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3333e-01, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.0000e+00, 1.1000e+01, 1.0000e+00, 0.0000e+00,
        0.0000e+00, 8.1000e+01, 3.0000e+00, 1.0000e+02, 0.0000e+00, 0.0000e+00,
        3.3333e-02, 0.0000e+00, 8.3333e-01, 1.0000e+00, 5.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5000e+01, 0.0000e+00, 3.3333e-01,
        0.0000e+00, 1.0000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5000e+00,
        8.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e-02, 0.0000e+00, 0.0000e+00,
        4.1667e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
       device='cuda:0')
time_max: tensor(47.9833, device='cuda:0')
model Model(
  (patch_embedding): PatchEmbedding(
    (padding_patch_layer): ReplicationPad1d((0, 8))
    (value_embedding): Linear(in_features=16, out_features=64, bias=False)
    (position_embedding): PositionalEmbedding()
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): Encoder(
    (attn_layers): ModuleList(
      (0-1): 2 x EncoderLayer(
        (attention): AttentionLayer(
          (inner_attention): FullAttention(
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (query_projection): Linear(in_features=64, out_features=64, bias=True)
          (key_projection): Linear(in_features=64, out_features=64, bias=True)
          (value_projection): Linear(in_features=64, out_features=64, bias=True)
          (out_projection): Linear(in_features=64, out_features=64, bias=True)
        )
        (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): Sequential(
      (0): Transpose()
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Transpose()
    )
  )
  (te_scale): Linear(in_features=1, out_features=1, bias=True)
  (te_periodic): Linear(in_features=1, out_features=63, bias=True)
  (decoder): Sequential(
    (0): Linear(in_features=128, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=1, bias=True)
  )
)
parameters: 64193
n_train_batches: 440
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_baselines.py
2024-07-19 12:20:53
run_baselines.py --history 36 --model PatchTST --dataset mimic
Namespace(state='def', n=100000000, epoch=100, patience=10, history=36, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='mimic', quantization=0.0, model='PatchTST', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=8, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='0', seq_len=464, top_k=5, num_kernels=64, npatch=2, device=device(type='cuda', index=0), PID=1843178, pred_window=12, ndim=96, patch_layer=2, task_name='long_term_forecast', label_len=48, pred_len=96, patch_len=16, d_model=64, dropout=0.1, output_attention=None, n_heads=1, d_ff=64, activation='gelu', e_layers=2, factor=3, enc_in=321)
- Epoch 000, ExpID 25838
Train - Loss (one batch): 0.04583
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06463, 0.06463, 0.25422, 0.19428, 720.02%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.06889, 0.06889, 0.26247, 0.20107, 670.37%
Time spent: 32.68s
- Epoch 001, ExpID 25838
Train - Loss (one batch): 0.05349
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06038, 0.06038, 0.24572, 0.17541, 507.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.06438, 0.06438, 0.25373, 0.18191, 457.64%
Time spent: 32.05s
- Epoch 002, ExpID 25838
Train - Loss (one batch): 0.05286
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06281, 0.06281, 0.25062, 0.18651, 515.62%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.06438, 0.06438, 0.25373, 0.18191, 457.64%
Time spent: 28.31s
- Epoch 003, ExpID 25838
Train - Loss (one batch): 0.04386
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05734, 0.05734, 0.23946, 0.17968, 568.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.06026, 0.06026, 0.24548, 0.18570, 525.59%
Time spent: 32.02s
- Epoch 004, ExpID 25838
Train - Loss (one batch): 0.03979
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06668, 0.06668, 0.25822, 0.18108, 465.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.06026, 0.06026, 0.24548, 0.18570, 525.59%
Time spent: 28.07s
- Epoch 005, ExpID 25838
Train - Loss (one batch): 0.03642
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06705, 0.06705, 0.25893, 0.17516, 317.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.06026, 0.06026, 0.24548, 0.18570, 525.59%
Time spent: 28.34s
- Epoch 006, ExpID 25838
Train - Loss (one batch): 0.03539
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05495, 0.05495, 0.23442, 0.16728, 429.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.05789, 0.05789, 0.24061, 0.17368, 394.56%
Time spent: 32.06s
- Epoch 007, ExpID 25838
Train - Loss (one batch): 0.04721
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05952, 0.05952, 0.24398, 0.17041, 384.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.05789, 0.05789, 0.24061, 0.17368, 394.56%
Time spent: 28.38s
- Epoch 008, ExpID 25838
Train - Loss (one batch): 0.03811
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05893, 0.05893, 0.24275, 0.16531, 313.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.05789, 0.05789, 0.24061, 0.17368, 394.56%
Time spent: 28.34s
- Epoch 009, ExpID 25838
Train - Loss (one batch): 0.08757
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06555, 0.06555, 0.25603, 0.17259, 299.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.05789, 0.05789, 0.24061, 0.17368, 394.56%
Time spent: 28.27s
- Epoch 010, ExpID 25838
Train - Loss (one batch): 0.04883
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05779, 0.05779, 0.24040, 0.16838, 355.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.05789, 0.05789, 0.24061, 0.17368, 394.56%
Time spent: 28.12s
- Epoch 011, ExpID 25838
Train - Loss (one batch): 0.04105
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05517, 0.05517, 0.23488, 0.16428, 370.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.05789, 0.05789, 0.24061, 0.17368, 394.56%
Time spent: 28.09s
- Epoch 012, ExpID 25838
Train - Loss (one batch): 0.03596
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06830, 0.06830, 0.26134, 0.17281, 270.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.05789, 0.05789, 0.24061, 0.17368, 394.56%
Time spent: 28.06s
- Epoch 013, ExpID 25838
Train - Loss (one batch): 0.04362
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05508, 0.05508, 0.23470, 0.16849, 373.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.05789, 0.05789, 0.24061, 0.17368, 394.56%
Time spent: 28.10s
- Epoch 014, ExpID 25838
Train - Loss (one batch): 0.05004
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05723, 0.05723, 0.23923, 0.16451, 328.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.05789, 0.05789, 0.24061, 0.17368, 394.56%
Time spent: 28.13s
- Epoch 015, ExpID 25838
Train - Loss (one batch): 0.04499
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06121, 0.06121, 0.24741, 0.16910, 329.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.05789, 0.05789, 0.24061, 0.17368, 394.56%
Time spent: 28.15s
- Epoch 016, ExpID 25838
Train - Loss (one batch): 0.03899
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05675, 0.05675, 0.23822, 0.16357, 327.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.05789, 0.05789, 0.24061, 0.17368, 394.56%
Time spent: 28.12s
- Epoch 017, ExpID 25838
Train - Loss (one batch): 0.04038
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05483, 0.05483, 0.23417, 0.16089, 319.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 17, 0.05857, 0.05857, 0.24201, 0.16723, 304.48%
Time spent: 31.87s
- Epoch 018, ExpID 25838
Train - Loss (one batch): 0.04133
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05520, 0.05520, 0.23495, 0.16112, 364.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 17, 0.05857, 0.05857, 0.24201, 0.16723, 304.48%
Time spent: 28.20s
- Epoch 019, ExpID 25838
Train - Loss (one batch): 0.03843
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06376, 0.06376, 0.25252, 0.16721, 261.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 17, 0.05857, 0.05857, 0.24201, 0.16723, 304.48%
Time spent: 28.25s
- Epoch 020, ExpID 25838
Train - Loss (one batch): 0.03710
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05231, 0.05231, 0.22872, 0.16002, 364.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 31.92s
- Epoch 021, ExpID 25838
Train - Loss (one batch): 0.06633
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05924, 0.05924, 0.24338, 0.17058, 303.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.31s
- Epoch 022, ExpID 25838
Train - Loss (one batch): 0.04214
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05276, 0.05276, 0.22970, 0.16002, 382.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.22s
- Epoch 023, ExpID 25838
Train - Loss (one batch): 0.04179
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06466, 0.06466, 0.25428, 0.16763, 248.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.23s
- Epoch 024, ExpID 25838
Train - Loss (one batch): 0.04649
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05536, 0.05536, 0.23530, 0.15989, 308.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.17s
- Epoch 025, ExpID 25838
Train - Loss (one batch): 0.03770
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07622, 0.07622, 0.27608, 0.18898, 312.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.25s
- Epoch 026, ExpID 25838
Train - Loss (one batch): 0.04607
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07759, 0.07759, 0.27855, 0.19210, 326.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.18s
- Epoch 027, ExpID 25838
Train - Loss (one batch): 0.03886
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06329, 0.06329, 0.25157, 0.17486, 372.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.33s
- Epoch 028, ExpID 25838
Train - Loss (one batch): 0.05675
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06664, 0.06664, 0.25815, 0.17619, 322.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.30s
- Epoch 029, ExpID 25838
Train - Loss (one batch): 0.03346
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05425, 0.05425, 0.23292, 0.16143, 336.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.11s
- Epoch 030, ExpID 25838
Train - Loss (one batch): 0.03917
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06617, 0.06617, 0.25724, 0.17546, 324.09%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.37s
- Epoch 031, ExpID 25838
Train - Loss (one batch): 0.04760
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05826, 0.05826, 0.24136, 0.16770, 350.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.38s
- Epoch 032, ExpID 25838
Train - Loss (one batch): 0.04955
Val - Loss, MSE, RMSE, MAE, MAPE: 0.08345, 0.08345, 0.28888, 0.19188, 225.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.28s
- Epoch 033, ExpID 25838
Train - Loss (one batch): 0.05275
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06224, 0.06224, 0.24948, 0.17249, 364.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.22s
- Epoch 034, ExpID 25838
Train - Loss (one batch): 0.04741
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06535, 0.06535, 0.25564, 0.17562, 434.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.06s
- Epoch 035, ExpID 25838
Train - Loss (one batch): 0.04297
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06061, 0.06061, 0.24620, 0.16764, 356.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.05s
- Epoch 036, ExpID 25838
Train - Loss (one batch): 0.04326
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05625, 0.05625, 0.23718, 0.16449, 335.70%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.14s
- Epoch 037, ExpID 25838
Train - Loss (one batch): 0.04903
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07497, 0.07497, 0.27380, 0.18368, 279.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.25s
- Epoch 038, ExpID 25838
Train - Loss (one batch): 0.03111
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05429, 0.05429, 0.23301, 0.16118, 348.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.20s
- Epoch 039, ExpID 25838
Train - Loss (one batch): 0.03816
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07653, 0.07653, 0.27664, 0.18730, 285.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.19s
- Epoch 040, ExpID 25838
Train - Loss (one batch): 0.04641
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06450, 0.06450, 0.25397, 0.17379, 366.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.27s
- Epoch 041, ExpID 25838
Train - Loss (one batch): 0.03817
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07136, 0.07136, 0.26713, 0.18654, 354.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.09s
- Epoch 042, ExpID 25838
Train - Loss (one batch): 0.03504
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05664, 0.05664, 0.23798, 0.15881, 286.83%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.28s
- Epoch 043, ExpID 25838
Train - Loss (one batch): 0.05529
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05472, 0.05472, 0.23391, 0.16693, 397.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.23s
- Epoch 044, ExpID 25838
Train - Loss (one batch): 0.05486
Val - Loss, MSE, RMSE, MAE, MAPE: 0.09687, 0.09687, 0.31124, 0.20697, 208.57%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.30s
- Epoch 045, ExpID 25838
Train - Loss (one batch): 0.04716
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05913, 0.05913, 0.24317, 0.16780, 369.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.40s
- Epoch 046, ExpID 25838
Train - Loss (one batch): 0.03938
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06410, 0.06410, 0.25319, 0.17642, 363.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.35s
- Epoch 047, ExpID 25838
Train - Loss (one batch): 0.03441
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07471, 0.07471, 0.27333, 0.18558, 287.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.24s
- Epoch 048, ExpID 25838
Train - Loss (one batch): 0.03910
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06191, 0.06191, 0.24881, 0.17293, 364.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.32s
- Epoch 049, ExpID 25838
Train - Loss (one batch): 0.05609
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06059, 0.06059, 0.24615, 0.17128, 398.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.42s
- Epoch 050, ExpID 25838
Train - Loss (one batch): 0.03404
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06118, 0.06118, 0.24734, 0.16768, 325.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.33s
- Epoch 051, ExpID 25838
Train - Loss (one batch): 0.03978
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05365, 0.05365, 0.23163, 0.16183, 351.09%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.33s
- Epoch 052, ExpID 25838
Train - Loss (one batch): 0.05087
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05410, 0.05410, 0.23260, 0.16643, 357.30%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.21s
- Epoch 053, ExpID 25838
Train - Loss (one batch): 0.04624
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06828, 0.06828, 0.26131, 0.17883, 355.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.37s
- Epoch 054, ExpID 25838
Train - Loss (one batch): 0.05541
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05282, 0.05282, 0.22982, 0.15631, 318.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.13s
- Epoch 055, ExpID 25838
Train - Loss (one batch): 0.03797
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05950, 0.05950, 0.24393, 0.16728, 345.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.11s
- Epoch 056, ExpID 25838
Train - Loss (one batch): 0.04443
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06563, 0.06563, 0.25619, 0.17651, 348.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.29s
- Epoch 057, ExpID 25838
Train - Loss (one batch): 0.03032
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05912, 0.05912, 0.24315, 0.16697, 335.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.00s
- Epoch 058, ExpID 25838
Train - Loss (one batch): 0.06174
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07034, 0.07034, 0.26522, 0.18291, 352.30%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.33s
- Epoch 059, ExpID 25838
Train - Loss (one batch): 0.03969
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05971, 0.05971, 0.24436, 0.16711, 361.62%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.33s
- Epoch 060, ExpID 25838
Train - Loss (one batch): 0.03860
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05908, 0.05908, 0.24307, 0.16267, 290.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.27s
- Epoch 061, ExpID 25838
Train - Loss (one batch): 0.04577
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07092, 0.07092, 0.26632, 0.18432, 342.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.00s
- Epoch 062, ExpID 25838
Train - Loss (one batch): 0.03983
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06080, 0.06080, 0.24658, 0.16881, 316.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.26s
- Epoch 063, ExpID 25838
Train - Loss (one batch): 0.04384
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06027, 0.06027, 0.24550, 0.16745, 341.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.25s
- Epoch 064, ExpID 25838
Train - Loss (one batch): 0.02409
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07043, 0.07043, 0.26539, 0.18398, 339.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.28s
- Epoch 065, ExpID 25838
Train - Loss (one batch): 0.03117
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06136, 0.06136, 0.24771, 0.17073, 396.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.24s
- Epoch 066, ExpID 25838
Train - Loss (one batch): 0.05223
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06732, 0.06732, 0.25947, 0.18009, 363.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.17s
- Epoch 067, ExpID 25838
Train - Loss (one batch): 0.03437
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07409, 0.07409, 0.27219, 0.19093, 382.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.34s
- Epoch 068, ExpID 25838
Train - Loss (one batch): 0.05715
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05346, 0.05346, 0.23122, 0.16168, 351.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.37s
- Epoch 069, ExpID 25838
Train - Loss (one batch): 0.04757
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07991, 0.07991, 0.28268, 0.19567, 333.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.34s
- Epoch 070, ExpID 25838
Train - Loss (one batch): 0.03462
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05642, 0.05642, 0.23753, 0.16405, 347.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.32s
- Epoch 071, ExpID 25838
Train - Loss (one batch): 0.03909
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05560, 0.05560, 0.23580, 0.16439, 349.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.28s
- Epoch 072, ExpID 25838
Train - Loss (one batch): 0.03938
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05366, 0.05366, 0.23165, 0.15826, 348.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.25s
- Epoch 073, ExpID 25838
Train - Loss (one batch): 0.03717
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05592, 0.05592, 0.23648, 0.16259, 348.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.18s
- Epoch 074, ExpID 25838
Train - Loss (one batch): 0.04148
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05565, 0.05565, 0.23590, 0.16110, 339.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.12s
- Epoch 075, ExpID 25838
Train - Loss (one batch): 0.04669
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05430, 0.05430, 0.23303, 0.16129, 313.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.14s
- Epoch 076, ExpID 25838
Train - Loss (one batch): 0.04118
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06990, 0.06990, 0.26438, 0.18472, 395.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.07s
- Epoch 077, ExpID 25838
Train - Loss (one batch): 0.03648
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05592, 0.05592, 0.23648, 0.15960, 299.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.10s
- Epoch 078, ExpID 25838
Train - Loss (one batch): 0.03076
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06258, 0.06258, 0.25016, 0.16939, 354.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.04s
- Epoch 079, ExpID 25838
Train - Loss (one batch): 0.05536
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06072, 0.06072, 0.24642, 0.17071, 362.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.12s
- Epoch 080, ExpID 25838
Train - Loss (one batch): 0.04248
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07459, 0.07459, 0.27310, 0.18985, 355.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.10s
- Epoch 081, ExpID 25838
Train - Loss (one batch): 0.03464
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05510, 0.05510, 0.23474, 0.16014, 354.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.04s
- Epoch 082, ExpID 25838
Train - Loss (one batch): 0.03248
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07403, 0.07403, 0.27208, 0.18782, 334.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.27s
- Epoch 083, ExpID 25838
Train - Loss (one batch): 0.04653
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05637, 0.05637, 0.23742, 0.16457, 391.09%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.29s
- Epoch 084, ExpID 25838
Train - Loss (one batch): 0.04411
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07824, 0.07824, 0.27972, 0.19252, 323.92%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.20s
- Epoch 085, ExpID 25838
Train - Loss (one batch): 0.04154
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06508, 0.06508, 0.25511, 0.17497, 344.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.11s
- Epoch 086, ExpID 25838
Train - Loss (one batch): 0.04273
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06637, 0.06637, 0.25761, 0.17607, 323.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.13s
- Epoch 087, ExpID 25838
Train - Loss (one batch): 0.04419
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06267, 0.06267, 0.25034, 0.16893, 298.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.10s
- Epoch 088, ExpID 25838
Train - Loss (one batch): 0.04827
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06297, 0.06297, 0.25095, 0.17207, 333.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.30s
- Epoch 089, ExpID 25838
Train - Loss (one batch): 0.04016
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06325, 0.06325, 0.25150, 0.17047, 326.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.29s
- Epoch 090, ExpID 25838
Train - Loss (one batch): 0.03467
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06481, 0.06481, 0.25459, 0.17539, 342.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.24s
- Epoch 091, ExpID 25838
Train - Loss (one batch): 0.03080
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06668, 0.06668, 0.25822, 0.18041, 400.02%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.26s
- Epoch 092, ExpID 25838
Train - Loss (one batch): 0.02970
Val - Loss, MSE, RMSE, MAE, MAPE: 0.08015, 0.08015, 0.28311, 0.19652, 362.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.25s
- Epoch 093, ExpID 25838
Train - Loss (one batch): 0.04440
Val - Loss, MSE, RMSE, MAE, MAPE: 0.08810, 0.08810, 0.29682, 0.20193, 293.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.32s
- Epoch 094, ExpID 25838
Train - Loss (one batch): 0.02627
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06535, 0.06535, 0.25564, 0.17503, 310.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.26s
- Epoch 095, ExpID 25838
Train - Loss (one batch): 0.03654
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05535, 0.05535, 0.23527, 0.16273, 323.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.33s
- Epoch 096, ExpID 25838
Train - Loss (one batch): 0.04893
Val - Loss, MSE, RMSE, MAE, MAPE: 0.08040, 0.08040, 0.28355, 0.19580, 345.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.13s
- Epoch 097, ExpID 25838
Train - Loss (one batch): 0.03048
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07312, 0.07312, 0.27042, 0.18181, 277.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.32s
- Epoch 098, ExpID 25838
Train - Loss (one batch): 0.02903
Val - Loss, MSE, RMSE, MAE, MAPE: 0.05766, 0.05766, 0.24013, 0.16708, 339.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.34s
- Epoch 099, ExpID 25838
Train - Loss (one batch): 0.04311
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06881, 0.06881, 0.26232, 0.17950, 331.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.05707, 0.05707, 0.23888, 0.16801, 352.73%
Time spent: 28.11s
True
Couldn't import umap
PID, device: 1843178 cuda:0
Total records: 23457
Dataset n_samples: 23457 14073 4692 4692
Test record ids (first 20): [20539, 3274, 10159, 3501, 7505, 21021, 12964, 12250, 9303, 13430, 247, 8922, 3778, 6354, 9236, 17756, 21529, 17436, 10901, 19808]
Test record ids (last 20): [5183, 5610, 19849, 20653, 16941, 20849, 22721, 18864, 6285, 23347, 42, 14912, 3570, 22992, 17801, 4049, 5466, 795, 396, 18120]
data_max: tensor([5.6000e+01, 5.0000e+01, 2.3300e+01, 1.5500e+02, 2.7800e+01, 2.3400e+03,
        3.7500e+01, 3.2800e+01, 1.5600e+01, 1.8200e+02, 4.0240e+03, 3.6400e+04,
        8.2800e+01, 2.8000e+02, 4.0000e+01, 5.1000e+01, 7.0600e+01, 2.2300e+01,
        1.0000e+02, 4.8000e+01, 3.9800e+01, 1.3900e+02, 1.0000e+02, 9.9000e+01,
        2.2920e+03, 2.9700e+01, 8.4400e+00, 6.0020e+02, 1.6260e+02, 3.1000e+01,
        1.5000e+02, 1.5030e+04, 9.0000e+00, 1.0800e+00, 1.0000e+01, 5.0000e+00,
        2.0000e+01, 2.0000e+00, 1.6667e+01, 1.1000e+04, 4.2000e+01, 2.5000e+03,
        9.2967e+01, 9.0000e+02, 1.8750e+02, 5.3333e+01, 5.0000e+01, 1.5571e+01,
        2.9000e+01, 6.5000e+01, 1.7400e+02, 7.7500e+02, 6.3000e+00, 3.1000e+03,
        2.7000e+02, 6.5000e+02, 9.0000e+01, 1.0000e+02, 3.7500e+02, 1.6390e+01,
        2.5000e+00, 2.5000e+01, 2.9000e+01, 1.0000e+02, 4.0000e+01, 5.2000e+02,
        6.0000e+01, 1.2500e+01, 1.5000e+02, 1.0000e+03, 4.8000e+03, 6.2500e+01,
        4.5000e+02, 3.0000e+02, 2.6000e+01, 2.5000e+02, 3.7000e+03, 1.0000e+02,
        4.0000e+01, 8.0000e+00, 1.0000e+03, 1.5000e+03, 3.0000e+01, 5.0000e+03,
        2.8000e+02, 2.7041e+03, 1.0500e+03, 5.0000e+00, 2.0640e+00, 1.4286e+02,
        5.0000e+02, 7.0000e+02, 1.0200e+03, 6.0000e+02, 1.5000e+03, 2.5000e+02],
       device='cuda:0')
data_min: tensor([2.0000e+00, 5.0000e+00, 1.8000e+00, 3.9000e+01, 0.0000e+00, 0.0000e+00,
        2.0000e-01, 0.0000e+00, 8.0000e-01, 8.2000e+01, 5.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e-01, 1.2500e+01, 1.0000e-01,
        8.2000e+00, 1.0000e+00, 1.0000e+00, 1.5000e-02, 3.0000e+00, 1.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3333e-01, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.0000e+00, 1.1000e+01, 1.0000e+00, 0.0000e+00,
        0.0000e+00, 8.1000e+01, 3.0000e+00, 1.0000e+02, 0.0000e+00, 0.0000e+00,
        3.3333e-02, 0.0000e+00, 8.3333e-01, 1.0000e+00, 5.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5000e+01, 0.0000e+00, 3.3333e-01,
        0.0000e+00, 1.0000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5000e+00,
        8.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e-02, 0.0000e+00, 0.0000e+00,
        4.1667e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
       device='cuda:0')
time_max: tensor(47.9833, device='cuda:0')
model Model(
  (patch_embedding): PatchEmbedding(
    (padding_patch_layer): ReplicationPad1d((0, 8))
    (value_embedding): Linear(in_features=16, out_features=64, bias=False)
    (position_embedding): PositionalEmbedding()
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): Encoder(
    (attn_layers): ModuleList(
      (0-1): 2 x EncoderLayer(
        (attention): AttentionLayer(
          (inner_attention): FullAttention(
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (query_projection): Linear(in_features=64, out_features=64, bias=True)
          (key_projection): Linear(in_features=64, out_features=64, bias=True)
          (value_projection): Linear(in_features=64, out_features=64, bias=True)
          (out_projection): Linear(in_features=64, out_features=64, bias=True)
        )
        (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): Sequential(
      (0): Transpose()
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Transpose()
    )
  )
  (te_scale): Linear(in_features=1, out_features=1, bias=True)
  (te_periodic): Linear(in_features=1, out_features=63, bias=True)
  (decoder): Sequential(
    (0): Linear(in_features=128, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=1, bias=True)
  )
)
parameters: 64193
n_train_batches: 440
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_baselines.py
2024-07-19 13:11:05
run_baselines.py --history 12 --model PatchTST --dataset mimic
Namespace(state='def', n=100000000, epoch=100, patience=10, history=12, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='mimic', quantization=0.0, model='PatchTST', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=8, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='0', seq_len=133, top_k=5, num_kernels=64, npatch=1, device=device(type='cuda', index=0), PID=1871401, pred_window=36, ndim=96, patch_layer=1, task_name='long_term_forecast', label_len=48, pred_len=96, patch_len=16, d_model=64, dropout=0.1, output_attention=None, n_heads=1, d_ff=64, activation='gelu', e_layers=2, factor=3, enc_in=321)
- Epoch 000, ExpID 24674
Train - Loss (one batch): 0.06403
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07127, 0.07127, 0.26696, 0.21910, 917.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.07516, 0.07516, 0.27415, 0.22046, 868.55%
Time spent: 28.62s
- Epoch 001, ExpID 24674
Train - Loss (one batch): 0.06124
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07127, 0.07127, 0.26696, 0.20925, 785.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.07534, 0.07534, 0.27448, 0.21012, 732.27%
Time spent: 27.89s
- Epoch 002, ExpID 24674
Train - Loss (one batch): 0.07856
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07117, 0.07117, 0.26679, 0.21165, 822.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.07504, 0.07504, 0.27394, 0.21242, 756.98%
Time spent: 27.95s
- Epoch 003, ExpID 24674
Train - Loss (one batch): 0.06782
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07138, 0.07138, 0.26717, 0.21042, 789.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.07504, 0.07504, 0.27394, 0.21242, 756.98%
Time spent: 24.33s
- Epoch 004, ExpID 24674
Train - Loss (one batch): 0.06495
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06918, 0.06918, 0.26303, 0.20815, 789.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.07292, 0.07292, 0.27003, 0.20920, 735.74%
Time spent: 27.82s
- Epoch 005, ExpID 24674
Train - Loss (one batch): 0.07469
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07043, 0.07043, 0.26539, 0.21224, 842.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.07292, 0.07292, 0.27003, 0.20920, 735.74%
Time spent: 24.48s
- Epoch 006, ExpID 24674
Train - Loss (one batch): 0.07310
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07137, 0.07137, 0.26716, 0.20872, 755.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.07292, 0.07292, 0.27003, 0.20920, 735.74%
Time spent: 24.29s
- Epoch 007, ExpID 24674
Train - Loss (one batch): 0.07251
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07033, 0.07033, 0.26520, 0.21153, 801.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.07292, 0.07292, 0.27003, 0.20920, 735.74%
Time spent: 24.23s
- Epoch 008, ExpID 24674
Train - Loss (one batch): 0.06114
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07057, 0.07057, 0.26565, 0.20935, 803.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.07292, 0.07292, 0.27003, 0.20920, 735.74%
Time spent: 24.39s
- Epoch 009, ExpID 24674
Train - Loss (one batch): 0.08128
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07088, 0.07088, 0.26623, 0.21194, 814.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.07292, 0.07292, 0.27003, 0.20920, 735.74%
Time spent: 24.21s
- Epoch 010, ExpID 24674
Train - Loss (one batch): 0.06465
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06840, 0.06840, 0.26153, 0.20602, 769.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.07209, 0.07209, 0.26850, 0.20734, 716.38%
Time spent: 27.63s
- Epoch 011, ExpID 24674
Train - Loss (one batch): 0.07103
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06985, 0.06985, 0.26428, 0.20533, 728.18%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.07209, 0.07209, 0.26850, 0.20734, 716.38%
Time spent: 24.08s
- Epoch 012, ExpID 24674
Train - Loss (one batch): 0.07293
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07029, 0.07029, 0.26513, 0.20689, 760.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.07209, 0.07209, 0.26850, 0.20734, 716.38%
Time spent: 24.54s
- Epoch 013, ExpID 24674
Train - Loss (one batch): 0.06017
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07168, 0.07168, 0.26773, 0.20660, 717.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.07209, 0.07209, 0.26850, 0.20734, 716.38%
Time spent: 24.50s
- Epoch 014, ExpID 24674
Train - Loss (one batch): 0.05931
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06980, 0.06980, 0.26420, 0.20681, 739.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.07209, 0.07209, 0.26850, 0.20734, 716.38%
Time spent: 24.51s
- Epoch 015, ExpID 24674
Train - Loss (one batch): 0.06760
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06986, 0.06986, 0.26431, 0.20594, 726.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.07209, 0.07209, 0.26850, 0.20734, 716.38%
Time spent: 24.52s
- Epoch 016, ExpID 24674
Train - Loss (one batch): 0.06957
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07038, 0.07038, 0.26528, 0.20501, 729.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.07209, 0.07209, 0.26850, 0.20734, 716.38%
Time spent: 24.28s
- Epoch 017, ExpID 24674
Train - Loss (one batch): 0.07581
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06810, 0.06810, 0.26096, 0.20337, 735.85%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 17, 0.07173, 0.07173, 0.26783, 0.20447, 690.45%
Time spent: 27.84s
- Epoch 018, ExpID 24674
Train - Loss (one batch): 0.07893
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06802, 0.06802, 0.26080, 0.20615, 788.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 27.70s
- Epoch 019, ExpID 24674
Train - Loss (one batch): 0.07558
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07050, 0.07050, 0.26552, 0.20396, 719.12%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.07s
- Epoch 020, ExpID 24674
Train - Loss (one batch): 0.05817
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07038, 0.07038, 0.26529, 0.20787, 757.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.21s
- Epoch 021, ExpID 24674
Train - Loss (one batch): 0.07266
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06863, 0.06863, 0.26197, 0.20513, 748.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.21s
- Epoch 022, ExpID 24674
Train - Loss (one batch): 0.07462
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06824, 0.06824, 0.26123, 0.20225, 699.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.20s
- Epoch 023, ExpID 24674
Train - Loss (one batch): 0.07251
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06926, 0.06926, 0.26317, 0.20515, 725.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.44s
- Epoch 024, ExpID 24674
Train - Loss (one batch): 0.06945
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07149, 0.07149, 0.26738, 0.20594, 723.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.36s
- Epoch 025, ExpID 24674
Train - Loss (one batch): 0.06774
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07005, 0.07005, 0.26466, 0.19696, 603.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.34s
- Epoch 026, ExpID 24674
Train - Loss (one batch): 0.06959
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06857, 0.06857, 0.26185, 0.20793, 787.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.38s
- Epoch 027, ExpID 24674
Train - Loss (one batch): 0.06341
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06965, 0.06965, 0.26392, 0.20716, 785.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.34s
- Epoch 028, ExpID 24674
Train - Loss (one batch): 0.08460
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07083, 0.07083, 0.26614, 0.20794, 759.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.35s
- Epoch 029, ExpID 24674
Train - Loss (one batch): 0.06290
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07033, 0.07033, 0.26520, 0.20413, 698.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.27s
- Epoch 030, ExpID 24674
Train - Loss (one batch): 0.06827
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06987, 0.06987, 0.26432, 0.21005, 799.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.35s
- Epoch 031, ExpID 24674
Train - Loss (one batch): 0.06168
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06956, 0.06956, 0.26374, 0.20725, 745.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.56s
- Epoch 032, ExpID 24674
Train - Loss (one batch): 0.06995
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07017, 0.07017, 0.26490, 0.20730, 734.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.56s
- Epoch 033, ExpID 24674
Train - Loss (one batch): 0.06659
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07065, 0.07065, 0.26580, 0.20529, 708.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.07168, 0.07168, 0.26773, 0.20733, 734.27%
Time spent: 24.33s
- Epoch 034, ExpID 24674
Train - Loss (one batch): 0.07732
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06787, 0.06787, 0.26052, 0.20571, 741.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 34, 0.07166, 0.07166, 0.26769, 0.20691, 694.51%
Time spent: 27.97s
- Epoch 035, ExpID 24674
Train - Loss (one batch): 0.05941
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06825, 0.06825, 0.26124, 0.20501, 756.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 34, 0.07166, 0.07166, 0.26769, 0.20691, 694.51%
Time spent: 24.54s
- Epoch 036, ExpID 24674
Train - Loss (one batch): 0.07099
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07087, 0.07087, 0.26622, 0.20875, 737.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 34, 0.07166, 0.07166, 0.26769, 0.20691, 694.51%
Time spent: 24.56s
- Epoch 037, ExpID 24674
Train - Loss (one batch): 0.07112
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06939, 0.06939, 0.26343, 0.20697, 746.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 34, 0.07166, 0.07166, 0.26769, 0.20691, 694.51%
Time spent: 24.41s
- Epoch 038, ExpID 24674
Train - Loss (one batch): 0.07100
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06874, 0.06874, 0.26219, 0.20487, 736.43%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 34, 0.07166, 0.07166, 0.26769, 0.20691, 694.51%
Time spent: 24.35s
- Epoch 039, ExpID 24674
Train - Loss (one batch): 0.07257
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06898, 0.06898, 0.26264, 0.20380, 720.18%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 34, 0.07166, 0.07166, 0.26769, 0.20691, 694.51%
Time spent: 24.49s
- Epoch 040, ExpID 24674
Train - Loss (one batch): 0.05836
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06725, 0.06725, 0.25932, 0.20260, 723.38%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 27.75s
- Epoch 041, ExpID 24674
Train - Loss (one batch): 0.06394
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07238, 0.07238, 0.26903, 0.20886, 724.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 24.22s
- Epoch 042, ExpID 24674
Train - Loss (one batch): 0.06688
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07255, 0.07255, 0.26936, 0.21054, 785.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 24.11s
- Epoch 043, ExpID 24674
Train - Loss (one batch): 0.07456
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06905, 0.06905, 0.26278, 0.20491, 733.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 24.30s
- Epoch 044, ExpID 24674
Train - Loss (one batch): 0.06585
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06846, 0.06846, 0.26165, 0.20617, 751.03%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 24.50s
- Epoch 045, ExpID 24674
Train - Loss (one batch): 0.05977
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07019, 0.07019, 0.26493, 0.20723, 741.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 25.50s
- Epoch 046, ExpID 24674
Train - Loss (one batch): 0.07441
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07339, 0.07339, 0.27091, 0.20759, 736.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 29.44s
- Epoch 047, ExpID 24674
Train - Loss (one batch): 0.06854
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06887, 0.06887, 0.26242, 0.20302, 706.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 29.57s
- Epoch 048, ExpID 24674
Train - Loss (one batch): 0.06466
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06745, 0.06745, 0.25972, 0.20535, 748.06%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 29.91s
- Epoch 049, ExpID 24674
Train - Loss (one batch): 0.06955
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07163, 0.07163, 0.26764, 0.20593, 720.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 29.58s
- Epoch 050, ExpID 24674
Train - Loss (one batch): 0.05811
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06988, 0.06988, 0.26435, 0.20565, 729.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 29.69s
- Epoch 051, ExpID 24674
Train - Loss (one batch): 0.07688
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07102, 0.07102, 0.26650, 0.20789, 742.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 29.86s
- Epoch 052, ExpID 24674
Train - Loss (one batch): 0.06665
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07003, 0.07003, 0.26463, 0.20500, 714.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 29.80s
- Epoch 053, ExpID 24674
Train - Loss (one batch): 0.07901
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06930, 0.06930, 0.26324, 0.20719, 756.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 29.70s
- Epoch 054, ExpID 24674
Train - Loss (one batch): 0.06262
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07167, 0.07167, 0.26771, 0.20642, 719.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 29.41s
- Epoch 055, ExpID 24674
Train - Loss (one batch): 0.06977
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06824, 0.06824, 0.26123, 0.20405, 736.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 40, 0.07115, 0.07115, 0.26674, 0.20426, 676.58%
Time spent: 29.57s
- Epoch 056, ExpID 24674
Train - Loss (one batch): 0.05977
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06721, 0.06721, 0.25925, 0.20210, 730.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 56, 0.07096, 0.07096, 0.26639, 0.20337, 672.92%
Time spent: 54.86s
- Epoch 057, ExpID 24674
Train - Loss (one batch): 0.06199
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06832, 0.06832, 0.26138, 0.20398, 737.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 56, 0.07096, 0.07096, 0.26639, 0.20337, 672.92%
Time spent: 47.39s
- Epoch 058, ExpID 24674
Train - Loss (one batch): 0.06189
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07161, 0.07161, 0.26761, 0.20880, 742.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 56, 0.07096, 0.07096, 0.26639, 0.20337, 672.92%
Time spent: 48.19s
- Epoch 059, ExpID 24674
Train - Loss (one batch): 0.06608
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06712, 0.06712, 0.25907, 0.20363, 734.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 59, 0.07105, 0.07105, 0.26655, 0.20532, 689.97%
Time spent: 57.46s
- Epoch 060, ExpID 24674
Train - Loss (one batch): 0.05894
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06695, 0.06695, 0.25875, 0.20192, 718.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 56.30s
- Epoch 061, ExpID 24674
Train - Loss (one batch): 0.06864
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06701, 0.06701, 0.25887, 0.20190, 724.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 47.90s
- Epoch 062, ExpID 24674
Train - Loss (one batch): 0.05908
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06911, 0.06911, 0.26290, 0.20640, 754.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 48.11s
- Epoch 063, ExpID 24674
Train - Loss (one batch): 0.07260
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07102, 0.07102, 0.26650, 0.20721, 728.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 48.86s
- Epoch 064, ExpID 24674
Train - Loss (one batch): 0.06631
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07097, 0.07097, 0.26640, 0.20806, 735.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 49.02s
- Epoch 065, ExpID 24674
Train - Loss (one batch): 0.07475
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07082, 0.07082, 0.26611, 0.20821, 754.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 49.11s
- Epoch 066, ExpID 24674
Train - Loss (one batch): 0.07716
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06900, 0.06900, 0.26267, 0.20727, 759.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 49.46s
- Epoch 067, ExpID 24674
Train - Loss (one batch): 0.06560
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07096, 0.07096, 0.26638, 0.20762, 730.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 48.24s
- Epoch 068, ExpID 24674
Train - Loss (one batch): 0.07008
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07043, 0.07043, 0.26539, 0.20820, 752.02%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 47.94s
- Epoch 069, ExpID 24674
Train - Loss (one batch): 0.06197
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07034, 0.07034, 0.26522, 0.20641, 723.68%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 48.47s
- Epoch 070, ExpID 24674
Train - Loss (one batch): 0.06212
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06809, 0.06809, 0.26095, 0.20332, 724.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 49.13s
- Epoch 071, ExpID 24674
Train - Loss (one batch): 0.06788
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06947, 0.06947, 0.26357, 0.20700, 758.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 49.33s
- Epoch 072, ExpID 24674
Train - Loss (one batch): 0.06359
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06882, 0.06882, 0.26233, 0.20643, 747.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 49.24s
- Epoch 073, ExpID 24674
Train - Loss (one batch): 0.06170
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06966, 0.06966, 0.26393, 0.20596, 743.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 49.73s
- Epoch 074, ExpID 24674
Train - Loss (one batch): 0.07616
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06912, 0.06912, 0.26291, 0.20539, 733.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 48.16s
- Epoch 075, ExpID 24674
Train - Loss (one batch): 0.06065
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06978, 0.06978, 0.26416, 0.20530, 725.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 48.08s
- Epoch 076, ExpID 24674
Train - Loss (one batch): 0.07390
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07246, 0.07246, 0.26918, 0.20656, 705.62%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 48.42s
- Epoch 077, ExpID 24674
Train - Loss (one batch): 0.07317
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07027, 0.07027, 0.26508, 0.20675, 740.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 49.07s
- Epoch 078, ExpID 24674
Train - Loss (one batch): 0.06805
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06786, 0.06786, 0.26049, 0.20408, 750.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 51.26s
- Epoch 079, ExpID 24674
Train - Loss (one batch): 0.06780
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06999, 0.06999, 0.26456, 0.20513, 706.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 49.94s
- Epoch 080, ExpID 24674
Train - Loss (one batch): 0.06364
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06875, 0.06875, 0.26221, 0.20351, 712.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 49.47s
- Epoch 081, ExpID 24674
Train - Loss (one batch): 0.07108
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06943, 0.06943, 0.26350, 0.20615, 763.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 48.22s
- Epoch 082, ExpID 24674
Train - Loss (one batch): 0.07260
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06870, 0.06870, 0.26210, 0.20379, 717.48%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 42.62s
- Epoch 083, ExpID 24674
Train - Loss (one batch): 0.07205
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07165, 0.07165, 0.26767, 0.20743, 726.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 29.39s
- Epoch 084, ExpID 24674
Train - Loss (one batch): 0.06168
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07004, 0.07004, 0.26466, 0.20482, 714.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 29.81s
- Epoch 085, ExpID 24674
Train - Loss (one batch): 0.06253
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07020, 0.07020, 0.26496, 0.20400, 704.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 29.68s
- Epoch 086, ExpID 24674
Train - Loss (one batch): 0.07543
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06729, 0.06729, 0.25941, 0.20510, 777.88%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 29.85s
- Epoch 087, ExpID 24674
Train - Loss (one batch): 0.06395
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06942, 0.06942, 0.26349, 0.20463, 735.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 29.94s
- Epoch 088, ExpID 24674
Train - Loss (one batch): 0.06442
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06895, 0.06895, 0.26259, 0.20346, 716.85%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 29.93s
- Epoch 089, ExpID 24674
Train - Loss (one batch): 0.06670
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07094, 0.07094, 0.26634, 0.20590, 700.96%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 29.99s
- Epoch 090, ExpID 24674
Train - Loss (one batch): 0.05878
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06717, 0.06717, 0.25917, 0.20357, 743.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 60, 0.07061, 0.07061, 0.26573, 0.20286, 673.29%
Time spent: 29.68s
- Epoch 091, ExpID 24674
Train - Loss (one batch): 0.08138
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06606, 0.06606, 0.25702, 0.20122, 726.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 91, 0.06995, 0.06995, 0.26449, 0.20270, 666.94%
Time spent: 34.17s
- Epoch 092, ExpID 24674
Train - Loss (one batch): 0.06650
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07069, 0.07069, 0.26588, 0.20639, 733.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 91, 0.06995, 0.06995, 0.26449, 0.20270, 666.94%
Time spent: 29.76s
- Epoch 093, ExpID 24674
Train - Loss (one batch): 0.06686
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07269, 0.07269, 0.26962, 0.20851, 721.83%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 91, 0.06995, 0.06995, 0.26449, 0.20270, 666.94%
Time spent: 41.96s
- Epoch 094, ExpID 24674
Train - Loss (one batch): 0.06146
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06867, 0.06867, 0.26205, 0.20274, 716.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 91, 0.06995, 0.06995, 0.26449, 0.20270, 666.94%
Time spent: 42.29s
- Epoch 095, ExpID 24674
Train - Loss (one batch): 0.05020
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06991, 0.06991, 0.26440, 0.20680, 725.65%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 91, 0.06995, 0.06995, 0.26449, 0.20270, 666.94%
Time spent: 42.27s
- Epoch 096, ExpID 24674
Train - Loss (one batch): 0.06554
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06736, 0.06736, 0.25954, 0.20313, 733.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 91, 0.06995, 0.06995, 0.26449, 0.20270, 666.94%
Time spent: 42.72s
- Epoch 097, ExpID 24674
Train - Loss (one batch): 0.05954
Val - Loss, MSE, RMSE, MAE, MAPE: 0.07079, 0.07079, 0.26606, 0.20632, 721.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 91, 0.06995, 0.06995, 0.26449, 0.20270, 666.94%
Time spent: 43.20s
- Epoch 098, ExpID 24674
Train - Loss (one batch): 0.06317
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06776, 0.06776, 0.26031, 0.20220, 716.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 91, 0.06995, 0.06995, 0.26449, 0.20270, 666.94%
Time spent: 42.92s
- Epoch 099, ExpID 24674
Train - Loss (one batch): 0.06908
Val - Loss, MSE, RMSE, MAE, MAPE: 0.06888, 0.06888, 0.26244, 0.20435, 726.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 91, 0.06995, 0.06995, 0.26449, 0.20270, 666.94%
Time spent: 43.16s
True
Couldn't import umap
PID, device: 1871401 cuda:0
Total records: 23457
Dataset n_samples: 23457 14073 4692 4692
Test record ids (first 20): [20539, 3274, 10159, 3501, 7505, 21021, 12964, 12250, 9303, 13430, 247, 8922, 3778, 6354, 9236, 17756, 21529, 17436, 10901, 19808]
Test record ids (last 20): [5183, 5610, 19849, 20653, 16941, 20849, 22721, 18864, 6285, 23347, 42, 14912, 3570, 22992, 17801, 4049, 5466, 795, 396, 18120]
data_max: tensor([5.6000e+01, 5.0000e+01, 2.3300e+01, 1.5500e+02, 2.7800e+01, 2.3400e+03,
        3.7500e+01, 3.2800e+01, 1.5600e+01, 1.8200e+02, 4.0240e+03, 3.6400e+04,
        8.2800e+01, 2.8000e+02, 4.0000e+01, 5.1000e+01, 7.0600e+01, 2.2300e+01,
        1.0000e+02, 4.8000e+01, 3.9800e+01, 1.3900e+02, 1.0000e+02, 9.9000e+01,
        2.2920e+03, 2.9700e+01, 8.4400e+00, 6.0020e+02, 1.6260e+02, 3.1000e+01,
        1.5000e+02, 1.5030e+04, 9.0000e+00, 1.0800e+00, 1.0000e+01, 5.0000e+00,
        2.0000e+01, 2.0000e+00, 1.6667e+01, 1.1000e+04, 4.2000e+01, 2.5000e+03,
        9.2967e+01, 9.0000e+02, 1.8750e+02, 5.3333e+01, 5.0000e+01, 1.5571e+01,
        2.9000e+01, 6.5000e+01, 1.7400e+02, 7.7500e+02, 6.3000e+00, 3.1000e+03,
        2.7000e+02, 6.5000e+02, 9.0000e+01, 1.0000e+02, 3.7500e+02, 1.6390e+01,
        2.5000e+00, 2.5000e+01, 2.9000e+01, 1.0000e+02, 4.0000e+01, 5.2000e+02,
        6.0000e+01, 1.2500e+01, 1.5000e+02, 1.0000e+03, 4.8000e+03, 6.2500e+01,
        4.5000e+02, 3.0000e+02, 2.6000e+01, 2.5000e+02, 3.7000e+03, 1.0000e+02,
        4.0000e+01, 8.0000e+00, 1.0000e+03, 1.5000e+03, 3.0000e+01, 5.0000e+03,
        2.8000e+02, 2.7041e+03, 1.0500e+03, 5.0000e+00, 2.0640e+00, 1.4286e+02,
        5.0000e+02, 7.0000e+02, 1.0200e+03, 6.0000e+02, 1.5000e+03, 2.5000e+02],
       device='cuda:0')
data_min: tensor([2.0000e+00, 5.0000e+00, 1.8000e+00, 3.9000e+01, 0.0000e+00, 0.0000e+00,
        2.0000e-01, 0.0000e+00, 8.0000e-01, 8.2000e+01, 5.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        5.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e-01, 1.2500e+01, 1.0000e-01,
        8.2000e+00, 1.0000e+00, 1.0000e+00, 1.5000e-02, 3.0000e+00, 1.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3333e-01, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 8.0000e+00, 1.1000e+01, 1.0000e+00, 0.0000e+00,
        0.0000e+00, 8.1000e+01, 3.0000e+00, 1.0000e+02, 0.0000e+00, 0.0000e+00,
        3.3333e-02, 0.0000e+00, 8.3333e-01, 1.0000e+00, 5.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5000e+01, 0.0000e+00, 3.3333e-01,
        0.0000e+00, 1.0000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5000e+00,
        8.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0000e-02, 0.0000e+00, 0.0000e+00,
        4.1667e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],
       device='cuda:0')
time_max: tensor(47.9833, device='cuda:0')
model Model(
  (patch_embedding): PatchEmbedding(
    (padding_patch_layer): ReplicationPad1d((0, 8))
    (value_embedding): Linear(in_features=16, out_features=64, bias=False)
    (position_embedding): PositionalEmbedding()
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): Encoder(
    (attn_layers): ModuleList(
      (0-1): 2 x EncoderLayer(
        (attention): AttentionLayer(
          (inner_attention): FullAttention(
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (query_projection): Linear(in_features=64, out_features=64, bias=True)
          (key_projection): Linear(in_features=64, out_features=64, bias=True)
          (value_projection): Linear(in_features=64, out_features=64, bias=True)
          (out_projection): Linear(in_features=64, out_features=64, bias=True)
        )
        (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): Sequential(
      (0): Transpose()
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Transpose()
    )
  )
  (te_scale): Linear(in_features=1, out_features=1, bias=True)
  (te_periodic): Linear(in_features=1, out_features=63, bias=True)
  (decoder): Sequential(
    (0): Linear(in_features=128, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=1, bias=True)
  )
)
parameters: 64193
n_train_batches: 440
/home/jiaxihu/bowenzhang/HPG/tPatchGNN/run_baselines.py
2024-07-19 14:08:00
run_baselines.py --history 24 --model PatchTST --dataset ushcn
Namespace(state='def', n=100000000, epoch=100, patience=10, history=24, logmode='a', lr=0.001, w_decay=0.0, batch_size=32, viz=False, save='experiments/', load=None, seed=1, dataset='ushcn', quantization=0.0, model='PatchTST', outlayer='Linear', patch_ts=False, hop=1, nhead=1, tf_layer=1, nlayer=1, patch_size=24, stride=8, hid_dim=64, te_dim=10, node_dim=10, alpha=0.9, res=1, gpu='0', seq_len=205, top_k=5, num_kernels=64, npatch=1, device=device(type='cuda', index=0), PID=1906391, n_months=48, pred_window=1, ndim=5, patch_layer=1, task_name='long_term_forecast', label_len=48, pred_len=96, patch_len=16, d_model=64, dropout=0.1, output_attention=None, n_heads=1, d_ff=64, activation='gelu', e_layers=2, factor=3, enc_in=321)
- Epoch 000, ExpID 55527
Train - Loss (one batch): 0.35233
Val - Loss, MSE, RMSE, MAE, MAPE: 0.97389, 0.97389, 0.98686, 0.40254, -61.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.61239, 0.61239, 0.78255, 0.37369, -60.57%
Time spent: 28.88s
- Epoch 001, ExpID 55527
Train - Loss (one batch): 0.29519
Val - Loss, MSE, RMSE, MAE, MAPE: 0.98028, 0.98028, 0.99009, 0.46668, -106.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.61239, 0.61239, 0.78255, 0.37369, -60.57%
Time spent: 24.82s
- Epoch 002, ExpID 55527
Train - Loss (one batch): 0.35408
Val - Loss, MSE, RMSE, MAE, MAPE: 0.98468, 0.98468, 0.99231, 0.42497, -77.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.61239, 0.61239, 0.78255, 0.37369, -60.57%
Time spent: 24.89s
- Epoch 003, ExpID 55527
Train - Loss (one batch): 0.81622
Val - Loss, MSE, RMSE, MAE, MAPE: 0.93791, 0.93791, 0.96846, 0.40909, -72.02%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.58622, 0.58622, 0.76565, 0.38076, -70.80%
Time spent: 28.78s
- Epoch 004, ExpID 55527
Train - Loss (one batch): 0.24383
Val - Loss, MSE, RMSE, MAE, MAPE: 0.95835, 0.95835, 0.97895, 0.40350, -63.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.58622, 0.58622, 0.76565, 0.38076, -70.80%
Time spent: 24.96s
- Epoch 005, ExpID 55527
Train - Loss (one batch): 0.34876
Val - Loss, MSE, RMSE, MAE, MAPE: 0.94745, 0.94745, 0.97337, 0.41084, -74.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.58622, 0.58622, 0.76565, 0.38076, -70.80%
Time spent: 25.28s
- Epoch 006, ExpID 55527
Train - Loss (one batch): 0.35465
Val - Loss, MSE, RMSE, MAE, MAPE: 0.93809, 0.93809, 0.96855, 0.38296, -55.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.58622, 0.58622, 0.76565, 0.38076, -70.80%
Time spent: 24.73s
- Epoch 007, ExpID 55527
Train - Loss (one batch): 0.27569
Val - Loss, MSE, RMSE, MAE, MAPE: 0.91921, 0.91921, 0.95875, 0.40397, -75.07%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.57685, 0.57685, 0.75951, 0.37556, -72.05%
Time spent: 28.58s
- Epoch 008, ExpID 55527
Train - Loss (one batch): 0.18660
Val - Loss, MSE, RMSE, MAE, MAPE: 0.92574, 0.92574, 0.96216, 0.37728, -56.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.57685, 0.57685, 0.75951, 0.37556, -72.05%
Time spent: 24.46s
- Epoch 009, ExpID 55527
Train - Loss (one batch): 0.28097
Val - Loss, MSE, RMSE, MAE, MAPE: 0.92089, 0.92089, 0.95963, 0.37974, -60.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.57685, 0.57685, 0.75951, 0.37556, -72.05%
Time spent: 24.32s
- Epoch 010, ExpID 55527
Train - Loss (one batch): 0.29723
Val - Loss, MSE, RMSE, MAE, MAPE: 0.91066, 0.91066, 0.95428, 0.38535, -64.43%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.56165, 0.56165, 0.74943, 0.35725, -63.43%
Time spent: 28.26s
- Epoch 011, ExpID 55527
Train - Loss (one batch): 0.25526
Val - Loss, MSE, RMSE, MAE, MAPE: 0.91310, 0.91310, 0.95556, 0.39428, -69.55%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.56165, 0.56165, 0.74943, 0.35725, -63.43%
Time spent: 24.08s
- Epoch 012, ExpID 55527
Train - Loss (one batch): 0.61574
Val - Loss, MSE, RMSE, MAE, MAPE: 0.90914, 0.90914, 0.95349, 0.39222, -68.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 12, 0.56899, 0.56899, 0.75431, 0.36270, -64.53%
Time spent: 28.87s
- Epoch 013, ExpID 55527
Train - Loss (one batch): 1.82668
Val - Loss, MSE, RMSE, MAE, MAPE: 0.91247, 0.91247, 0.95523, 0.35863, -44.19%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 12, 0.56899, 0.56899, 0.75431, 0.36270, -64.53%
Time spent: 24.88s
- Epoch 014, ExpID 55527
Train - Loss (one batch): 0.34891
Val - Loss, MSE, RMSE, MAE, MAPE: 0.92483, 0.92483, 0.96168, 0.39101, -63.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 12, 0.56899, 0.56899, 0.75431, 0.36270, -64.53%
Time spent: 24.98s
- Epoch 015, ExpID 55527
Train - Loss (one batch): 0.69273
Val - Loss, MSE, RMSE, MAE, MAPE: 0.90933, 0.90933, 0.95359, 0.38157, -65.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 12, 0.56899, 0.56899, 0.75431, 0.36270, -64.53%
Time spent: 13.94s
- Epoch 016, ExpID 55527
Train - Loss (one batch): 0.52954
Val - Loss, MSE, RMSE, MAE, MAPE: 0.90368, 0.90368, 0.95062, 0.40374, -79.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.56302, 0.56302, 0.75035, 0.37283, -78.49%
Time spent: 16.88s
- Epoch 017, ExpID 55527
Train - Loss (one batch): 0.19002
Val - Loss, MSE, RMSE, MAE, MAPE: 0.90415, 0.90415, 0.95087, 0.37670, -62.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.56302, 0.56302, 0.75035, 0.37283, -78.49%
Time spent: 14.81s
- Epoch 018, ExpID 55527
Train - Loss (one batch): 0.32632
Val - Loss, MSE, RMSE, MAE, MAPE: 0.91939, 0.91939, 0.95885, 0.39735, -78.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.56302, 0.56302, 0.75035, 0.37283, -78.49%
Time spent: 14.79s
- Epoch 019, ExpID 55527
Train - Loss (one batch): 0.66347
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87990, 0.87990, 0.93803, 0.36602, -62.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 19, 0.54189, 0.54189, 0.73613, 0.33800, -61.33%
Time spent: 16.86s
- Epoch 020, ExpID 55527
Train - Loss (one batch): 0.32556
Val - Loss, MSE, RMSE, MAE, MAPE: 0.84997, 0.84997, 0.92194, 0.36875, -67.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 21.39s
- Epoch 021, ExpID 55527
Train - Loss (one batch): 0.09654
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89785, 0.89785, 0.94755, 0.35615, -47.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 35.75s
- Epoch 022, ExpID 55527
Train - Loss (one batch): 0.47165
Val - Loss, MSE, RMSE, MAE, MAPE: 0.88114, 0.88114, 0.93869, 0.36868, -68.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 39.47s
- Epoch 023, ExpID 55527
Train - Loss (one batch): 0.32658
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86776, 0.86776, 0.93154, 0.35113, -55.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 38.21s
- Epoch 024, ExpID 55527
Train - Loss (one batch): 0.19371
Val - Loss, MSE, RMSE, MAE, MAPE: 0.85876, 0.85876, 0.92670, 0.34853, -56.03%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 38.03s
- Epoch 025, ExpID 55527
Train - Loss (one batch): 0.40351
Val - Loss, MSE, RMSE, MAE, MAPE: 0.88824, 0.88824, 0.94246, 0.34626, -54.30%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 37.15s
- Epoch 026, ExpID 55527
Train - Loss (one batch): 0.21659
Val - Loss, MSE, RMSE, MAE, MAPE: 0.88139, 0.88139, 0.93882, 0.35753, -60.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 37.62s
- Epoch 027, ExpID 55527
Train - Loss (one batch): 0.33412
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86376, 0.86376, 0.92938, 0.33588, -50.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 37.31s
- Epoch 028, ExpID 55527
Train - Loss (one batch): 0.73606
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87379, 0.87379, 0.93477, 0.37945, -71.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 37.99s
- Epoch 029, ExpID 55527
Train - Loss (one batch): 0.30895
Val - Loss, MSE, RMSE, MAE, MAPE: 0.85226, 0.85226, 0.92318, 0.35021, -58.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 37.12s
- Epoch 030, ExpID 55527
Train - Loss (one batch): 0.55215
Val - Loss, MSE, RMSE, MAE, MAPE: 0.88490, 0.88490, 0.94069, 0.36900, -71.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 37.90s
- Epoch 031, ExpID 55527
Train - Loss (one batch): 0.13604
Val - Loss, MSE, RMSE, MAE, MAPE: 0.88017, 0.88017, 0.93817, 0.35367, -60.91%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 38.17s
- Epoch 032, ExpID 55527
Train - Loss (one batch): 0.65579
Val - Loss, MSE, RMSE, MAE, MAPE: 0.88137, 0.88137, 0.93881, 0.34809, -54.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 38.02s
- Epoch 033, ExpID 55527
Train - Loss (one batch): 0.44037
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87116, 0.87116, 0.93336, 0.34182, -53.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 39.16s
- Epoch 034, ExpID 55527
Train - Loss (one batch): 0.49334
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87679, 0.87679, 0.93637, 0.34465, -52.49%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 38.73s
- Epoch 035, ExpID 55527
Train - Loss (one batch): 0.23893
Val - Loss, MSE, RMSE, MAE, MAPE: 0.85578, 0.85578, 0.92508, 0.34771, -59.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 39.33s
- Epoch 036, ExpID 55527
Train - Loss (one batch): 0.20191
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87179, 0.87179, 0.93370, 0.33414, -50.35%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 28.43s
- Epoch 037, ExpID 55527
Train - Loss (one batch): 0.19493
Val - Loss, MSE, RMSE, MAE, MAPE: 0.85564, 0.85564, 0.92501, 0.36019, -69.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 12.63s
- Epoch 038, ExpID 55527
Train - Loss (one batch): 0.14750
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86928, 0.86928, 0.93235, 0.33940, -51.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 12.35s
- Epoch 039, ExpID 55527
Train - Loss (one batch): 0.51166
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87117, 0.87117, 0.93337, 0.34696, -57.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 12.78s
- Epoch 040, ExpID 55527
Train - Loss (one batch): 0.26306
Val - Loss, MSE, RMSE, MAE, MAPE: 0.85589, 0.85589, 0.92514, 0.34810, -59.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 12.06s
- Epoch 041, ExpID 55527
Train - Loss (one batch): 0.36855
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86376, 0.86376, 0.92938, 0.34510, -56.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 12.42s
- Epoch 042, ExpID 55527
Train - Loss (one batch): 0.87930
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86046, 0.86046, 0.92761, 0.36820, -72.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 12.76s
- Epoch 043, ExpID 55527
Train - Loss (one batch): 0.25696
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87205, 0.87205, 0.93384, 0.36310, -68.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 12.79s
- Epoch 044, ExpID 55527
Train - Loss (one batch): 0.23162
Val - Loss, MSE, RMSE, MAE, MAPE: 0.85261, 0.85261, 0.92337, 0.34093, -54.87%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 12.08s
- Epoch 045, ExpID 55527
Train - Loss (one batch): 0.33857
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87299, 0.87299, 0.93434, 0.33754, -52.10%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 12.02s
- Epoch 046, ExpID 55527
Train - Loss (one batch): 0.25740
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87453, 0.87453, 0.93516, 0.35301, -58.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 11.71s
- Epoch 047, ExpID 55527
Train - Loss (one batch): 0.98253
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86862, 0.86862, 0.93200, 0.34532, -58.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 11.72s
- Epoch 048, ExpID 55527
Train - Loss (one batch): 0.32032
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87974, 0.87974, 0.93794, 0.35108, -57.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 12.45s
- Epoch 049, ExpID 55527
Train - Loss (one batch): 0.16538
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87330, 0.87330, 0.93450, 0.34700, -58.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 12.55s
- Epoch 050, ExpID 55527
Train - Loss (one batch): 0.49455
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86137, 0.86137, 0.92810, 0.34566, -59.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 11.92s
- Epoch 051, ExpID 55527
Train - Loss (one batch): 0.11731
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86199, 0.86199, 0.92843, 0.35983, -68.80%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 11.85s
- Epoch 052, ExpID 55527
Train - Loss (one batch): 0.73400
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89299, 0.89299, 0.94498, 0.36404, -65.41%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 11.73s
- Epoch 053, ExpID 55527
Train - Loss (one batch): 0.30483
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87384, 0.87384, 0.93479, 0.34448, -57.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 11.94s
- Epoch 054, ExpID 55527
Train - Loss (one batch): 0.35367
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86559, 0.86559, 0.93037, 0.33625, -52.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 11.76s
- Epoch 055, ExpID 55527
Train - Loss (one batch): 0.34968
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87809, 0.87809, 0.93706, 0.35020, -62.04%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 12.64s
- Epoch 056, ExpID 55527
Train - Loss (one batch): 0.18307
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87270, 0.87270, 0.93418, 0.35034, -61.16%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 12.45s
- Epoch 057, ExpID 55527
Train - Loss (one batch): 0.36895
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87390, 0.87390, 0.93482, 0.35430, -61.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 14.01s
- Epoch 058, ExpID 55527
Train - Loss (one batch): 0.15232
Val - Loss, MSE, RMSE, MAE, MAPE: 0.88404, 0.88404, 0.94023, 0.35066, -57.18%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 13.02s
- Epoch 059, ExpID 55527
Train - Loss (one batch): 0.22897
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86878, 0.86878, 0.93208, 0.34101, -54.48%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 12.72s
- Epoch 060, ExpID 55527
Train - Loss (one batch): 0.14034
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87681, 0.87681, 0.93638, 0.34537, -57.18%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 11.81s
- Epoch 061, ExpID 55527
Train - Loss (one batch): 0.63015
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87935, 0.87935, 0.93774, 0.33001, -47.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 12.63s
- Epoch 062, ExpID 55527
Train - Loss (one batch): 0.27936
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87117, 0.87117, 0.93336, 0.34667, -59.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 13.77s
- Epoch 063, ExpID 55527
Train - Loss (one batch): 0.26192
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87166, 0.87166, 0.93363, 0.34649, -56.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 13.92s
- Epoch 064, ExpID 55527
Train - Loss (one batch): 1.00908
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87492, 0.87492, 0.93537, 0.33876, -53.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 13.66s
- Epoch 065, ExpID 55527
Train - Loss (one batch): 1.41612
Val - Loss, MSE, RMSE, MAE, MAPE: 0.88450, 0.88450, 0.94048, 0.34261, -54.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 14.16s
- Epoch 066, ExpID 55527
Train - Loss (one batch): 0.92463
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86971, 0.86971, 0.93258, 0.33480, -49.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 14.89s
- Epoch 067, ExpID 55527
Train - Loss (one batch): 0.38656
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86387, 0.86387, 0.92945, 0.36221, -69.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 22.14s
- Epoch 068, ExpID 55527
Train - Loss (one batch): 0.52496
Val - Loss, MSE, RMSE, MAE, MAPE: 0.88385, 0.88385, 0.94013, 0.34343, -53.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 28.35s
- Epoch 069, ExpID 55527
Train - Loss (one batch): 0.44504
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86873, 0.86873, 0.93205, 0.33780, -52.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 31.50s
- Epoch 070, ExpID 55527
Train - Loss (one batch): 0.35747
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86625, 0.86625, 0.93073, 0.33833, -52.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 31.71s
- Epoch 071, ExpID 55527
Train - Loss (one batch): 0.13122
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87849, 0.87849, 0.93728, 0.34308, -55.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 32.05s
- Epoch 072, ExpID 55527
Train - Loss (one batch): 0.64046
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86817, 0.86817, 0.93175, 0.32893, -48.85%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 31.20s
- Epoch 073, ExpID 55527
Train - Loss (one batch): 0.22646
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87184, 0.87184, 0.93373, 0.33518, -52.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 31.49s
- Epoch 074, ExpID 55527
Train - Loss (one batch): 0.60086
Val - Loss, MSE, RMSE, MAE, MAPE: 0.88115, 0.88115, 0.93869, 0.34454, -57.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 31.54s
- Epoch 075, ExpID 55527
Train - Loss (one batch): 0.81807
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87424, 0.87424, 0.93501, 0.34476, -56.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 30.65s
- Epoch 076, ExpID 55527
Train - Loss (one batch): 0.53636
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86979, 0.86979, 0.93263, 0.34730, -57.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 31.85s
- Epoch 077, ExpID 55527
Train - Loss (one batch): 0.25807
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86471, 0.86471, 0.92990, 0.34248, -54.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 32.18s
- Epoch 078, ExpID 55527
Train - Loss (one batch): 0.11600
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86407, 0.86407, 0.92955, 0.34043, -55.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 31.50s
- Epoch 079, ExpID 55527
Train - Loss (one batch): 0.28790
Val - Loss, MSE, RMSE, MAE, MAPE: 0.88108, 0.88108, 0.93866, 0.35271, -58.74%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 30.57s
- Epoch 080, ExpID 55527
Train - Loss (one batch): 0.25382
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87169, 0.87169, 0.93364, 0.34287, -54.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 31.37s
- Epoch 081, ExpID 55527
Train - Loss (one batch): 1.09071
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87024, 0.87024, 0.93286, 0.34168, -53.83%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 31.71s
- Epoch 082, ExpID 55527
Train - Loss (one batch): 0.78689
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86352, 0.86352, 0.92926, 0.34145, -57.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 31.71s
- Epoch 083, ExpID 55527
Train - Loss (one batch): 0.41561
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87707, 0.87707, 0.93652, 0.33486, -50.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 30.18s
- Epoch 084, ExpID 55527
Train - Loss (one batch): 0.29166
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87674, 0.87674, 0.93634, 0.35319, -60.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 31.24s
- Epoch 085, ExpID 55527
Train - Loss (one batch): 0.39124
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86310, 0.86310, 0.92903, 0.34148, -57.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 31.23s
- Epoch 086, ExpID 55527
Train - Loss (one batch): 0.22307
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87538, 0.87538, 0.93562, 0.33390, -51.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 32.15s
- Epoch 087, ExpID 55527
Train - Loss (one batch): 0.69312
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86931, 0.86931, 0.93237, 0.34910, -61.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 31.13s
- Epoch 088, ExpID 55527
Train - Loss (one batch): 0.36052
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87002, 0.87002, 0.93275, 0.33885, -54.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 31.53s
- Epoch 089, ExpID 55527
Train - Loss (one batch): 0.66655
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87447, 0.87447, 0.93513, 0.34102, -55.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 31.51s
- Epoch 090, ExpID 55527
Train - Loss (one batch): 0.31004
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86757, 0.86757, 0.93144, 0.34383, -55.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 31.05s
- Epoch 091, ExpID 55527
Train - Loss (one batch): 0.37088
Val - Loss, MSE, RMSE, MAE, MAPE: 0.88085, 0.88085, 0.93854, 0.34553, -58.10%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 31.84s
- Epoch 092, ExpID 55527
Train - Loss (one batch): 0.49002
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87109, 0.87109, 0.93332, 0.33413, -50.18%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 32.21s
- Epoch 093, ExpID 55527
Train - Loss (one batch): 0.21641
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87905, 0.87905, 0.93758, 0.34065, -56.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 32.86s
- Epoch 094, ExpID 55527
Train - Loss (one batch): 0.33053
Val - Loss, MSE, RMSE, MAE, MAPE: 0.86323, 0.86323, 0.92910, 0.33955, -56.31%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 32.58s
- Epoch 095, ExpID 55527
Train - Loss (one batch): 0.31122
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87921, 0.87921, 0.93766, 0.35673, -64.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 31.91s
- Epoch 096, ExpID 55527
Train - Loss (one batch): 0.38139
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87521, 0.87521, 0.93552, 0.34218, -56.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 32.30s
- Epoch 097, ExpID 55527
Train - Loss (one batch): 0.12971
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87410, 0.87410, 0.93493, 0.34384, -57.64%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 30.78s
- Epoch 098, ExpID 55527
Train - Loss (one batch): 1.27268
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87076, 0.87076, 0.93315, 0.34439, -57.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 31.04s
- Epoch 099, ExpID 55527
Train - Loss (one batch): 0.43673
Val - Loss, MSE, RMSE, MAE, MAPE: 0.87162, 0.87162, 0.93361, 0.34392, -59.47%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.53469, 0.53469, 0.73123, 0.33915, -65.90%
Time spent: 30.71s
True
Couldn't import umap
PID, device: 1906391 cuda:0
Total records: 1114
Dataset n_samples: 1114 668 223 223
Test record ids (first 20): [886, 101, 1120, 730, 291, 875, 958, 260, 128, 1043, 620, 88, 1005, 872, 617, 538, 508, 44, 273, 817]
Test record ids (last 20): [982, 275, 991, 997, 66, 801, 67, 942, 12, 361, 555, 710, 333, 1017, 851, 184, 882, 509, 726, 587]
data_max: tensor([37.2551, 36.6691, 38.2520,  3.0401,  2.9104], device='cuda:0')
data_min: tensor([-0.3057, -0.1280, -0.1738, -3.8821, -4.1854], device='cuda:0')
time_max: tensor(48., device='cuda:0')
Dataset n_samples after time split: 26736 16032 5352 5352
model Model(
  (patch_embedding): PatchEmbedding(
    (padding_patch_layer): ReplicationPad1d((0, 8))
    (value_embedding): Linear(in_features=16, out_features=64, bias=False)
    (position_embedding): PositionalEmbedding()
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (encoder): Encoder(
    (attn_layers): ModuleList(
      (0-1): 2 x EncoderLayer(
        (attention): AttentionLayer(
          (inner_attention): FullAttention(
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (query_projection): Linear(in_features=64, out_features=64, bias=True)
          (key_projection): Linear(in_features=64, out_features=64, bias=True)
          (value_projection): Linear(in_features=64, out_features=64, bias=True)
          (out_projection): Linear(in_features=64, out_features=64, bias=True)
        )
        (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
        (conv2): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): Sequential(
      (0): Transpose()
      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): Transpose()
    )
  )
  (te_scale): Linear(in_features=1, out_features=1, bias=True)
  (te_periodic): Linear(in_features=1, out_features=63, bias=True)
  (decoder): Sequential(
    (0): Linear(in_features=128, out_features=64, bias=True)
    (1): ReLU(inplace=True)
    (2): Linear(in_features=64, out_features=64, bias=True)
    (3): ReLU(inplace=True)
    (4): Linear(in_features=64, out_features=1, bias=True)
  )
)
parameters: 64193
n_train_batches: 501
